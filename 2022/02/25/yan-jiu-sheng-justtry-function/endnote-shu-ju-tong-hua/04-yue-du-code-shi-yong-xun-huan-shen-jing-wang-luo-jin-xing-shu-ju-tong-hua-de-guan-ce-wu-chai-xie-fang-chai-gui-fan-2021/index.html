<!DOCTYPE HTML>
<!-- 01 语言选择 -->
<html lang="En">

<!-- 02 head是哪里？ok~~，首页，分类～～ -->
<!-- 下面的这个ejs语句，添加网站的head部分，即主页，分类等及其图标 -->


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="04-阅读：使用循环神经网络进行数据同化的观测误差协方差规范-2021, Jincan">
    <meta name="description" content="~~">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>04-阅读：使用循环神经网络进行数据同化的观测误差协方差规范-2021 | Jincan</title>
    <link rel="icon" type="image/png" href="/favicon_hua.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    
    <!-- aliyun网站教程添加图标所需的导入css，放到 matery 中的 my.css中 -->
    <link rel="stylesheet" type="text/css" href="/css/my.css">
    
    
    
    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

     
<meta name="generator" content="Hexo 5.4.1">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>


<!-- 03 background是什么？网站背景图 -->



<body>
    <!--04 header是什么？logo，navigation，githublink -->
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo_hua.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Jincan</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>Index</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>Categories</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>Archives</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>About</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>Friends</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="Search" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo_hua.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Jincan</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			Index
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			Categories
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			Archives
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			About
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			Friends
		</a>
          
        </li>
        
        
    </ul>
</div>


        </div>

        
    </nav>

</header>

    
<script src="/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('请输入访问本文章的密码')).toString(CryptoJS.enc.Hex)) {
                alert('密码错误，将返回主页！');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220327135302.png')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">04-阅读：使用循环神经网络进行数据同化的观测误差协方差规范-2021</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: scroll;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                          <div class="article-tag">
                            <span class="chip bg-color">No tag</span>
                          </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E6%95%B0%E6%8D%AE%E5%90%8C%E5%8C%96/" class="post-category">
                                数据同化
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>Publish Date:&nbsp;&nbsp;
                    2022-02-25
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>Update Date:&nbsp;&nbsp;
                    2022-04-17
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>Word Count:&nbsp;&nbsp;
                    11.3k
                </div>
                

                

                
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="07-阅读：使用循环神经网络进行数据同化的观测误差协方差规范-2021"><a href="#07-阅读：使用循环神经网络进行数据同化的观测误差协方差规范-2021" class="headerlink" title="07-阅读：使用循环神经网络进行数据同化的观测误差协方差规范-2021"></a><center>07-阅读：使用循环神经网络进行数据同化的观测误差协方差规范-2021</center></h1><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><p>英文名：<strong>Observation error covariance specification in dynamical systems for data assimilation using recurrent neural networks</strong></p>
</li>
<li><p>期刊：《Neural Computing and Applications》，LetPub，<a target="_blank" rel="noopener" href="https://www.letpub.com.cn/index.php?page=journalapp&amp;view=search">https://www.letpub.com.cn/index.php?page=journalapp&amp;view=search</a></p>
<blockquote>
<p>这个期刊好像不错~~</p>
</blockquote>
</li>
<li><p>作者：Sibo Cheng， Mingming Qiu</p>
</li>
<li><p>来自于Wjc老师的分享，用于<strong>2022创新基金</strong>的思考的出发点； </p>
</li>
<li><p><code>谷歌浏览器无法阅读的公式，火狐浏览器可以~~~😎，但是翻译质量没有谷歌翻译好┭┮﹏┭┮</code></p>
</li>
<li><p><code>思维流记录更好吧~</code></p>
</li>
</ul>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>Data assimilation techniques are widely used to predict complex dynamical systems with uncertainties, based on timeseries observation data. <strong>Error covariance matrices modeling</strong> is an important element in data assimilation algorithms which can considerably impact the forecasting accuracy. The estimation of these covariances, which usually relies on <strong>empirical assumptions</strong> and <strong>physical constraints</strong>, is often imprecise and computationally expensive, especially for systems of large dimensions. In this work, we propose a <strong>data-driven approach based on long short term memory (LSTM) recurrent neural networks (RNN)</strong> to improve both the accuracy and the efficiency of observation covariance specification in data assimilation for dynamical systems. </p>
<blockquote>
<ul>
<li><code>误差协方差矩阵建模是数据同化算法中的一个重要元素，它会极大地影响预测的准确性。</code></li>
<li><code>这些协方差的估计通常依赖于经验假设和物理约束，通常不精确且计算成本很高，尤其是对于大尺寸系统。</code></li>
</ul>
</blockquote>
<p>Learning the covariance matrix from observed/simulated time-series data, the proposed approach <strong>does not require any knowledge or assumption about prior error distribution</strong>, unlike classical posterior tuning methods. </p>
<blockquote>
<ul>
<li><code>与经典的后验调整方法不同，所提出的方法不需要任何关于先验误差分布的知识或假设。</code></li>
</ul>
</blockquote>
<p>We have compared the novel approach with <strong>two state-of-the-art covariance tuning algorithms, namely DI01 and D05</strong>, first in a <strong>Lorenz dynamical system</strong> and then in a <strong>2D shallow water</strong> twin experiments framework with different covariance parameterization using ensemble assimilation. </p>
<blockquote>
<ul>
<li><code>两种最先进的协方差调整算法（即 DI01 和 D05）</code></li>
<li><code>Lorenz 动力系统</code></li>
<li><code>二维浅水孪生实验</code></li>
</ul>
</blockquote>
<p>This novel method shows significant advantages in observation covariance specification, assimilation accuracy, and computational efficiency.</p>
<blockquote>
<ul>
<li><code>新方法在观测协方差规范、同化精度和计算效率方面具有显着优势。</code></li>
</ul>
</blockquote>
<h2 id="Acknowledgments"><a href="#Acknowledgments" class="headerlink" title="Acknowledgments"></a>Acknowledgments</h2><p>S.Cheng would like to thank Dr. D.Lucor, Dr. J-P.Argaud, Dr. B.Iooss, and Dr. A.Ponc¸ot for <strong>fruitful discussions about the error covariance computation</strong>. This research was supported by EDF R&amp;D. This research was partially funded by the Leverhulme Centre for Wildfires, Environment and Society through the Leverhulme Trust, grant number RC-2018-023.</p>
<h2 id="Declarations-with-code"><a href="#Declarations-with-code" class="headerlink" title="Declarations (with code)"></a>Declarations (with code)</h2><p><strong>Conflict of interest statement</strong></p>
<p>…</p>
<p><strong>Code availability</strong> </p>
<p>Code for the proposed LSTM-based covariance specification, together with DI01, D05 methods, for both Lorenz and shallow water models is available at <a target="_blank" rel="noopener" href="https://github.com/scheng1992/">https://github.com/scheng1992/</a> LSTM_Covariance.</p>
<p><strong>Contribution statement</strong></p>
<p>…</p>
<p><strong>Open Access</strong></p>
<p>…</p>
<h2 id="9-Discussion"><a href="#9-Discussion" class="headerlink" title="9 Discussion"></a>9 Discussion</h2><p>The precision of DA reconstruction/prediction depends heavily on the specification of both the background and the observation error correlation. The latter is often challenging to estimate in real-world applications because of the dynamic nature of the observation data. Furthermore, the observation matrix $\mathbf{R}$ can not be empirically estimated from an ensemble of simulated trajectories, unlike the background error covariance. In this paper, we review in detail some well-known <strong>observation covariance tuning algorithms</strong> <strong>[23, 54]</strong>, based on <strong>time-variant posterior innovation quantities</strong>. These methods, being widely adopted in geoscience, rely on some <strong>specific prior assumptions</strong> such as knowledge of the <strong>correlation structure</strong> <strong>[23]</strong> or the <strong>background matrix</strong> <strong>[24]</strong>. This is difficult to fulfill in some domains where very little knowledge about the prior error is available.</p>
<blockquote>
<ul>
<li><code>为什么？：观察矩阵 R 与背景误差协方差不同，不能从模拟轨迹的集合中凭经验估计</code></li>
<li><code>什么是？：时变后验创新量</code></li>
</ul>
</blockquote>
<p>In this study, we have proposed a novel machine learning approach based on LSTM neural networks to predict the $\mathbf{R}$ matrix using time series observation data as model input. Similar to the work of <strong>[23, 24]</strong>, $\mathbf{R}$ is assumed to be <strong>time-invariant, at least over a sufficiently long time period</strong>. Both the <strong>Kalman- and variational-type assimilation methods</strong> can benefit from the method proposed in this paper for improving the assimilation accuracy. The proposed data-driven approach also contributes to tackling <strong>one of the major bottlenecks of DA: it is time-consuming and computationally expensive to update covariance matrix, by mapping raw sensor observations to observation error covariance matrix</strong>. In both the Lorenz96 and the shallow water models presented in this paper, the LSTM-based approach displays significant strength, compared to classical posterior tuning methods DI01 and D05, in terms of: </p>
<ul>
<li>(i) estimation accuracy of the observation covariance $\mathbf{R}$; </li>
<li>(ii) reconstruction and prediction accuracy of the DA schema, using the estimated $\mathbf{R}$ matrix; </li>
<li>(iii) computational efficiency of the online covariance estimation; </li>
<li>(iv) flexibility of different model parameterization. It is worth mentioning that an important limitation of the proposed LSTM-based method is the specification of $\Phi_{\mathbf{R}}$ which defines the range of parameters for training.</li>
</ul>
<blockquote>
<ul>
<li><code>-&gt; 很强大，可以做很多这方面的工作</code></li>
</ul>
</blockquote>
<p>Since we assume that the observation matrix is timeinvariant, the proposed approach could <strong>only deal with fixed sensor placement for dynamical systems</strong>, which is also the case of DI01 and D05 tuning algorithms. The possibility of time-variant sensor placement warrants further investigation. As pointed out by <strong>[55]</strong>, the DL model can be stolen or reverse engineered, by model inversion or model extraction attack. Despite the fact that all data used in the current study is generated from <strong>toy models</strong>, it is important to ensure the data privacy when applying the model to real applications. </p>
<blockquote>
<ul>
<li><code>限制只能在空间点上进行？：只能处理动态系统的固定传感器放置</code></li>
</ul>
</blockquote>
<p>Future research should also consider applying the new method to a broader range of real-world problems, including <strong>NWP</strong>, hydrology, and object tracking, where the offline data simulation could be more computationally expensive compared to the two test models presented in this paper. To this end, future studies could also investigate <strong>the combination of model reduction methods</strong>, such as <strong>domain localization [56]</strong>, <strong>proper orthogonal decomposition</strong>, <strong>information-based data compression [57]</strong>, <strong>auto-encoder neural networks [58]</strong>, and <strong>the current covariance estimation method</strong>. More precisely, the data assimilation can be performed in the compressed low dimensional space (e.g., obtained from <strong>POD</strong> or auto-encoder). The <strong>LSTM-based</strong> covariance specification algorithm developed in this work can be used to estimate the observation error covariance matrices in the low dimensional space for improving the accuracy of reduced-order data assimilation approaches.</p>
<blockquote>
<ul>
<li><code>更广泛的现实问题</code></li>
<li><code>创新工作：为了减少计算成本，压缩的低维空间</code></li>
</ul>
</blockquote>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h2><p>In order to <strong>improve the reconstruction and prediction of dynamical systems with uncertainties</strong>, <strong>data assimilation (DA) techniques</strong>, originally developed in <strong>numerical weather prediction (NWP) [1]</strong> and geosciences [2], are widely applied to industrial problems, such as hydrology [3], wildfire forecasting [4], drought monitoring[5] and nuclear engineering [6]. </p>
<ul>
<li><p>DA algorithms aim to find the optimal approximation (also known as the analyzed state) of the state variables (usually representing a physical field of interest, such as velocity, temperature, etc.,), relying on prior estimations and real-time observations, both assumed to be noisy. Due to the large dimension (often ranging from $10^6$ to $10^{10}$ in NWP and geoscience problems), <strong>prior errors are supposed to be Gaussian distributed</strong> for the sake of simplicity [7]. As a consequence, the prior error distribution can be perfectly characterized by the <strong>first (mean) and the second (covariance)</strong> moment. </p>
<blockquote>
<p><code>DA算法：改进具有不确定性的动力系统的重建和预测，依靠先前的估计和实时观察来找到状态变量，为了简单起见，先验误差应该是高斯分布的</code></p>
</blockquote>
</li>
<li><p>The output of the DA algorithms is determined through some <strong>optimization function</strong> where <strong>the weight of prior simulations and observations is determined by the associated error covariance matrices, respectively named as background and observation covariances</strong>. </p>
<p><code>解释了DA中误差协方差矩阵的实质：模拟和观察的权重由相关的误差协方差矩阵确定，分别称为背景和观察协方差。</code></p>
</li>
<li><p>These error covariance matrices thus <strong>provide crucial information</strong> in DA algorithms [8], for not only the <strong>estimation of the analyzed state but also specifying posterior error distributions</strong> [9]. </p>
<blockquote>
<p><code>DA中误差协方差矩阵的意义：不仅用于估计分析状态，还用于指定后验误差分布</code></p>
</blockquote>
</li>
<li><p>The prior errors represented by these matrices, especially in the case of observation errors, consisting of an ensemble of different sources of noise/uncertainties, including model error, instrument noise, and representativity error [10, 11].</p>
<blockquote>
<p><code>用矩阵表示的先验误差包含哪些：模型误差、仪器噪声和代表性误差</code></p>
</blockquote>
</li>
</ul>
<p>In statistics, the covariance matrix of a random vector is often obtained via empirical estimation where <strong>a sufficient number of simultaneous samplings</strong> is required to avoid estimation bias [12]. Moreover, when the sampling number is inferior to the problem dimension, the estimated covariance will be <strong>rank deficient</strong>. In DA problems, <strong>the high dimensionality and lack of simultaneous data (i.e., several backgrounds or observation trajectories in the same time window) represent significant obstacles of covariance computation in data assimilation</strong> [13]. </p>
<blockquote>
<ul>
<li><code>DA中协方差计算的重大障碍：高维和缺乏同时数据</code></li>
</ul>
</blockquote>
<p>To overcome these difficulties, we often rely on <strong>calibration (e.g., least-square) methods based on some generic correlation kernels</strong>, often with <strong>homogeneous and isotropic characteristics</strong> [14]. </p>
<ul>
<li><p>Balanced operators can be employed for <strong>multivariate systems</strong> [15]. </p>
</li>
<li><p>In terms of correlation kernels, <strong>the family of Matérn functions</strong>, including the Exponential kernel (Matérn 1/2), the Balgovind kernel (Matérn  3/2, also known as second-order auto-regressive (SOAR) function), and the Gaussian kernel (Matérn  5/2), is often prioritized for covariance computing <strong>owing to its smoothness and capability to capture spatial correlations in physical processes</strong> [10, 16, 17]. </p>
</li>
<li><p><strong>Other stationary covariance models</strong> involve, for instance, <strong>convolution formulation</strong> [18] or <strong>diffusion-based operators</strong> [19], both contribute to an efficient storage of the covariance matrices. However, limited by homogeneous and isotropic assumptions, it remains cumbersome to represent complex spatial correlation (often multi-dimensional and multivariate) using <strong>these one-dimensional kernels</strong>.</p>
</li>
</ul>
<blockquote>
<ul>
<li><code>解决DA中协方差计算重大障碍的经典方法</code></li>
</ul>
</blockquote>
<p>In this study, we develop and test a novel data-driven approach based on recurrent neural networks (RNNs) to improve both <strong>the accuracy and the efficiency of observation covariance specification</strong> in dynamical data assimilation problems. The novel approach is tested and compared with <strong>two state-of-the-art covariance tuning algorithms</strong> in two different digital experiments with <strong>parametric and nonparametric covariance estimation</strong>, respectively.</p>
<blockquote>
<ul>
<li><code>本文创新点~，新的方法，进行同化协方差的计算~</code></li>
</ul>
</blockquote>
<p>The paper is organized as follows. In Section 2, we introduce the related work for error covariance specification. The problem statement and the contribution of this paper are described in Section 3. Data assimilation techniques and the ensemble methods are introduced briefly in Section 4. We then describe traditional posterior covariance tuning algorithms DI01 and D05 in Section 5. The novel LSTM-based method is introduced in Section 6, followed by the comparison in the Lorenz (Section 7) and the shallow water twin experiments (Section 8). We close the paper with a discussion in Section 9.</p>
<h2 id="2-Related-work"><a href="#2-Related-work" class="headerlink" title="2 Related work"></a>2 Related work</h2><p>To gain a clearer insight into covariance evolution, </p>
<ul>
<li><p>some <strong>ensemble-based methods such as [1] (NMC) and [20] (EnKF)</strong>, have been developed to provide a <strong>non-parametric covariance estimation</strong>. These methods depend on <strong>the propagation of an ensemble of simulated trajectories</strong>, initialized either at different forecasting time steps (NMC) or by adding some artificially set perturbations to the current state (EnKF). <strong>These methods are more appropriate for modeling the background matrix compared rather than the observation matrix</strong>. The latter, independent from the numerical simulations, can not be represented by the propagation of artificially added noises. </p>
</li>
<li><p><strong>The Particle-Aided Unscented Kalman Filter [21]</strong> can estimate systems with high nonlinearity with a real-time updating of the background matrix. However, the observation matrix can not be estimated directly via the Particle-Aided Unscented Kalman Filter. </p>
<blockquote>
<p><code>上面两点说明，NFC，EnKF,PAUKF,这些方法是适用于背景误差协方差的，不适用于观测误差协方差。</code></p>
</blockquote>
</li>
<li><p>In practice, the observation matrix is often set to be <strong>diagonal or spatially isotropic</strong> for the sake of simplicity (e.g. [22]). However, it is shown in the work of [10] that <strong>well-specified correlated observation covariances</strong> can significantly improve the performance of DA algorithms.</p>
<blockquote>
<p><code>这一点说明，简单的观测误差协方差是不够好的。</code></p>
</blockquote>
</li>
</ul>
<p>Several methods of <strong>data-derived posterior diagnosis</strong> have also been developed <strong>based on the analysis of innovation quantities</strong>.(The innovation quantities consist of the difference <strong>between the observations and the projected background/analyzed state in the observation space</strong>). </p>
<blockquote>
<ul>
<li><code>innovation quantities，应该是个专有名称，可能不叫创新量，可能可以在同化课程那个pdf笔记中找到相关的介绍</code></li>
</ul>
</blockquote>
<ul>
<li><p>As a strong contributor to this topic, the meteorology community developed several well-known <strong>posterior diagnoses and their improved versions</strong> [23–25] to <strong>adjust the background/observation ratio</strong>, <strong>the correlation scale length</strong>, or <strong>the full covariance structure in the observation space</strong> (both the observation matrix and the projected background matrix). </p>
</li>
<li><p>Some iterative processes [26, 27] based on the <strong>fixed-point theory</strong> have also been proposed for <strong>error covariance tuning</strong>. </p>
<p>Recent works of [28, 29] have proved the convergence of so-called <strong>Desroziers iterative methods[24] (also known as D05)</strong> in the ideal case. In brief, they have mathematically proved that, by using a semi-positive definite matrix as an initial guess, D05 iterative method converges on the <strong>exact time-invariant (at least over a sufficiently long time period) observation error covariance</strong>, when the background matrix and the transformation operator (which maps the state variables to real-time observations) are perfectly known <strong>a priori</strong>.  (Here, by the term ‘‘exact’’, we refer to the covariance truly corresponding to the remaining errors present in the observation space). </p>
<p>On the other hand, it is also mentioned by [29] that <strong>a regularization step</strong> is necessary for practice for applying D05 and the convergence of the regularized iterations remains an open question [3, 29]. </p>
</li>
<li><p>To deal with <strong>timevarying systems</strong>, <strong>lag-innovation statistics</strong> are used for error covariance estimation [30]. The essential idea is to build a secondary Kalman-filtering process for adjusting error covariances using time-shifted innovation vectors. </p>
</li>
<li><p>For <strong>more details of the innovation-based methods</strong>, we refer to the overview of [13] which also covers some other estimation methods, such as the family of <strong>likelihood-based approaches</strong> and <strong>expectation-maximum(EM) methods</strong>.</p>
</li>
</ul>
<h2 id="3-Problem-statement-and-contribution-（Q）"><a href="#3-Problem-statement-and-contribution-（Q）" class="headerlink" title="3 Problem statement and contribution （Q）"></a>3 Problem statement and contribution （Q）</h2><p>Our work lies in a similar condition of [24, 29] where both the state <strong>forward model</strong> and the <strong>transformation operator</strong> are presumed to be well known. </p>
<blockquote>
<p><code>↑ 前向模型，应该是动力模式，本文是M的斜体加粗</code></p>
<p><code>↑ 转换算子，应该是观测算子，本文是H的斜体，线性是H</code></p>
</blockquote>
<ul>
<li><p>As the main difficulty concerns the <strong>non-synchronous time-variant observations</strong> in dynamical systems (which prevents empirical estimation), in this work we propose <strong>the use of recurrent neural networks (RNNs) [31]</strong> for <strong>the specification of the observation matrix across the underlying dynamics of the observed quantities</strong>. </p>
</li>
<li><p>RNN has been widely adapted for <strong>the prediction/reconstruction of dynamical systems</strong>, especially in <strong>natural language processing (NLP)</strong> [32] and image/video processing [33] due to its convincing capacity for dealing with time series. More recently, RNN has also made their way to other engineering fields such as biomedical applications and computational fluid mechanics [34]. </p>
<blockquote>
<p><code>↑ RNN 的优点，广泛被应用</code></p>
</blockquote>
</li>
<li><p>In general, the combination of deep learning and data assimilation methods [35, 36] has been widely adapted and analyzed in a variety of industrial applications, including air pollution [37] and ocean-atmosphere modeling [38]. </p>
</li>
<li><p><strong>A convolutional neural network (CNN) for covariance estimation</strong> has also been suggested in the work of [39]. </p>
</li>
<li><p>In this study, we propose a novel methodology for <strong>LSTM-based covariance estimation</strong> which can be easily integrated into any DA schema for dynamical systems. </p>
<blockquote>
<p><code>Q：↑ 新方法，真的很容易用进去吗？~</code></p>
</blockquote>
<p>Here, we first construct a set of <strong>training covariance matrices</strong>, being either parametric or non-parametric, within a certain range defined <strong>a priori</strong>. For each matrix in the training set, we then <strong>simulate a dynamic trajectory</strong> of the observation vector relying on the knowledge of the forward model where the noises at each time step are generated following a centered Gaussian distribution characterized by the error covariance. These trajectories are later used as input variables to train the long-short-term-memory (LSTM) RNN regression model where <strong>the time-invariant observation matrices stand for the learning target</strong>. For <strong>the online evaluation</strong>, only the historical observation data is needed to predict the error covariances. </p>
<blockquote>
<p><code>↑ 新方法，实现过程</code></p>
</blockquote>
<p>Compared to traditional posterior tuning methods [24, 40] which require several implementations of DA algorithms, the proposed machine learning (ML) method can be <strong>much more computationally efficient for real-time covariance estimation</strong>. Moreover, <strong>no prior knowledge concerning either the background or the observation matrix</strong> is necessary for the proposed ML approach unlike most of the traditional methods. For example, DI01 [23] requires precise knowledge of correlation structures for both background and observation matrices while D05 [24] make use of the perfect knowledge of the background covariance.</p>
<blockquote>
<p><code>↑ 新方法，与传统方法的对比，新方法的优势</code></p>
</blockquote>
</li>
</ul>
<p>In order to make a comprehensive comparison with traditional methods, <strong>two different twin experiment frameworks</strong> are implemented in this paper, using respectively <strong>the Lorenz96 and the 2D shallow-water models</strong>. </p>
<ul>
<li><p>The Lorenz system, characterized by only three state variables, is associated with <strong>a non-parametric covariance modeling</strong> while we use <strong>an isotropic correlation kernel</strong> to parameterize the observation matrix in the shallow water dynamics. </p>
<blockquote>
<p><code>↑ 非参数化方法和各向同性相关核，两种方法的区别？</code></p>
</blockquote>
</li>
<li><p>In both cases, we compare the performance of the proposed <strong>LSTM-based method</strong> against the state-of-the-art tuning approaches D05 and DI01 in terms of both the covariance specification and the posterior DA accuracy. </p>
</li>
<li><p>An <strong>ensemble DA schema</strong> is used for estimating t<strong>he time-variant background matrix</strong> for each of these methods.</p>
<blockquote>
<p><code>↑ 选取的是集合DA方法，估计时变背景矩阵</code></p>
</blockquote>
</li>
</ul>
<h2 id="4-Data-assimilation-（Q）"><a href="#4-Data-assimilation-（Q）" class="headerlink" title="4 Data assimilation （Q）"></a>4 Data assimilation （Q）</h2><h3 id="4-1-Principle-of-data-assimilation-（Q）"><a href="#4-1-Principle-of-data-assimilation-（Q）" class="headerlink" title="4.1 Principle of data assimilation （Q）"></a>4.1 Principle of data assimilation （Q）</h3><blockquote>
<p><code>在markdown中如何加入上标、下标？：</code></p>
<p><code> 用公式，网页翻译会出问题，不用公式的方法 https://www.jianshu.com/p/13b3366f0260</code></p>
</blockquote>
<p>The objective of data assimilation algorithms is to approach the estimation of system’s states <strong>x</strong> to its true values <strong>x<sub>true</sub></strong>, also known as the true state, by taking advantage of <strong>two sources of information</strong>: </p>
<ul>
<li>the prior estimation or forecast <strong>x<sub>b</sub></strong>, which is also called the background state, </li>
<li>and the measurement or observation <strong>y</strong>. </li>
</ul>
<p>DA algorithms aim to find an optimally weighted compromise between <strong>x<sub>b</sub></strong> and <strong>y</strong> by minimizing the lost function <em><strong>J</strong></em> defined as:</p>
<blockquote>
<p><code>Q：↓ 为什么J是这个形式？</code></p>
</blockquote>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225144725.png" style="zoom:72%;">

<p>where <em><strong>H</strong></em> denotes the transformation operator from the state space to observation space. <strong>B</strong> and <strong>R</strong> are, respectively, the background and the observation error covariance matrices, i.e.</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225150048.png" style="zoom:72%;">

<p>Errors <strong>ε<sub>b</sub>, ε<sub>y&nbsp;</sub></strong> are supposed to be <strong>centered Gaussian</strong> following:</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225150304.png" style="zoom:72%;">

<blockquote>
<p><code>↑ 假设1：高斯分布</code></p>
</blockquote>
<p>In <strong>Eq 1</strong>, the left side strives for incorporating the prior information <strong>x<sub>b</sub></strong> , and the right side penalizes the difference between the observation <strong>y</strong> and the state variables after having been mapped to the observation space <em><strong>H(x)</strong></em> . Both terms are weighted by the corresponding inverse of error covariance matrix (<strong>B<sup>-1</sup></strong>, <strong>R<sup>-1</sup></strong>) to <strong>reflect confidences for each of them</strong>.</p>
<p>The optimization problem of <strong>Eq 1</strong>, so called <strong>three-dimensional variational (3D-Var)</strong> formulation, is a general representation of variational assimilation which <strong>does not take into account model errors</strong>. The output of <strong>Eq 1</strong> is denoted as <strong>x<sub>a</sub></strong>, i.e.</p>
<blockquote>
<p><code>↑ Q：模式误差，是什么？</code></p>
</blockquote>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225150829.png" style="zoom:72%;">

<p>If <em><strong>H</strong></em> is the <strong>linear observation operator</strong> represented by <strong>H</strong> , <strong>Eq 6</strong> can be solved via <strong>BLUE (Best Linearized Unbiased Estimator)</strong> formulation:</p>
<blockquote>
<p><code>↑ 假设2：线性观测算子</code></p>
</blockquote>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225151004.png" style="zoom:72%;">

<p>where <strong>A</strong> =Cov( <strong>x<sub>a</sub></strong>- <strong>x<sub>true</sub></strong>) is the analyzed error covariance, and <strong>K</strong> is the <strong>Kalman gain matrix</strong> described by </p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225151432.png" style="zoom:72%;">

<p>In the rest of this paper, we define <strong>H</strong> as a linear transformation operator. Nevertheless, it is usually more challenging to find the minimum of <strong>Eq 1</strong> when <strong>H</strong> is nonlinear, even more, challenging when states are high-dimensional. The solution for the minimization often involves <strong>gradient descent algorithms such as ‘‘L-BFGS-B’’ [41] or adjoint-based [42] numerical techniques</strong>.</p>
<p>DA algorithms could be <strong>applied to dynamical systems thanks to sequential applications</strong> expressed by a transition operator  <strong><em>M</em><sub>t<sup>k</sup>→t<sup>k+1</sup></sub></strong> (from discrete time <strong>t<sup>k</sup> to t<sup>k+1</sup></strong>), where</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225152151.png" style="zoom:78%;">

<p><strong>x<sub>b,t<sup>k+1</sup></sub></strong> thus depends on the knowledge of <strong><em>M</em><sub>t<sup>k</sup>→t<sup>k+1</sup></sub></strong> and the DA correcting state <strong>x<sub>a,t<sup>k</sup></sub></strong> , i.e.</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225152602.png" style="zoom:78%;">

<p>Obviously, the more accurate <strong>x<sub>a,t<sup>k</sup></sub></strong>  is, the more reliable <strong>x<sub>b,t<sup>k+1</sup></sub></strong> would be.</p>
<p>To leverage the information embedded in the background state and observations, <strong>covariance matrices modeling is a pivotal point in DA</strong> as they influence not only how prior errors spread but may also change the DA results [26].</p>
<h3 id="4-2-Ensemble-methods-（Q）"><a href="#4-2-Ensemble-methods-（Q）" class="headerlink" title="4.2 Ensemble methods （Q）"></a>4.2 Ensemble methods （Q）</h3><p><strong>Ensemble data assimilation (EnDA)</strong> [43, 44] methods have shown a strong performance in dealing with <strong>non-linear chaotic DA systems</strong> by creating <strong>an ensemble with size</strong> <em>M</em> <strong>of the system state</strong> depicted as:</p>
<blockquote>
<p><code>↑ M斜体加粗是动力系统，M斜体未加粗是系统状态集合的大小</code></p>
<p><code>↓ 系统状态集合，理解深点</code></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225162140.png"></p>
<ul>
<li><p><strong>The latter</strong> is used to represent both the prior and the posterior probability distribution of the state variables. </p>
<blockquote>
<p><code>Q：↑ 后者，指的是哪个？</code></p>
</blockquote>
</li>
<li><p>The system states of the ensemble evolve under  <strong><em>M</em><sub>t<sup>k</sup>→t<sup>k+1</sup></sub></strong> and DA is applied to each of these ensemble states at <strong>every assimilation windows</strong>. </p>
<blockquote>
<p><code>↑ 意思指的是，对系统状态集合中的每一个系统状态都进行同化</code></p>
</blockquote>
</li>
<li><p>Furthermore, instead of evolving the system to obtain the <strong>B</strong> matrix, which is a time and computationally expensive process when a large number of states is available, <strong>B</strong> is estimated as a sample covariance:</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225161222.png" alt=" " style="zoom:78%;">

<p>where</p>
<p><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225161336.png"></p>
<p>and the estimation becomes <strong>more reliable with the increases of</strong> <em>M</em> . </p>
</li>
<li><p>For applications in this study, EnDA, with a sufficiently large number of examples, is used to estimate <strong>x<sub>b,t<sup>k</sup></sub></strong>  and <strong>B<sub>b,t<sup>k</sup></sub></strong>  so that we can focus on the comparison of <strong>R</strong> matrix modelings.</p>
</li>
</ul>
<h3 id="4-3-Observation-error-covariances-specification"><a href="#4-3-Observation-error-covariances-specification" class="headerlink" title="4.3 Observation error covariances specification"></a>4.3 Observation error covariances specification</h3><p>For the estimation of <strong>R</strong>, under the assumption that the system model is stationary, </p>
<blockquote>
<p><code>↑ 假设3：系统模型平衡</code></p>
</blockquote>
<ul>
<li><p>a wide variety of methods have been explored, for example, the DI01 [23] method which adjusts accordingly the ratio between <em>Tr</em>(<strong>B</strong>) and <em>Tr</em>(<strong>R</strong>) and the D05 [24] approach which estimates the full observation space iteratively. </p>
<p>However, these methods, based on posterior innovation quantities (i.e., <strong>y</strong> - <strong><em>H</em>(x<sub>a</sub>)</strong>) which requires several applications of DA algorithms, can be <strong>computationally expensive</strong>. </p>
<p>Moreover, these tuning methods, especially the D05 which estimates the full matrix, are <strong>not suitable for different matrix parameterizations</strong>. </p>
</li>
<li><p>In this paper, working with time-series observation data, we use LSTM to predict the corresponding <strong>R</strong> matrix under similar assumptions of DI01 and D05. The two classical methods, introduced in Section 5, are implemented to compare the results with the proposed machine learning approach.</p>
</li>
</ul>
<h2 id="5-Posterior-covariance-tuning-algorithms"><a href="#5-Posterior-covariance-tuning-algorithms" class="headerlink" title="5 Posterior covariance tuning algorithms"></a>5 Posterior covariance tuning algorithms</h2><h3 id="5-1-Desroziers-and-Ivanov-DI01-tuning-algorithm-（Q）"><a href="#5-1-Desroziers-and-Ivanov-DI01-tuning-algorithm-（Q）" class="headerlink" title="5.1 Desroziers and Ivanov (DI01) tuning algorithm （Q）"></a>5.1 Desroziers and Ivanov (DI01) tuning algorithm （Q）</h3><p>Because <strong>B</strong> and <strong>R</strong> determine the weight of background and observation information in the loss function ( <strong>Eq 1</strong>), the knowledge of Tr(<strong>B</strong>) and Tr(<strong>R</strong>) is crucial to DA accuracy. </p>
<blockquote>
<p><code>Q：↑ 为什么B和R矩阵的Tr()很重要？</code></p>
</blockquote>
<p><strong>DI01 [23] tuning algorithm</strong>, relying on the diagnosis of <strong>innovation quantities</strong>, has been widely adopted in meteorology [28, 45] and geoscience [46]. Consecutive works have been carried out to improve its performance and feasibility in problems of large dimensions [47]. Without modifying error correlation structures, DI01 adjusts the prior error amplitudes by applying an iterative fixed-point procedure.</p>
<blockquote>
<p><code>Q：↑ DI01的验证指标是创新量（增益量），0，？</code></p>
</blockquote>
<p>As demonstrated in [23, 48], when <strong>B</strong> and <strong>R</strong> are perfectly specified,</p>
<blockquote>
<p><code>Q: ↑ 需要 B 和 R 被预先指定，那 DI01 做什么？</code></p>
</blockquote>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225202325.png" style="zoom:93%;">

<p>where <strong>H</strong> is a linearized observation operator. Based on <strong>Eqs 13 and 14</strong> it is possible to iteratively correct the magnitudes of <strong>B</strong> and <strong>R</strong>, following</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225202444.png" style="zoom:93%;">

<p>using the two indicators</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225202603.png" style="zoom:93%;">

<p>where <em>q</em> is the current iteration.</p>
<p>Acting as scaling coefficients, the sequences {<em>s</em><sub><em>b,q</em></sub>} and {<em>s</em><sub><em>o,q</em></sub>} modify the error variance magnitude in the iterative process. It is worth reminding that both the analyzed state <strong>x<sub>a</sub></strong> and the gain matrix <strong>K<sub><em>q</em></sub></strong> are obtained using <strong>B<sub><em>q</em></sub></strong> ,  <strong>R<sub><em>q</em></sub></strong>  which depend on <em>s</em><sub><em>b,q</em></sub> and <em>s</em><sub><em>o,q</em></sub>. When the correlation patterns of both <strong>B</strong> and <strong>R</strong> are well known, <strong>DI01 is equivalent to a maximum-likelihood parameter tuning</strong>, as pointed out in [28, 47].</p>
<p>Unlike other posterior covariance diagnosis/computations, such as [24, 26], the estimation of the full matrices is not needed in DI01. Instead, <strong>only the estimation of two scalar values (<em>J</em><sub>b</sub>, <em>J</em><sub>o</sub>) is required</strong>, which significantly <strong>reduce the computational cost</strong>. As a consequence, <strong>this method could be more appropriate for online covariance tuning</strong>.</p>
<blockquote>
<p><code>Q: ↑ DI01为什么不需要对整个矩阵进行估计？因为增益是验证指标吗？</code></p>
</blockquote>
<h3 id="5-2-Desroziers-iterative-method-D05-in-the-observation-space"><a href="#5-2-Desroziers-iterative-method-D05-in-the-observation-space" class="headerlink" title="5.2 Desroziers iterative method (D05) in the observation space"></a>5.2 Desroziers iterative method (D05) in the observation space</h3><p><strong>The Desroziers diagnosis (D05)</strong>[24], subject to prior and posterior state-observation residuals has been widely applied in engineering problems, including numerical weather prediction[28] and hydrology [3]. The work of [24] proved that when <strong>B</strong> and <strong>R</strong> are well known <strong>a priori</strong>, the expectation of the analysis state should satisfy:</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225203904.png" style="zoom:95%;">

<p>The difference between the left side and the right side of <strong>Eq 18</strong>,</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225203956.png" style="zoom:95%;">

<blockquote>
<p><code>↑ D05迭代方法的收敛指标，当收敛时，趋近0</code></p>
</blockquote>
<p>can be used as a validation indicator of the <strong>R</strong> matrix estimation where ||.||<sub><em>F</em></sub>  denotes the Frobenius norm. Applying this method, time variant observation/background data can contribute to the estimation of the <strong>R</strong> matrix because the expectation in <strong>Eq 18</strong> could be evaluated using residuals at different time steps. When the <strong>B</strong> matrix is well known, an iterative process has been introduced to estimate the <strong>R</strong> matrix:</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225204210.png" style="zoom:95%;">

<blockquote>
<p><code>↑ D05迭代方法要求 B 矩阵已知~</code></p>
</blockquote>
<p>based on the fixed-point theory [29]. The current analysis state <strong>x<sub><em>a,q</em></sub></strong> is obtained using the specification of  <strong>R<sub><em>q</em></sub></strong> while  <strong>x<sub><em>b</em></sub></strong> , <strong>B</strong>,  <strong>y</strong> remains invariant. As proved in [28, 29], under the assumption of sufficient observation data and well known <strong>B</strong> matrix, the iterative process of <strong>Eq 20</strong> converges to the exact observation error covariance. However, as shown in [29], the intermediate matrices <strong>R<sub><em>q</em></sub></strong>  could be non-symmetric and possibly contain negative or complex eigenvalues, which is cumbersome for DA algorithms to deal with.</p>
<p>In practice, a posterior regularization at each iteration step is often required to ensure the positive definiteness of <strong>R<sub><em>q</em></sub></strong> [29] where the first step of the regularization could be symmetrizing the estimated <strong>R<sub><em>q</em></sub></strong>  matrix, i.e.,</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225204611.png" style="zoom:96%;">

<p>The spectrum of  <strong>R<sub><em>q</em></sub></strong>  now contains only real numbers but they are not necessarily positive. The hybrid method[2] is a standard approach in ensemble-based DA methods to ensure the positive definiteness, which consists of combining a prior defined covariance matrix <strong>C</strong> with the one obtained from empirical estimation. We thus obtain the formulation of the regularized observation matrix  <strong>R<sub>r,n</sub></strong> :</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225204748.png" style="zoom:95%;">

<blockquote>
<p><code>↑ 正则化，为了满足正定性（实数）+非负性，</code></p>
</blockquote>
<p>following <strong>Eq 21</strong> with μ∈(0,1). The matrix <strong>C</strong> is often set as a diagonal matrix since it helps to enhance the matrix conditioning. In this work, we choose to set</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225204913.png" style="zoom:95%;">

<blockquote>
<p><code>↓ 正则化的观测矩阵收敛性仍未解决~</code></p>
</blockquote>
<p>so that <em>Tr</em>(<strong>R<sub><em>q</em></sub></strong>) will not be modified due to the post regularization. As mentioned in the discussion of [3, 29], <strong>the convergence of regularized observation matrices remains an open question</strong>. Therefore, a small iteration number is often assigned for D05 tuning in industrial problems (e.g., <em>q</em> = 2 in [3, 49]). Since the right side of <strong>Eq 20</strong> can be estimated using residual quantities at different time steps, D05 is often used to <strong>deal with time series observation data</strong> (e.g., [3, 49]) when assuming the <strong>R</strong> matrix is time-invariant.</p>
<h2 id="6-LSTM-for-error-covariance-estimation"><a href="#6-LSTM-for-error-covariance-estimation" class="headerlink" title="6 LSTM for error covariance estimation"></a>6 LSTM for error covariance estimation</h2><h3 id="6-1-Introduction-of-RNN-and-LSTM"><a href="#6-1-Introduction-of-RNN-and-LSTM" class="headerlink" title="6.1 Introduction of RNN and LSTM"></a>6.1 Introduction of RNN and LSTM</h3><p>LSTM, first introduced in [50], is a kind of RNN [31], capable of solving <strong>long-term dependency problems</strong> [51] that traditional RNN could not handle. As with other recurrent neural networks, LSTM has a chain-like structure. This structure is created by repeating the same module shown on the left side in <strong>Fig. 1</strong>. In addition, the repeating module comprises four neural networks instead of only one. The specific structure of the <strong>repeating module</strong> is on the right side in <strong>Fig. 1</strong>.</p>
<blockquote>
<p><code>↑ 李宏毅老师的视频对RNN，讲的很详细~ </code></p>
</blockquote>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225211508.png" style="zoom:100%;">

<p>An essential part of LSTM is the <strong>cell state</strong> C<sub><em>t<sup>k-1</sup></em></sub>  which is the long-term memory storing information about past behaviors. LSTM uses <strong>three gates</strong> with each composed out of <strong>a sigmoid layer neural network</strong> (single layer neural network with sigmoid activation function at the output layer) and a <strong>pointwise multiplication operation</strong>, to protect and control information of the cell state as shown in <strong>Fig. 1</strong>.</p>
<p><strong>The first gate is the forget gate</strong> following:</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225211732.png" style="zoom:95%;">

<p>where the <strong>recurrent variable</strong> h<sub><em>t<sup>k-1</sup></em></sub> summarizing all the information about past behaviors,  x<sub><em>t<sup>k</sup></em></sub>  resuming information about current behaviors, and  W<sub><em>f</em></sub>  and <em>b</em><sub><em>f</em></sub>  are weights and bias, respectively, parameterizing the sigma layer neural network.  The forget gate decides what kind of information is going to be ignored in C<sub><em>t<sup>k-1&nbsp;</sup></em></sub>.</p>
<p><strong>The second gate is the input gate</strong>, and it determines which new information is added into C<sub><em>t<sup>k-1</sup></em></sub> . This new information, $\tilde{\mathbf{C}}_{t^{k}}$, as conforming to</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225212609.png" style="zoom:95%;">

<p>is attained by passing h<sub><em>t<sup>k-1</sup></em></sub> and x<sub><em>t<sup>k</sup></em></sub> to a tanh layer neural network (single layer neural network with tanh activation function at the output layer) with parameters W<sub><em>c</em></sub>  and <em>b</em><sub><em>c</em></sub> .</p>
<p>$\tilde{\mathbf{C}}_{t^{k}}$ is then multiplied by weight coefficients i<sub><em>t<sup>k</sup></em></sub>  which is acquired by the input gate, i.e.,</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225212927.png" style="zoom:95%;">

<p>i<sub><em>t<sup>k</sup></em></sub> is applied to decide which new information would be employed to update C<sub><em>t<sup>k-1</sup></em></sub>.</p>
<p>Hence, the state cell C<sub><em>t<sup>k</sup></em></sub> at the current time step <em>t<sup>k</sup></em> can be attained using</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225213116.png" alt=" " style="zoom:95%;">

<p>Finally, the acquisition of h<sub><em>t<sup>k</sup></em></sub> requires the participation of the output gate and a tanh activation function: first, the tanh activation function <em>tanh</em> is used to create a cell state candidate information <em>tanh</em>(C<sub><em>t<sup>k</sup></em></sub>). <em>tanh</em>(C<sub><em>t<sup>k</sup></em></sub>) is then multiplied by some weight coefficients following</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225213356.png" alt=" " style="zoom:95%;">

<p>to decide which information of  <em>tanh</em>(C<sub><em>t<sup>k</sup></em></sub>)  would contribute to the obtainment of  h<sub><em>t<sup>k</sup></em></sub>  . Among them, o<sub><em>t<sup>k</sup></em></sub>, is generated by the output gate with neural network parameters  W<sub><em>o</em></sub>  and <em>b</em><sub><em>o</em></sub> , i.e.,</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225213556.png" style="zoom:95%;">

<h3 id="6-2-LSTM-for-R-matrix-estimation-using-time-series-observation-data-Q"><a href="#6-2-LSTM-for-R-matrix-estimation-using-time-series-observation-data-Q" class="headerlink" title="6.2 LSTM for R matrix estimation using time series observation data (Q)"></a>6.2 LSTM for R matrix estimation using time series observation data (Q)</h3><p>The tuning methods presented in Section 5 have been applied in various engineering applications with significant improvement of covariance specification and DA accuracy. However, these methods which require several applications of DA algorithms can be computationally expensive for high-dimensional problems. Another important drawback stands for the requirement of precise knowledge on either the <strong>correlation patterns</strong> of <strong>B</strong> and <strong>R</strong> (for DI01) or the full <strong>B</strong> matrix (for D05). </p>
<blockquote>
<p><code>Q: ↑ 还是不能理解 DI01 做什么？correlation pattern 是 full matrix吗？</code></p>
</blockquote>
<p>In this study, we aim to build a data-driven surrogate model for efficient online <strong>R</strong> matrix specification using LSTM. Unlike DI01 or D05, no specific knowledge about the error covariances or the state/observation dynamical systems other than the transformation operator <em><strong>H</strong></em> and the forward model  <strong><em>M</em><sub>t<sup>k</sup>→t<sup>k+1</sup></sub></strong> (which is also indispensable for standard DA algorithms including variational methods and Kalman-filters) is required.</p>
<blockquote>
<p><code>↑ 指出了本算法的需要，观测算子、前向模型，不需要，B和R的相关特定信息</code></p>
<p><code>😎~win+. emoji表情包</code></p>
</blockquote>
<h4 id="Algorithm-1：Simulated-observations-generating-process"><a href="#Algorithm-1：Simulated-observations-generating-process" class="headerlink" title="Algorithm 1：Simulated observations generating process"></a>Algorithm 1：Simulated observations generating process</h4><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226134527.png" style="zoom:67%;">

<p><strong>our main idea is to build a training set for the specific problem</strong>, including predefined time-invariant observation matrices {$\mathbf{R}^{[\text{iter}]}$}  within certain range and generated dynamical observation vector {$\mathbf{y}_{t^{k}}^{[\text {iter }]}$}.  </p>
<blockquote>
<p><code>↑ 算法1：目的</code></p>
</blockquote>
<p>Setting the dynamical observations {$\mathbf{y}_{t^{k}}^{[\text {iter }]}$} as the system input and the <strong>R</strong> matrices as output, <strong>LSTM networks are used to learn the error distribution across the underlying observation dynamics</strong>.</p>
<blockquote>
<p><code>↑ 算法1：和LSTM的联系，LSTM的输入，输出，LSTM作用</code></p>
</blockquote>
<p>More precisely, a real function $g^{\mathbf{R}}(.): \Phi_{\mathbf{R}} \longrightarrow \mathbb{R}^{m \times m}$ is predefined where $\Phi_{\mathbf{R}}$ is an empirically estimated real space which <strong>defines the range of a set of parameters, such as marginal error variance, correlation scale length [18]</strong> for computing the <strong>R</strong> matrices. The generated observation matrices {$\mathbf{R}^{[\text{iter}]}$}  are set to be <strong>symmetric positive definite (SPD)</strong> thanks to the function $g^{\mathbf{R}}(.)$. Both $g^{\mathbf{R}}(.)$ and $\Phi_{\mathbf{R}}$ vary for different applications.</p>
<blockquote>
<p><code>↑ 算法1：介绍了</code>$\Phi_{\mathbf{R}}$，<code>生成的R是对称正定的</code></p>
</blockquote>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226133013.png" alt=" " style="zoom:67%;">

<blockquote>
<p><code>↑ 算法1：核心求解公式</code></p>
</blockquote>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226114331.png" alt=" " style="zoom:67%;">

<blockquote>
<p><code>↑ 算法1：完整的观测模拟生成过程；</code></p>
</blockquote>
<h4 id="Algorithm-2-LSTM-training-and-validation-process"><a href="#Algorithm-2-LSTM-training-and-validation-process" class="headerlink" title="Algorithm 2: LSTM training and validation process"></a>Algorithm 2: LSTM training and validation process</h4><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226133421.png" style="zoom:67%;">

<p><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226133548.png"></p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226133810.png" style="zoom:67%;">

<p><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226134947.png"></p>
<p>Different from classical covariance tuning algo-rithms, the LSTM network only makes use of historical observation data, requiring neither the background states nor the error covariance matrix. The advantage of using LSTM is more salient <strong>when the observation dimension is large</strong>, for example, millions or even billions, while such dimension is not uncommon in real-world applications [2, 7].</p>
<p>To estimate <strong>R</strong>, LSTM is first trained to learn: <strong>related variables</strong></p>
<ul>
<li>– <strong>either</strong> which can be used to constitute the symmetry observation error covariance matrix (i.e., input variables of the g<sup>R</sup>(.) function) <strong>in a parametric modeling</strong>;</li>
<li> –<strong>or</strong> elements of the <strong>R</strong> matrix (e.g., variables in the upper triangle and those in the diagonal of the covariance matrix) <strong>in a non-parametric modeling</strong>. </li>
</ul>
<p>The whole process for <strong>R</strong> estimation using LSTM is described in <strong>Algorithm 2</strong>.</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226140352.png" style="zoom:100%;">

<p>In Algorithm 2, it is suggested that LSTM training process is consisted of <strong>training and validation processes</strong>: </p>
<ul>
<li><p><strong>the training process</strong> is comprised of the forward prediction and the backward neural network weight parameters updating processes; </p>
</li>
<li><p>and <strong>validation process</strong> is used to predict desirable outputs or objectives and then calculate validation loss between predicted output and prior true output values. </p>
</li>
<li><p><strong>N_epoch</strong> indicates the number of times that the entire example data set is passed forward and backward through the LSTM during the training process. </p>
</li>
<li><p><strong>Early stopping</strong>, which terminates the training process when the validation loss reaches the minimum and is always the minimum value after N_patience_epoch epochs, is applied to reduce the LSTM training time.</p>
</li>
</ul>
<p>It is important to note that the offline data generation and LSTM training processes need to be carried out individually for different DA applications (<strong>Fig 4</strong>).</p>
<p><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226140509.png"></p>
<h2 id="7-Lorenz-twin-experiment"><a href="#7-Lorenz-twin-experiment" class="headerlink" title="7 Lorenz twin experiment"></a>7 Lorenz twin experiment</h2><h3 id="7-1-Twin-experiment-principle"><a href="#7-1-Twin-experiment-principle" class="headerlink" title="7.1 Twin experiment principle"></a>7.1 Twin experiment principle</h3><p>In order to overcome the drawback that, in a realistic experiment, <strong>x</strong><sub>true</sub> is usually unknown and <strong>y</strong> is often mixed with noises, twin experiment, in which a prototypical test case is selected to simulate real situations, is applied so as to provide <strong>x</strong><sub>true</sub> for comparison. </p>
<blockquote>
<p><code>↑ 解释了什么是孪生实验</code></p>
</blockquote>
<p>In this experiment, a mapping is applied to some sampling true trajectory <strong>x</strong><sub>true,<em>t<sup>k</sup></em></sub> at some points in space and time and arbitrary random noises are added to obtain simulated raw measurements  <strong>y</strong><sub><em>t<sup>k</sup></em></sub>  . DA is then implemented starting from the initial background state <strong>x</strong><sub>b,<em>t<sup>0</sup></em></sub> representing the prior information that could be obtained about corresponding state <strong>x</strong><sub>true,<em>t<sup>0</sup></em></sub>  , along with initial raw measurement  <strong>y</strong><sub><em>t<sup>0</sup></em></sub>  . The output state is then compared against <strong>x</strong><sub>true</sub> , verifying the distance of these two states and minimizing it to evaluate and improve the performance of DA. </p>
<p>In this section, we use a twin experiment to evaluate the performance of applying DA to a simple Lorenz system in which raw measurement error covariance is estimated/adjusted using, respectively, DI01, D05 and LSTM.</p>
<h3 id="7-2-Experiment-set-up-（Q）"><a href="#7-2-Experiment-set-up-（Q）" class="headerlink" title="7.2 Experiment set up （Q）"></a>7.2 Experiment set up （Q）</h3><p>The Lorenz system, first studied by Edward Lorenz, is a system of ordinary differential equations. For certain parameter values and initial conditions, the Lorenz system is notable for having chaotic solutions, in particular the Lorenz attractor, toward which a system tends to evolve. The Lorenz 96 system[52] has been widely used as a prototypical test case to compare the performance of DA algorithms[34, 35, 53]. </p>
<blockquote>
<p><code>↑ 洛伦兹系统广泛应用于DA中</code></p>
</blockquote>
<p>Here we build a twin experiment framework with a simple three dimensional Lorenz system in which the state vector is denoted as <strong>x</strong>=[x<sub>(0)</sub>, x<sub>(1)</sub>, x<sub>(2)</sub>]. The studied <strong>Lorenz system</strong> can be characterized as:</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226143503.png" style="zoom:95%;">

<!--- The initial values of the true state **x**<sub>true,*t<sup>0</sup>*</sub> are set to be [0, 1, 1.05] while the initial background state **x**<sub>b,*t<sup>0</sup>*</sub> is generated by combining **x**<sub>true,*t<sup>0</sup>*</sub> with a centered Gaussian noise **ε**<sub>*b,t<sup>0</sup>*</sub> : <img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226144151.png" style="zoom:95%;" /> Then both of true states  **x**<sub>true</sub> ={**x**<sub>true,*t<sup>0</sup>*</sub>,...,**x**<sub>true,*t<sup>T</sup>*</sub> } and background states  **x**<sub>b</sub> ={ **x**<sub>b,*t<sup>0</sup>*</sub> ,..., **x**<sub>b,*t<sup>T</sup>*</sub> } of the Lorenz system evolve by conforming, respectively, to the Lorenz equation in Eq 32 until t=1s with total *T* =1000 time steps.  -->

<p>initial true state, initial background state →(Lorenz) true state, background</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226144836.png" alt="  " style="zoom:95%;">

<p>observations ← observation operator, noise</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226145209.png" style="zoom:95%;">

<p><strong>EnDA</strong> is then applied in this twin experiment to update the background ensemble using available observations.</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226150001.png" style="zoom:95%;">

<blockquote>
<p><code>Q：↑ 同化窗口是 10 个时间步吗？</code></p>
</blockquote>
<h3 id="7-3-DA-with-LSTM-based-covariance-estimation"><a href="#7-3-DA-with-LSTM-based-covariance-estimation" class="headerlink" title="7.3 DA with LSTM-based covariance estimation"></a>7.3 DA with LSTM-based covariance estimation</h3><p><strong>R</strong> matrix generation</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226151107.png" style="zoom:95%;">

<blockquote>
<p> ↑ 参数化<strong>R</strong>生成对称正定矩阵的网站：<a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_spd_matrix.html">https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_spd_matrix.html</a></p>
</blockquote>
<p>the input, output and structure of <strong>LSTM function</strong></p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226152701.png" style="zoom:90%;">

<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226153047.png" style="zoom:75%;">

<p>LSTM1000 and LSTM200：</p>
<blockquote>
<p>↑  In this Lorenz twin experiment, two LSTM networks, respectively named as <strong>LSTM1000 and LSTM200</strong> are designed with different input sizes of times series data. LSTM1000 is trained on a total of 1000 time steps for predicting the R matrix while LSTM200 makes use of only the first 200 time steps to simulate a realistic application where the time-invariant R matrix is estimated using historical data for improving future DA performance. The evaluation of both LSTM1000 and LSTM200, in terms of DA accuracy, is made using the full test dataset with 1000 times steps. By leveraging the LSTM model along with available observations, we can still perform DA algorithms even though R is not explicitly given. The results are then compared with the ones obtained using the exact R matrix.</p>
</blockquote>
<h3 id="7-4-Results"><a href="#7-4-Results" class="headerlink" title="7.4 Results"></a>7.4 Results</h3><p>Prediction results of the <strong>non-parametric error covariance</strong> and the true values：</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226155018.png" style="zoom:67%;">

<p><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226155112.png"></p>
<p>The averaged DA performance </p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226163134.png" style="zoom:80%;">

<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226163708.png" style="zoom:80%;">

<p><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226163826.png"></p>
<p><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226163916.png"></p>
<blockquote>
<p>↑ <code>averaged</code> 是因为EnDA有100个背景轨迹；</p>
</blockquote>
<h2 id="8-Application-to-shallow-water-equations"><a href="#8-Application-to-shallow-water-equations" class="headerlink" title="8 Application to shallow water equations"></a>8 Application to shallow water equations</h2><h3 id="8-1-Experiment-setup"><a href="#8-1-Experiment-setup" class="headerlink" title="8.1 Experiment setup"></a>8.1 Experiment setup</h3><p>For further evaluating the performance of error covariance estimation using LSTM when incorporated with predefined correlation kernels, we also set up a twin experiment framework with <strong>a simplified 2D shallow-water dynamical model</strong>, which is frequently used for <strong>testing data assimilation algorithms</strong> ( e.g., [26, 42]). </p>
<p>A cylinder of water is positioned in the middle of the study field with size 20<em>mm</em> × 20<em>mm</em> and released at the initial time step <em>t<sup>k</sup>=t<sup>0</sup></em> s (i.e., with no initial speed), leading to a non-linear wave-propagation. The dynamics of the water level <em>h</em> (in <em>mm</em>), as well as the horizontal and vertical velocity field (respectively denoted as <em>u</em> and <em>v</em> in 0.1<em>m/s</em>), is given by the nonconservative shallow water equations,</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220227201158.png" style="zoom:80%;">

<blockquote>
<p><code>↑ 潜水模型</code></p>
</blockquote>
<p>The evolution of the reference state (x<sub>true</sub>), together with the error-free model <strong>equivalent observations</strong> (i.e., H(x<sub>true</sub>)), is illustrated in <strong>Fig 8</strong>. </p>
<p><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220227201917.png"></p>
<p>Spatially <strong>correlated prior observation errors</strong> are generated artificially and combined with the transformation operator to simulate real-time observations. More precisely, the observations are generated from the model equivalent  H(x<sub>true</sub>) <strong>separately for the fields u and v</strong>. H is defined as a <strong>sparse matrix to imply the fact that measurements in real-world applications are sparser than true states</strong> due to the interference existing in the former situations as well as the limited performances of sensors.</p>
<blockquote>
<p><code>↑ 这里对H算子与观测的关系说的非常到位，对H算子的稀疏性也讲的很好</code></p>
</blockquote>
<p>As shown in <strong>Fig 7</strong>, the spatial observations at time <em>t<sup>k</sup></em> is defined as the average of u<sub><em>t<sup>k</sup></em></sub> and v<sub><em>t<sup>k</sup></em></sub>  in a 2 × 2 cells area with an observation error ε<sub>y<sub><em>t<sup>k</sup></em></sub></sub> ,</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220227204749.png" alt=" " style="zoom:80%;">

<p>and identical for y<sub><em>v,i,j,t<sup>k</sup></em></sub> . </p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220227204957.png" style="zoom:80%;">

<p>Therefore, the dimension of the observation vector y = [ y<sub><em>u,t<sup>k</sup></em></sub>, y<sub><em>v,t<sup>k</sup></em></sub>] is 200.</p>
<blockquote>
<p><code>↑ 上面介绍的是某一时刻的观测是什么，H 观测算子依此构建</code></p>
</blockquote>
<p>In this experiment, we suppose that the observation error  ε<sub>y<sub><em>u,i,j,t<sup>k</sup></em></sub></sub>  and ε<sub>y<sub><em>v,i,j,t<sup>k</sup></em></sub></sub>  , respectively of the velocity fields u and v, follow the same <strong>Gaussian distribution</strong> N(0,R). Thus, the observation error covariance in this shallow water system can be fully characterized by a 100 × 100 <strong>R</strong> matrix after the observations (originally in a 2D grid) being converted to a 1D vector.</p>
<blockquote>
<p><code>↑ 上面介绍的是某一时刻观测误差协方差的维数</code></p>
</blockquote>
<p>Here we adopt a different parameterization of the R matrix thanks to an <strong>isotropic correlation function</strong> ψ<sub>R</sub>(.),</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220227210650.png" style="zoom:80%;">

<ul>
<li><p>where <strong>D</strong>=[<em>D</em><sub>0</sub>,…, <em>D</em><sub>99</sub>], representing the error variances in the 2D (10 × 10) velocity field. Each element of D is generated individually following an uniform distribution,</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220227210854.png" style="zoom:80%;">

<p>which produces only positive elements to guarantee the positive definiteness of R.</p>
</li>
<li><p>ψ<sub>R</sub>(.) is the <strong>second-order auto-aggressive (also known as Balgovind) function</strong>,</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220227211048.png" style="zoom:80%;">

<p>where <em>L</em><sub>R</sub> is the correlation scale length, fixed as <em>L</em><sub>R</sub> = 10 in this application. <em>r</em> denotes the correlation scale length in the 2D space and is also generated uniformly with  <em>r</em> ~U(1,5). </p>
<p>Being part of Matern kernels, <strong>the SOAR function is often used in DA</strong> for prior error covariance modeling [6, 26] thanks to its smoothness and good conditioning. </p>
</li>
</ul>
<blockquote>
<p><code>↑ 上面介绍了观测误差协方差的构建</code></p>
</blockquote>
<p>The simulation of x<sub><em>b,t<sup>k</sup></em></sub>=[u<sub><em>b,t<sup>k</sup></em></sub>, v<sub><em>b,t<sup>k</sup></em></sub>] via the same discretization of <strong>Eq 39</strong> (except the initial conditions) is used as background states at time <em>t<sup>k</sup></em> in the DA modeling. Similar to the Lorenz experiment(i.e., <strong>Eq 35</strong>), {x<sub><em>b,t<sup>k</sup></em></sub>} is acquired by combining {x<sub><em>a,t<sup>k</sup></em></sub>} with randomly generated Gaussian errors, while {x<sub><em>a,t<sup>k</sup></em></sub>} is obtained every 100 time steps (i.e., 0.01s) from ensemble DA with time series observation data {y<sub><em>t<sup>k</sup></em></sub>} and the estimated observation error covariance R.</p>
<blockquote>
<p><code>↑ 上面介绍了某一时刻的背景场是什么</code></p>
</blockquote>
<h3 id="8-2-DA-with-LSTM-estimated-R"><a href="#8-2-DA-with-LSTM-estimated-R" class="headerlink" title="8.2 DA with LSTM estimated R"></a>8.2 DA with LSTM estimated R</h3><p>As with the Lorenz experiment, simulated observations {y<sub><em>t<sup>k</sup></em></sub>}, generated in the same process with that in the Lorenz system, are used as input training data for the LSTM model, while the <strong>D</strong> vector and the correlation scale <strong>r</strong> served as training output. </p>
<blockquote>
<p><code>↑ 上面介绍了浅水试验LSTM模型训练集的输入和输出</code></p>
</blockquote>
<p>The specific structure of this LSTM network is shown in <strong>Table 3</strong>. This model has the same structure as the one of the Lorenz systems shown in <strong>Table 1</strong>, except the input and output dimensions. Besides, two types of LSTM are also proposed as what have been realized in the Lorenz system: <strong>LSTM1000</strong> employs the whole 1000 time steps observation data as LSTM training and prediction inputs while <strong>LSTM200</strong> makes use of only the first 200 time steps of observation data as the LSTM inputs. </p>
<p><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220227212912.png"></p>
<blockquote>
<p><code>↑ 上面介绍了浅水试验LSTM模型结构，两个试验</code></p>
</blockquote>
<p>After the LSTM is well trained on the training set of 173000 generated observation trajectories in this experiment, R can be gained even only observation time-series data {y<sub><em>t<sup>k</sup></em></sub>} is acknowledged.</p>
<blockquote>
<p><code>↑ ...</code></p>
</blockquote>
<p>Similar to the Lorenz system, EnDA is performed here with an ensemble of 100 state trajectories initialized from the same initial state x<sub><em>t<sup>0</sup></em></sub> for each observation series. <strong>EnDA takes place every 200 time steps</strong> with the R matrix estimated through different methods.</p>
<blockquote>
<p><code>↑ EnDA 集合，EnDA 同化窗口</code></p>
</blockquote>
<h3 id="8-3-Results"><a href="#8-3-Results" class="headerlink" title="8.3 Results"></a>8.3 Results</h3><h2 id="Pycharm-实现-code"><a href="#Pycharm-实现-code" class="headerlink" title="Pycharm 实现 code"></a>Pycharm 实现 code</h2><h3 id="Git托管（待）"><a href="#Git托管（待）" class="headerlink" title="Git托管（待）"></a>Git托管（待）</h3><p>目前保存在D盘；</p>
<h3 id="界面MATLAB化-环境配置"><a href="#界面MATLAB化-环境配置" class="headerlink" title="界面MATLAB化+环境配置"></a>界面MATLAB化+环境配置</h3><ol>
<li><p>为了<strong>使得pycharm更像MATLAB</strong>，：</p>
<ul>
<li><p>主题设置为 <strong>白色</strong>；</p>
</li>
<li><p>勾选<code>Run with Python Console</code>，在运行完文件后，<strong>能在Python Console看到变量</strong>;</p>
<p><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226203810.png"></p>
</li>
<li><p>右键执行所选代码，<strong>能在Python Console看到变量</strong>;</p>
</li>
<li><p>pycharm不会将当前文件目录自动加入自己的sourse_path。右键make_directory as–&gt;sources path将当前工作的文件夹加入source_path就可以了。这样<strong>可以在同目录下import其它py文件</strong>。</p>
<blockquote>
<p>文件夹加入source_path后会显示成<strong>蓝色</strong>。</p>
</blockquote>
</li>
</ul>
<blockquote>
<p><strong>其实pycharm很强大的</strong>~~以前是自己了解的不够多~</p>
<p><strong>有些MATLAB那味道了</strong>~~</p>
<p><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226211922.png"></p>
<p>怎么<strong>感觉pycharm比matlab还好用呀</strong>~~😊</p>
</blockquote>
</li>
<li><p>在pycharm上以项目的形式打开<code>LSTM_Covariance-main</code>文件夹，通过Anaconda，为项目创建一个新环境</p>
<p><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226170212.png"></p>
</li>
<li><p>为环境安装相关python包（库）</p>
<pre class="line-numbers language-none"><code class="language-none">numpy
scipy
matplotlib
keras
tensorflow
sklearn
pandas<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>进入 Anaconda Prompt，输入：</p>
<pre class="line-numbers language-Anaconda" data-language="Anaconda"><div class="caption"><span>Prompt</span></div><code class="language-Anaconda">conda info -e
conda activate LSTM_Covariance-main
pip install tensorflow<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li>
</ol>
<h4 id="参考资料-1"><a href="#参考资料-1" class="headerlink" title="参考资料"></a>参考资料</h4><p>pycharm<strong>新建项目环境</strong>设置详解：<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_38858443/article/details/108966449">https://blog.csdn.net/weixin_38858443/article/details/108966449</a></p>
<ul>
<li>项目、解释器、环境几个概念的理解</li>
<li>在pycharm为项目新建一个新环境</li>
</ul>
<p>Pycharm中<strong>运行Python代码</strong>的几种方式：<a target="_blank" rel="noopener" href="https://blog.csdn.net/JHON07/article/details/78966837">https://blog.csdn.net/JHON07/article/details/78966837</a></p>
<ul>
<li>右键，run，ok~~</li>
</ul>
<p>PyCharm配置anaconda环境 <strong>安装第三方库</strong>：<a target="_blank" rel="noopener" href="https://blog.51cto.com/u_15284226/2992785">https://blog.51cto.com/u_15284226/2992785</a></p>
<p>Pycharm在运行过程中,**查看每个变量的操作(show variables)**：<a target="_blank" rel="noopener" href="http://www.deiniu.com/article/188284.htm">http://www.deiniu.com/article/188284.htm</a></p>
<ul>
<li>让你的Pycharm用得和matlab一模一样！：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/337278800?ivk_sa=1024320u">https://zhuanlan.zhihu.com/p/337278800?ivk_sa=1024320u</a></li>
</ul>
<p>为什么用pycharm在同目录下import，pycharm会报错，但是实际可以运行？：</p>
<h3 id="Lorenz"><a href="#Lorenz" class="headerlink" title="Lorenz"></a>Lorenz</h3><h4 id="simulated-data-generation-py-（QT）"><a href="#simulated-data-generation-py-（QT）" class="headerlink" title="simulated_data_generation.py （QT）"></a>simulated_data_generation.py （QT）</h4><p><code>simulated_data_generation.py</code> released in 2022-02-26</p>
<ul>
<li><p>整个运行时间</p>
<p>运行开始时间：17:55</p>
<p>运行结束时间：20:50</p>
</li>
<li><p><code>.ravel 矩阵向量化</code></p>
</li>
<li><p><code>.concatenate axis=0 数组拼接</code></p>
</li>
<li><p><code>y = np.dot(H,x)               #why this is this expression to calculate y? </code></p>
<p>这个 x ，在论文7.2中指出是x<sub>true</sub>，</p>
<p>而代码中的 x 根据7.2中公式(33)应该是x<sub>b</sub>，</p>
<p><strong>QT：矛盾了吗？</strong></p>
<p><strong>猜测</strong>：我觉得应该是代码出了问题</p>
<ul>
<li><p>代码中出现了两次 x<sub>true</sub> 的定义，有一个应该是x<sub>b</sub>；</p>
</li>
<li><p>从<strong>同化公式</strong>可以看出，y应该等于H(x<sub>true</sub>) ，<strong>如果观测数据y等于H(x<sub>b</sub>)，那还需要同化什么呀</strong>，直接x<sub>a</sub>=x<sub>b</sub> 。</p>
<p>可以看看后面<strong>作者是怎么同化的</strong>~</p>
<p>往下看~</p>
</li>
</ul>
</li>
<li><p><strong>整个py的作用，6中的算法1，7.2部分</strong>，生成训练集；</p>
</li>
<li><p><code>simulated_data_generation.py</code> released in 2022-02-26 最开始的代码</p>
</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># -*- coding: utf-8 -*-</span>
<span class="token comment"># generate the trainning set for keras regression </span>

<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> scipy<span class="token punctuation">.</span>optimize <span class="token keyword">import</span> fmin
<span class="token keyword">from</span> scipy<span class="token punctuation">.</span>optimize <span class="token keyword">import</span> fmin_l_bfgs_b

<span class="token comment">#from scipy.optimize import fmin_ncg</span>
<span class="token keyword">from</span> scipy<span class="token punctuation">.</span>linalg <span class="token keyword">import</span> sqrtm
<span class="token keyword">import</span> math


<span class="token keyword">from</span> constructB <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> lorentz_attractor <span class="token keyword">import</span> <span class="token operator">*</span>

<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>gridspec <span class="token keyword">as</span> gridspec
<span class="token keyword">import</span> time
<span class="token keyword">import</span> random
<span class="token keyword">import</span> lorentz_attractor
<span class="token keyword">import</span> sklearn
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets

<span class="token keyword">import</span> os

<span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isdir<span class="token punctuation">(</span><span class="token string">'lorenz_cov_train_v2'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span><span class="token string">'lorenz_cov_train_v2'</span><span class="token punctuation">)</span>

<span class="token comment">#######################################################################</span>

<span class="token keyword">def</span> <span class="token function">correlation_from_covariance</span><span class="token punctuation">(</span>covariance<span class="token punctuation">)</span><span class="token punctuation">:</span>
    v <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>np<span class="token punctuation">.</span>diag<span class="token punctuation">(</span>covariance<span class="token punctuation">)</span><span class="token punctuation">)</span>
    outer_v <span class="token operator">=</span> np<span class="token punctuation">.</span>outer<span class="token punctuation">(</span>v<span class="token punctuation">,</span> v<span class="token punctuation">)</span>
    correlation <span class="token operator">=</span> covariance <span class="token operator">/</span> outer_v   <span class="token comment">#https://www.mygreatlearning.com/blog/covariance-vs-correlation/</span>
    correlation<span class="token punctuation">[</span>covariance <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">return</span> correlation

<span class="token comment">######################################################################</span>
<span class="token comment">#define matrix R by extra-diagonal elements</span>
<span class="token keyword">def</span> <span class="token function">R_covariance_dim3</span><span class="token punctuation">(</span>r1<span class="token punctuation">,</span>r2<span class="token punctuation">,</span>r3<span class="token punctuation">)</span><span class="token punctuation">:</span>
    M <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    M<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> r1
    M<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> r2
    M<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> r3
    M <span class="token operator">=</span> M <span class="token operator">+</span> M<span class="token punctuation">.</span>T
    M <span class="token operator">+=</span> np<span class="token punctuation">.</span>eye<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> M
    
<span class="token comment">################################################################################</span>
<span class="token comment">#######################################################################</span>
<span class="token keyword">def</span> <span class="token function">cov_to_cor</span><span class="token punctuation">(</span>M<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># from a covariance matrix to its associated correlation matrix</span>
    inv_diag_M<span class="token operator">=</span>np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>inv<span class="token punctuation">(</span>sqrtm<span class="token punctuation">(</span>np<span class="token punctuation">.</span>diag<span class="token punctuation">(</span>np<span class="token punctuation">.</span>diag<span class="token punctuation">(</span>M<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    cor_M <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>inv_diag_M<span class="token punctuation">,</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>M<span class="token punctuation">,</span>inv_diag_M<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> cor_M


<span class="token keyword">def</span> <span class="token function">lorenz_1step</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> z<span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> r<span class="token operator">=</span><span class="token number">28</span><span class="token punctuation">,</span> b<span class="token operator">=</span><span class="token number">2.667</span><span class="token punctuation">,</span>dt <span class="token operator">=</span> <span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    x_dot<span class="token punctuation">,</span> y_dot<span class="token punctuation">,</span> z_dot <span class="token operator">=</span> lorenz<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> z<span class="token punctuation">)</span>
    x_next <span class="token operator">=</span> x <span class="token operator">+</span> <span class="token punctuation">(</span>x_dot <span class="token operator">*</span> dt<span class="token punctuation">)</span>
    y_next <span class="token operator">=</span> y <span class="token operator">+</span> <span class="token punctuation">(</span>y_dot <span class="token operator">*</span> dt<span class="token punctuation">)</span>
    z_next <span class="token operator">=</span> z <span class="token operator">+</span> <span class="token punctuation">(</span>z_dot <span class="token operator">*</span> dt<span class="token punctuation">)</span>    
    <span class="token keyword">return</span> x_next<span class="token punctuation">,</span> y_next<span class="token punctuation">,</span> z_next

<span class="token keyword">def</span> <span class="token function">VAR_3D</span><span class="token punctuation">(</span>xb<span class="token punctuation">,</span>Y<span class="token punctuation">,</span>H<span class="token punctuation">,</span>B<span class="token punctuation">,</span>R<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#booleen=1 garde la trace</span>
    xb1<span class="token operator">=</span>np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>xb<span class="token punctuation">)</span>
    xb1<span class="token punctuation">.</span>shape<span class="token operator">=</span><span class="token punctuation">(</span>xb1<span class="token punctuation">.</span>size<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
    Y<span class="token punctuation">.</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>Y<span class="token punctuation">.</span>size<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
    dim_x <span class="token operator">=</span> xb1<span class="token punctuation">.</span>size
    K<span class="token operator">=</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>B<span class="token punctuation">,</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>H<span class="token punctuation">)</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>inv<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>H<span class="token punctuation">,</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>B<span class="token punctuation">,</span>np<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>H<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">+</span>R<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#matrice de gain, Kalman gain</span>
    A<span class="token operator">=</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>eye<span class="token punctuation">(</span>dim_x<span class="token punctuation">)</span><span class="token operator">-</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>K<span class="token punctuation">,</span>H<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>B<span class="token punctuation">)</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>eye<span class="token punctuation">(</span>dim_x<span class="token punctuation">)</span><span class="token operator">-</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>K<span class="token punctuation">,</span>H<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">+</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>K<span class="token punctuation">,</span>R<span class="token punctuation">)</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>K<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment">#not the kalman filter expression???</span>
    vect<span class="token operator">=</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>H<span class="token punctuation">,</span>xb1<span class="token punctuation">)</span>
    xa<span class="token operator">=</span>np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>xb1<span class="token operator">+</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>K<span class="token punctuation">,</span><span class="token punctuation">(</span>Y<span class="token operator">-</span>vect<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> xa<span class="token punctuation">,</span>A   <span class="token comment">#xa is the new estimated data, A is the new covariance,</span>
<span class="token comment">###################################################################################</span>

<span class="token comment">###################################################################################</span>
    <span class="token comment">#parameters</span>
num_steps <span class="token operator">=</span> <span class="token number">1000</span>
H <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
R <span class="token operator">=</span> <span class="token number">0.001</span><span class="token operator">*</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0.4</span><span class="token punctuation">,</span><span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0.4</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0.4</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">0.4</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

B <span class="token operator">=</span><span class="token number">0.01</span><span class="token operator">*</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0.2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0.2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token number">0.2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment">#Q = 0.0001*np.eye(3)</span>

<span class="token comment">###################################################################################</span>
<span class="token comment">#save the trainning set for different R </span>
trainning_set <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>num_steps<span class="token operator">*</span><span class="token number">3</span><span class="token operator">+</span><span class="token number">3</span><span class="token operator">+</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   

<span class="token comment">###################################################################################</span>

<span class="token comment">#############################################################################</span>
    <span class="token comment"># true states vector 3 * number_steps</span>
xs<span class="token punctuation">,</span>ys<span class="token punctuation">,</span>zs <span class="token operator">=</span> lorenz_attractor<span class="token punctuation">(</span>s<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> r<span class="token operator">=</span><span class="token number">28</span><span class="token punctuation">,</span> b<span class="token operator">=</span><span class="token number">2.667</span><span class="token punctuation">,</span> dt <span class="token operator">=</span> <span class="token number">0.001</span><span class="token punctuation">,</span> num_steps<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span>

x_true <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>num_steps<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

x_true<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>xs<span class="token punctuation">)</span>
x_true<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>ys<span class="token punctuation">)</span>
x_true<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>zs<span class="token punctuation">)</span>


<span class="token comment">###############################################################################</span>
<span class="token keyword">for</span> ii <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> ii<span class="token operator">%</span><span class="token number">100</span> <span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>ii<span class="token punctuation">)</span>
            
<span class="token comment"># construct observations</span>
                
<span class="token comment">#=========================================================================</span>
    <span class="token comment">#generate x with noise</span>
    <span class="token keyword">for</span> repetation <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        xs<span class="token punctuation">,</span>ys<span class="token punctuation">,</span>zs <span class="token operator">=</span> lorenz_attractor<span class="token punctuation">(</span>s<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> r<span class="token operator">=</span><span class="token number">28</span><span class="token punctuation">,</span> b<span class="token operator">=</span><span class="token number">2.667</span><span class="token punctuation">,</span> dt <span class="token operator">=</span> <span class="token number">0.001</span><span class="token punctuation">,</span> num_steps <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">,</span>x0 <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token operator">+</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                    y0<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">+</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">)</span><span class="token punctuation">,</span>z0<span class="token operator">=</span><span class="token number">1.05</span><span class="token operator">+</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        
        x_true <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>num_steps<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        
        x_true<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>xs<span class="token punctuation">)</span>
        x_true<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>ys<span class="token punctuation">)</span>
        x_true<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>zs<span class="token punctuation">)</span>                
        
<span class="token comment">#=========================================================================</span>

        y_true <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>num_steps<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        y_obs <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>num_steps<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        
        v <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
        R <span class="token operator">=</span> correlation_from_covariance<span class="token punctuation">(</span>sklearn<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>make_spd_matrix<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment">#SPD covariance</span>
        
        r1 <span class="token operator">=</span> R<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span>
        r2 <span class="token operator">=</span> R<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span>
        r3 <span class="token operator">=</span> R<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span>
        
        R <span class="token operator">=</span> v<span class="token operator">*</span>R   
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_steps<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"sample time: "</span><span class="token punctuation">,</span>ii<span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"iteration time: "</span><span class="token punctuation">,</span>i<span class="token punctuation">)</span>
            x <span class="token operator">=</span> x_true<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token punctuation">]</span>
            x<span class="token punctuation">.</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
            y <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>H<span class="token punctuation">,</span>x<span class="token punctuation">)</span>               <span class="token comment">#why this is this expression to calculate y?        </span>
            y<span class="token punctuation">.</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>y<span class="token punctuation">.</span>size<span class="token punctuation">,</span><span class="token punctuation">)</span>
            y_true<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> y
            
            y_noise <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>multivariate_normal<span class="token punctuation">(</span>np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>R<span class="token punctuation">)</span>
            y_noise<span class="token punctuation">.</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>y_noise<span class="token punctuation">.</span>size<span class="token punctuation">,</span><span class="token punctuation">)</span>
            y_noise <span class="token operator">+=</span> y 
            y_obs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> y_noise
            
            parameters <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>r1<span class="token punctuation">,</span>r2<span class="token punctuation">,</span>r3<span class="token punctuation">,</span>v<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment">#output for deep learning regression</span>
                        <span class="token comment">#train_row = np.concatenate((y_obs.ravel(),x_true.ravel())) #input for deep learning    #what are the functionalities of these r -&gt;covaraicen! why v is not necessary???</span>
            train_row <span class="token operator">=</span> y_obs<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span>
            train_row <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>train_row<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>parameters<span class="token punctuation">)</span><span class="token punctuation">)</span>
            
        train_row<span class="token punctuation">.</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>train_row<span class="token punctuation">.</span>size<span class="token punctuation">)</span>
        trainning_set <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>trainning_set<span class="token punctuation">,</span>train_row<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

        <span class="token comment"># if repetation+ii*10==5000:</span>

        <span class="token comment">#     np.savetxt(f"lorenz_cov_train_v2/trainset_withx_steps1000_test_{10000+repetation+ii*10}.csv", trainning_set, delimiter=",")</span>

trainning_set <span class="token operator">=</span> trainning_set<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
<span class="token comment">#####################################################################################""</span>
np<span class="token punctuation">.</span>savetxt<span class="token punctuation">(</span><span class="token string">"lorenz_cov_train_v2/trainset_withx_steps1000_test8.csv"</span><span class="token punctuation">,</span> trainning_set<span class="token punctuation">,</span> delimiter<span class="token operator">=</span><span class="token string">","</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<blockquote>
<blockquote>
</blockquote>
</blockquote>
</blockquote>
<p><code>simulated_data_generation.py</code> 在released in 2022-02-26 基础上，进行注释</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># -*- coding: utf-8 -*-</span>
<span class="token comment"># generate the trainning set for keras regression </span>

<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> scipy<span class="token punctuation">.</span>optimize <span class="token keyword">import</span> fmin
<span class="token keyword">from</span> scipy<span class="token punctuation">.</span>optimize <span class="token keyword">import</span> fmin_l_bfgs_b

<span class="token comment">#from scipy.optimize import fmin_ncg</span>
<span class="token keyword">from</span> scipy<span class="token punctuation">.</span>linalg <span class="token keyword">import</span> sqrtm
<span class="token keyword">import</span> math


<span class="token keyword">from</span> constructB <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> lorentz_attractor <span class="token keyword">import</span> <span class="token operator">*</span>

<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>gridspec <span class="token keyword">as</span> gridspec
<span class="token keyword">import</span> time
<span class="token keyword">import</span> random
<span class="token keyword">import</span> lorentz_attractor
<span class="token keyword">import</span> sklearn
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets

<span class="token keyword">import</span> os

<span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isdir<span class="token punctuation">(</span><span class="token string">'lorenz_cov_train_v2'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span><span class="token string">'lorenz_cov_train_v2'</span><span class="token punctuation">)</span>

<span class="token comment">#######################################################################</span>

<span class="token keyword">def</span> <span class="token function">correlation_from_covariance</span><span class="token punctuation">(</span>covariance<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''
    Given:
        covariance: 对称正定矩阵
    Returns:
        correlation: (-1,1) 的对称正定矩阵，相关系数

    '''</span>
    v <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>np<span class="token punctuation">.</span>diag<span class="token punctuation">(</span>covariance<span class="token punctuation">)</span><span class="token punctuation">)</span>
    outer_v <span class="token operator">=</span> np<span class="token punctuation">.</span>outer<span class="token punctuation">(</span>v<span class="token punctuation">,</span> v<span class="token punctuation">)</span>
    correlation <span class="token operator">=</span> covariance <span class="token operator">/</span> outer_v   <span class="token comment">#https://www.mygreatlearning.com/blog/covariance-vs-correlation/</span>
    correlation<span class="token punctuation">[</span>covariance <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">return</span> correlation

<span class="token comment">######################################################################</span>
<span class="token comment">#define matrix R by extra-diagonal elements</span>
<span class="token keyword">def</span> <span class="token function">R_covariance_dim3</span><span class="token punctuation">(</span>r1<span class="token punctuation">,</span>r2<span class="token punctuation">,</span>r3<span class="token punctuation">)</span><span class="token punctuation">:</span>
    M <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    M<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> r1
    M<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> r2
    M<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> r3
    M <span class="token operator">=</span> M <span class="token operator">+</span> M<span class="token punctuation">.</span>T
    M <span class="token operator">+=</span> np<span class="token punctuation">.</span>eye<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> M
    
<span class="token comment">################################################################################</span>
<span class="token comment">#######################################################################</span>
<span class="token keyword">def</span> <span class="token function">cov_to_cor</span><span class="token punctuation">(</span>M<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># from a covariance matrix to its associated correlation matrix</span>
    inv_diag_M<span class="token operator">=</span>np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>inv<span class="token punctuation">(</span>sqrtm<span class="token punctuation">(</span>np<span class="token punctuation">.</span>diag<span class="token punctuation">(</span>np<span class="token punctuation">.</span>diag<span class="token punctuation">(</span>M<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    cor_M <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>inv_diag_M<span class="token punctuation">,</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>M<span class="token punctuation">,</span>inv_diag_M<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> cor_M


<span class="token keyword">def</span> <span class="token function">lorenz_1step</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> z<span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> r<span class="token operator">=</span><span class="token number">28</span><span class="token punctuation">,</span> b<span class="token operator">=</span><span class="token number">2.667</span><span class="token punctuation">,</span>dt <span class="token operator">=</span> <span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    x_dot<span class="token punctuation">,</span> y_dot<span class="token punctuation">,</span> z_dot <span class="token operator">=</span> lorenz<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> z<span class="token punctuation">)</span>
    x_next <span class="token operator">=</span> x <span class="token operator">+</span> <span class="token punctuation">(</span>x_dot <span class="token operator">*</span> dt<span class="token punctuation">)</span>
    y_next <span class="token operator">=</span> y <span class="token operator">+</span> <span class="token punctuation">(</span>y_dot <span class="token operator">*</span> dt<span class="token punctuation">)</span>
    z_next <span class="token operator">=</span> z <span class="token operator">+</span> <span class="token punctuation">(</span>z_dot <span class="token operator">*</span> dt<span class="token punctuation">)</span>    
    <span class="token keyword">return</span> x_next<span class="token punctuation">,</span> y_next<span class="token punctuation">,</span> z_next

<span class="token keyword">def</span> <span class="token function">VAR_3D</span><span class="token punctuation">(</span>xb<span class="token punctuation">,</span>Y<span class="token punctuation">,</span>H<span class="token punctuation">,</span>B<span class="token punctuation">,</span>R<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#booleen=1 garde la trace</span>
    xb1<span class="token operator">=</span>np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>xb<span class="token punctuation">)</span>
    xb1<span class="token punctuation">.</span>shape<span class="token operator">=</span><span class="token punctuation">(</span>xb1<span class="token punctuation">.</span>size<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
    Y<span class="token punctuation">.</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>Y<span class="token punctuation">.</span>size<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
    dim_x <span class="token operator">=</span> xb1<span class="token punctuation">.</span>size
    K<span class="token operator">=</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>B<span class="token punctuation">,</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>H<span class="token punctuation">)</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>inv<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>H<span class="token punctuation">,</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>B<span class="token punctuation">,</span>np<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>H<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">+</span>R<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#matrice de gain, Kalman gain</span>
    A<span class="token operator">=</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>eye<span class="token punctuation">(</span>dim_x<span class="token punctuation">)</span><span class="token operator">-</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>K<span class="token punctuation">,</span>H<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>B<span class="token punctuation">)</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>eye<span class="token punctuation">(</span>dim_x<span class="token punctuation">)</span><span class="token operator">-</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>K<span class="token punctuation">,</span>H<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">+</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>K<span class="token punctuation">,</span>R<span class="token punctuation">)</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>K<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment">#not the kalman filter expression???</span>
    vect<span class="token operator">=</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>H<span class="token punctuation">,</span>xb1<span class="token punctuation">)</span>
    xa<span class="token operator">=</span>np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>xb1<span class="token operator">+</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>K<span class="token punctuation">,</span><span class="token punctuation">(</span>Y<span class="token operator">-</span>vect<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> xa<span class="token punctuation">,</span>A   <span class="token comment">#xa is the new estimated data, A is the new covariance,</span>
<span class="token comment">###################################################################################</span>

<span class="token comment">###################################################################################</span>
<span class="token comment">#parameters</span>
num_steps <span class="token operator">=</span> <span class="token number">1000</span>
H <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
R <span class="token operator">=</span> <span class="token number">0.001</span><span class="token operator">*</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0.4</span><span class="token punctuation">,</span><span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0.4</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0.4</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">0.4</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

B <span class="token operator">=</span><span class="token number">0.01</span><span class="token operator">*</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0.2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0.2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token number">0.2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment">#Q = 0.0001*np.eye(3)</span>

<span class="token comment">###################################################################################</span>
<span class="token comment">#save the trainning set for different R </span>
trainning_set <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>num_steps<span class="token operator">*</span><span class="token number">3</span><span class="token operator">+</span><span class="token number">3</span><span class="token operator">+</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">#加3的原因：Lorenz 系统每个参数的时间节点个数，比步长数多 1，有3个参数，加3</span>
    <span class="token comment">#加4的原因：R 矩阵生成的4个参数</span>

<span class="token comment">###################################################################################</span>

<span class="token comment">#############################################################################</span>
<span class="token comment"># true states vector 3 * number_steps</span>
xs<span class="token punctuation">,</span>ys<span class="token punctuation">,</span>zs <span class="token operator">=</span> lorenz_attractor<span class="token punctuation">(</span>s<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> r<span class="token operator">=</span><span class="token number">28</span><span class="token punctuation">,</span> b<span class="token operator">=</span><span class="token number">2.667</span><span class="token punctuation">,</span> dt <span class="token operator">=</span> <span class="token number">0.001</span><span class="token punctuation">,</span> num_steps<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span>

x_true <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>num_steps<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 真实场</span>

x_true<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>xs<span class="token punctuation">)</span>
x_true<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>ys<span class="token punctuation">)</span>
x_true<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>zs<span class="token punctuation">)</span>


<span class="token comment">###############################################################################</span>
<span class="token keyword">for</span> ii <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># ii = 0   算法1  中的iter?</span>
    <span class="token keyword">if</span> ii<span class="token operator">%</span><span class="token number">100</span> <span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>ii<span class="token punctuation">)</span>
            
<span class="token comment"># construct observations</span>
                
<span class="token comment">#=========================================================================</span>
    <span class="token keyword">for</span> repetation <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># repetation = 0</span>
        <span class="token comment"># 背景场 的生成</span>
        xs<span class="token punctuation">,</span>ys<span class="token punctuation">,</span>zs <span class="token operator">=</span> lorenz_attractor<span class="token punctuation">(</span>s<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> r<span class="token operator">=</span><span class="token number">28</span><span class="token punctuation">,</span> b<span class="token operator">=</span><span class="token number">2.667</span><span class="token punctuation">,</span> dt <span class="token operator">=</span> <span class="token number">0.001</span><span class="token punctuation">,</span> num_steps <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">,</span>x0 <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token operator">+</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                    y0<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">+</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">)</span><span class="token punctuation">,</span>z0<span class="token operator">=</span><span class="token number">1.05</span><span class="token operator">+</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        
        x_true <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>num_steps<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 背景场，这里只对初始值进行噪声干扰，是因为lorenz是个混沌系统；</span>
        
        x_true<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>xs<span class="token punctuation">)</span>
        x_true<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>ys<span class="token punctuation">)</span>
        x_true<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>zs<span class="token punctuation">)</span>                
        
<span class="token comment">#=========================================================================</span>

        y_true <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>num_steps<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#</span>
        y_obs <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>num_steps<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#</span>

        <span class="token comment"># R 的构建</span>
        v <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
        R <span class="token operator">=</span> correlation_from_covariance<span class="token punctuation">(</span>sklearn<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>make_spd_matrix<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment">#SPD covariance</span>
        
        r1 <span class="token operator">=</span> R<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span>
        r2 <span class="token operator">=</span> R<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span>
        r3 <span class="token operator">=</span> R<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span>
        
        R <span class="token operator">=</span> v<span class="token operator">*</span>R

        <span class="token comment"># 训练数据集 的构建：Lorenz 3 个参数的时间节点（3*1001），R 的 4 个参数 （+4）</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_steps<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># i=0</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"sample time: "</span><span class="token punctuation">,</span>ii<span class="token punctuation">)</span> <span class="token comment">#采样次数</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"iteration time: "</span><span class="token punctuation">,</span>i<span class="token punctuation">)</span> <span class="token comment">#迭代次数</span>
            <span class="token comment"># 观测 y 的生成</span>
            x <span class="token operator">=</span> x_true<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token punctuation">]</span>
            x<span class="token punctuation">.</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
            y <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>H<span class="token punctuation">,</span>x<span class="token punctuation">)</span>               <span class="token comment">#why this is this expression to calculate y?        </span>
            y<span class="token punctuation">.</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>y<span class="token punctuation">.</span>size<span class="token punctuation">,</span><span class="token punctuation">)</span>
            y_true<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> y
            
            y_noise <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>multivariate_normal<span class="token punctuation">(</span>np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>R<span class="token punctuation">)</span>
            y_noise<span class="token punctuation">.</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>y_noise<span class="token punctuation">.</span>size<span class="token punctuation">,</span><span class="token punctuation">)</span>
            y_noise <span class="token operator">+=</span> y 
            y_obs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> y_noise

            <span class="token comment"># 拼接上 R 的 4 个参数</span>
            parameters <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>r1<span class="token punctuation">,</span>r2<span class="token punctuation">,</span>r3<span class="token punctuation">,</span>v<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment">#output for deep learning regression</span>
                        <span class="token comment">#train_row = np.concatenate((y_obs.ravel(),x_true.ravel())) #input for deep learning    #what are the functionalities of these r -&gt;covaraicen! why v is not necessary???</span>
            train_row <span class="token operator">=</span> y_obs<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># .ravel 矩阵向量化，x = np.array([[1,2],[3,4]]),则print(np.ravel(x)) = [1 2 3 4]</span>
            train_row <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>train_row<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>parameters<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># .concatenate 数组拼接</span>
            
        train_row<span class="token punctuation">.</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>train_row<span class="token punctuation">.</span>size<span class="token punctuation">)</span> <span class="token comment"># .shape</span>
        trainning_set <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>trainning_set<span class="token punctuation">,</span>train_row<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># .concatenate axis=0 数组拼接</span>

        <span class="token comment"># if repetation+ii*10==5000:</span>

        <span class="token comment">#     np.savetxt(f"lorenz_cov_train_v2/trainset_withx_steps1000_test_{10000+repetation+ii*10}.csv", trainning_set, delimiter=",")</span>

trainning_set <span class="token operator">=</span> trainning_set<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token comment"># 不要第一行，全是 0 的那一行；</span>
<span class="token comment">#####################################################################################""</span>
np<span class="token punctuation">.</span>savetxt<span class="token punctuation">(</span><span class="token string">"lorenz_cov_train_v2/trainset_withx_steps1000_test8.csv"</span><span class="token punctuation">,</span> trainning_set<span class="token punctuation">,</span> delimiter<span class="token operator">=</span><span class="token string">","</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="QT：为什么线性观测算子H是固定的那个矩阵？为什么H-x-加上个多元误差的协方差分布，就变成观测了？（因为DA中，观测也是有误差的？）"><a href="#QT：为什么线性观测算子H是固定的那个矩阵？为什么H-x-加上个多元误差的协方差分布，就变成观测了？（因为DA中，观测也是有误差的？）" class="headerlink" title="QT：为什么线性观测算子H是固定的那个矩阵？为什么H(x)加上个多元误差的协方差分布，就变成观测了？（因为DA中，观测也是有误差的？）"></a>QT：为什么线性观测算子H是固定的那个矩阵？为什么H(x)加上个多元误差的协方差分布，就变成观测了？（因为DA中，观测也是有误差的？）</h4><h4 id="lorenz-lstm200-py"><a href="#lorenz-lstm200-py" class="headerlink" title="lorenz_lstm200.py"></a>lorenz_lstm200.py</h4><p><code>lorenz_lstm200.py</code> released in 2022-02-26</p>
<ul>
<li><p>报错：</p>
<pre class="line-numbers language-none"><code class="language-none">ImportError: cannot import name 'Adam' from 'keras.optimizers' (D:\Program Files (x86)\Anaconda3\envs\LSTM_Covariance-main\lib\site-packages\keras\optimizers.py)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>解决方法：<a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/62707558/importerror-cannot-import-name-adam-from-keras-optimizers/69581798">https://stackoverflow.com/questions/62707558/importerror-cannot-import-name-adam-from-keras-optimizers/69581798</a></p>
<pre class="line-numbers language-none"><code class="language-none">from tensorflow.keras.optimizers import Adam<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>整个运行时间</p>
<p>运行开始时间：11:40 </p>
<p>运行结束时间：14:20</p>
</li>
<li><p>相关代码知识点</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 相对路径解决办法</span>
<span class="token comment">#train_data = data_set_order('D:/LSTM_Covariance-main/lorenz/lorenz_cov_train_v2/trainset_withx_steps1000_test8.csv')</span>
<span class="token comment">#os.getcwd()</span>
os<span class="token punctuation">.</span>chdir<span class="token punctuation">(</span><span class="token string">'D:/LSTM_Covariance-main/lorenz/'</span><span class="token punctuation">)</span>

<span class="token comment"># -2表示的意思</span>
train_data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token builtin">file</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment">#取这个数组从第一行到倒数第三行，最后两行被丢弃了。</span>

<span class="token comment"># .insert axis=1 列插入</span>
train_data<span class="token operator">=</span>np<span class="token punctuation">.</span>insert<span class="token punctuation">(</span>r0<span class="token punctuation">,</span><span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>r0<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>r1<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> 

<span class="token comment">#.concateenate axis=1 列合并`</span>
train_data<span class="token operator">=</span>np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>train_data<span class="token punctuation">,</span>r3<span class="token punctuation">)</span><span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> 

<span class="token comment"># .random.shuffle 打乱行的顺序</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>train_data <span class="token punctuation">)</span>

<span class="token comment"># 与matlab不一样的一点：索引</span>
input_data <span class="token operator">=</span> train_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">603</span><span class="token punctuation">]</span> 
output_data <span class="token operator">=</span> train_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">603</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token comment">#出现两次 603 ，索引的数据重复了吗？没有</span>

<span class="token comment"># 可以对中文变量进行赋值，意义在于，可以在pycharm看到变量的大纲</span>
P03_LSTM模型结构和运行 <span class="token operator">=</span> <span class="token number">0</span>

<span class="token comment"># pycharm中plt.show()不显示图像解决办法</span>
<span class="token keyword">import</span> matplotlib
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
matplotlib<span class="token punctuation">.</span>use<span class="token punctuation">(</span><span class="token string">'TKAgg'</span><span class="token punctuation">)</span><span class="token comment">#加上这行代码即可，agg是一个没有图形显示界面的终端，常用的有图形界面显示的终端有TkAgg等</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p><code>lorenz_lstm200.py</code> released in 2022-02-26 最开始的代码</p>
</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># -*- coding: utf-8 -*-</span>
<span class="token triple-quoted-string string">"""
Created on Wed Jan  6 13:39:58 2021

@author: siboc
"""</span>

<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> scipy
<span class="token keyword">import</span> math
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt


<span class="token keyword">from</span> keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Sequential
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Dense
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> r2_score
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">import</span> keras<span class="token punctuation">.</span>backend <span class="token keyword">as</span> K
<span class="token comment"># check scikit-learn version</span>

<span class="token comment"># check scikit-learn version</span>
<span class="token keyword">import</span> sklearn
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LinearRegression
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> make_regression
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>neighbors <span class="token keyword">import</span> KNeighborsRegressor
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>tree <span class="token keyword">import</span> DecisionTreeRegressor
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

<span class="token keyword">def</span> <span class="token function">data_set_order</span><span class="token punctuation">(</span><span class="token builtin">file</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
	train_data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token builtin">file</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
	r0<span class="token operator">=</span>train_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token number">1001</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token number">201</span><span class="token punctuation">]</span>
	r1<span class="token operator">=</span>train_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1001</span><span class="token punctuation">:</span><span class="token number">2002</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token number">201</span><span class="token punctuation">]</span>
	r2<span class="token operator">=</span>train_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">2002</span><span class="token punctuation">:</span><span class="token number">3003</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token number">201</span><span class="token punctuation">]</span>
	r3<span class="token operator">=</span>train_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">3003</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
	r3<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">=</span>r3<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">/</span><span class="token number">100</span>
	train_data<span class="token operator">=</span>np<span class="token punctuation">.</span>insert<span class="token punctuation">(</span>r0<span class="token punctuation">,</span><span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>r0<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>r1<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
	train_data<span class="token operator">=</span>np<span class="token punctuation">.</span>insert<span class="token punctuation">(</span>train_data<span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">2</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>train_data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>r2<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
	train_data<span class="token operator">=</span>np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>train_data<span class="token punctuation">,</span>r3<span class="token punctuation">)</span><span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
	<span class="token keyword">return</span> train_data

<span class="token comment">#input</span>
train_data <span class="token operator">=</span> data_set_order<span class="token punctuation">(</span><span class="token string">'lorenz_cov_train_v2/trainset_withx_steps1000_test8.csv'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"train_data shape: "</span><span class="token punctuation">,</span>train_data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>


<span class="token comment"># train_data1 = data_set_order('lorenz_cov_train/trainset_withx_repeat10bis3.csv')</span>
<span class="token comment"># print("train_data1 shape: ",train_data1.shape)</span>

<span class="token comment"># train_data2 = data_set_order('lorenz_cov_train/trainset_withx_repeat10bis4.csv')</span>
<span class="token comment"># print("train_data2 shape: ",train_data2.shape)</span>

<span class="token comment"># train_data3 = data_set_order('lorenz_cov_train/trainset_withx_repeat10bis5.csv')</span>
<span class="token comment"># print("train_data3 shape: ",train_data3.shape)</span>

<span class="token comment"># train_data4 = data_set_order('lorenz_cov_train/trainset_withx_repeat10bis6.csv')</span>
<span class="token comment"># print("train_data4 shape: ",train_data4.shape)</span>

<span class="token comment"># train_data5 = data_set_order('lorenz_cov_train/trainset_withx_repeat10bis7.csv')</span>
<span class="token comment"># print("train_data5 shape: ",train_data5.shape)</span>

<span class="token comment"># train_data6 = data_set_order('lorenz_cov_train/trainset_withx_repeat10bis8.csv')</span>
<span class="token comment"># print("train_data6 shape: ",train_data6.shape)</span>

<span class="token comment">#size: num_steps*3,r1,r2,r3,v</span>


<span class="token comment">#########################################################################################</span>

<span class="token comment">#train_data = np.array(pd.read_csv('data_1000steps/trainset_withx_1000steps.csv'))</span>
<span class="token comment">#</span>
<span class="token comment">#</span>
<span class="token comment">#train_data1 = np.array(pd.read_csv('data_1000steps/trainset_withx_1000stepsbis1.csv'))</span>
<span class="token comment">#</span>
<span class="token comment">#train_data2 = np.array(pd.read_csv('data_1000steps/trainset_withx_1000stepsbis2.csv'))</span>
<span class="token comment">#</span>
<span class="token comment">#train_data3 = np.array(pd.read_csv('data_1000steps/trainset_withx_1000stepsbis3.csv'))</span>





<span class="token comment"># train_data = np.concatenate((train_data6,train_data5),axis = 0)</span>

<span class="token comment"># train_data = np.concatenate((train_data,train_data4),axis = 0)</span>

<span class="token comment"># train_data = np.concatenate((train_data,train_data3),axis = 0)</span>

<span class="token comment"># train_data = np.concatenate((train_data,train_data2),axis = 0)</span>

<span class="token comment"># train_data = np.concatenate((train_data,train_data1),axis = 0)</span>

<span class="token comment"># train_data = np.concatenate((train_data,train_data0),axis = 0)</span>

<span class="token comment"># train_data=train_data[:120000,:]</span>


<span class="token comment">#weightstrain_data[:,604:]</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>train_data <span class="token punctuation">)</span>

input_data <span class="token operator">=</span> train_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">603</span><span class="token punctuation">]</span>
output_data <span class="token operator">=</span> train_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">603</span><span class="token punctuation">:</span><span class="token punctuation">]</span>



<span class="token comment">########################################################################</span>
train_part <span class="token operator">=</span> <span class="token number">0.97</span>

threshold <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>train_part<span class="token operator">*</span>train_data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>


<span class="token comment">##########################################################################</span>

train_input <span class="token operator">=</span> input_data<span class="token punctuation">[</span><span class="token punctuation">:</span>threshold<span class="token punctuation">]</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"input_data shape: "</span><span class="token punctuation">,</span>input_data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

train_output <span class="token operator">=</span> output_data<span class="token punctuation">[</span><span class="token punctuation">:</span>threshold<span class="token punctuation">]</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"output_data shape: "</span><span class="token punctuation">,</span>output_data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>


test_input <span class="token operator">=</span> input_data <span class="token punctuation">[</span>threshold<span class="token punctuation">:</span><span class="token punctuation">]</span>

true_test_output <span class="token operator">=</span> output_data<span class="token punctuation">[</span>threshold<span class="token punctuation">:</span><span class="token punctuation">]</span>



X1 <span class="token operator">=</span> train_input
Y1 <span class="token operator">=</span> train_output

X2 <span class="token operator">=</span> test_input
<span class="token comment">#Y2 = ValidationSet_Y</span>

<span class="token comment">############################################################################</span>



<span class="token comment">#def my_loss_fn(y_true, y_pred):</span>
<span class="token comment">#    </span>
<span class="token comment">#    return K.mean(K.abs(y_true - y_pred) * weight)</span>

<span class="token comment"># ========================================================================================</span>
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> LSTM<span class="token punctuation">,</span>Dropout
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> TimeDistributed
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>callbacks <span class="token keyword">import</span> EarlyStopping
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>callbacks <span class="token keyword">import</span> ModelCheckpoint
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>optimizers <span class="token keyword">import</span> Adam




<span class="token comment"># save data</span>
<span class="token keyword">import</span> os
<span class="token keyword">import</span> json
<span class="token keyword">import</span> pickle

<span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isdir<span class="token punctuation">(</span><span class="token string">'save_data_v2'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
	os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span><span class="token string">'save_data_v2'</span><span class="token punctuation">)</span>

hidden_size<span class="token operator">=</span><span class="token number">200</span>

input_sample<span class="token operator">=</span>input_data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  <span class="token comment">#for one sample</span>


output_sample<span class="token operator">=</span>output_data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

input_data<span class="token operator">=</span>input_data<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>input_sample<span class="token punctuation">,</span><span class="token number">201</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>  <span class="token comment">#201 is the time steps in data_generation</span>
output_data<span class="token operator">=</span>output_data<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>output_sample<span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>

use_dropout<span class="token operator">=</span><span class="token boolean">True</span>
model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>LSTM<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span>input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">201</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># opt = Adam(lr=0.0001)</span>
model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">'mean_squared_error'</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span><span class="token string">'Adam'</span><span class="token punctuation">,</span> metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'mae'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

es<span class="token operator">=</span>EarlyStopping<span class="token punctuation">(</span>monitor<span class="token operator">=</span><span class="token string">'val_loss'</span><span class="token punctuation">,</span>mode<span class="token operator">=</span><span class="token string">'min'</span><span class="token punctuation">,</span>verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>patience<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span>
<span class="token comment"># modelcheckpoint</span>
mc<span class="token operator">=</span>ModelCheckpoint<span class="token punctuation">(</span><span class="token string">'save_data_v2/sequentiallstm200_ing.h5'</span><span class="token punctuation">,</span>monitor<span class="token operator">=</span><span class="token string">'val_loss'</span><span class="token punctuation">,</span>mode<span class="token operator">=</span><span class="token string">'min'</span><span class="token punctuation">,</span>save_best_only<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

history<span class="token operator">=</span>model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>input_data<span class="token punctuation">,</span> output_data<span class="token punctuation">,</span> validation_split<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>callbacks<span class="token operator">=</span><span class="token punctuation">[</span>es<span class="token punctuation">,</span>mc<span class="token punctuation">]</span><span class="token punctuation">)</span>




<span class="token comment"># model.save('save_data/sequentiallstm2')</span>
model<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">'save_data_v2/sequentiallstm200_ing_f.h5'</span><span class="token punctuation">)</span>

<span class="token comment"># https://stackoverflow.com/a/44674337/10349608</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'save_data_v2/sequentiallstm200_ing_history.pickle'</span><span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> file_his<span class="token punctuation">:</span>
	pickle<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>history<span class="token punctuation">.</span>history<span class="token punctuation">,</span> file_his<span class="token punctuation">)</span>


<span class="token comment"># Calculate predictions</span>
PredTestSet <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X1<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>X1<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">201</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
PredValSet <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X2<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>X2<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">201</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>




plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Model loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Epoch'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'Train'</span><span class="token punctuation">,</span> <span class="token string">'Test'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> loc<span class="token operator">=</span><span class="token string">'upper left'</span><span class="token punctuation">)</span>
<span class="token comment">#plt.savefig('figure_dp/loss_trace.eps', format='eps',bbox_inches='tight')</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>



plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>PredValSet<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>true_test_output<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token string">'o'</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'blue'</span><span class="token punctuation">,</span>markersize<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
<span class="token comment">#plt.plot(list(range(0,1,0.1)),list(range(0,1,0.1)),'k')</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>PredValSet<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>true_test_output<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token string">'o'</span><span class="token punctuation">,</span>color<span class="token operator">=</span><span class="token string">'blue'</span><span class="token punctuation">,</span>markersize<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
<span class="token comment">#plt.plot(list(range(0,1,0.1)),list(range(0,1,0.1)),'k')</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>



<span class="token comment"># predint = model.predict(train_input[:3000])</span>

<span class="token comment"># trueint = train_output[:3000]</span>


<span class="token comment"># plt.plot(predint[:,3],trueint[:,3],'o', color='blue',markersize=5)</span>
<span class="token comment"># #plt.plot(list(range(0,1,0.1)),list(range(0,1,0.1)),'k')</span>
<span class="token comment"># plt.show()</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="QT：Tensorflow-keras与keras的区别"><a href="#QT：Tensorflow-keras与keras的区别" class="headerlink" title="QT：Tensorflow-keras与keras的区别"></a>QT：Tensorflow-keras与keras的区别</h4><p>Tensorflow-keras与keras的区别：<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/135b2ee61a1c">https://www.jianshu.com/p/135b2ee61a1c</a></p>
<blockquote>
<p>如果你需要任何一个上述tf.keras的特有特性的话，那当然应该选择tf.keras。</p>
<p>如果后端可互换性对你很重要的话，那选择keras。</p>
<p>如果以上两条对你都不重要的话，那选用哪个都可以。</p>
</blockquote>
<h3 id="Shallow-water：希望能对lorenz中遇到的问题，得到启发"><a href="#Shallow-water：希望能对lorenz中遇到的问题，得到启发" class="headerlink" title="Shallow water：希望能对lorenz中遇到的问题，得到启发~"></a>Shallow water：希望能对lorenz中遇到的问题，得到启发~</h3><blockquote>
<p>算法1，没给出同化的具体程序~~🤮</p>
</blockquote>
<h3 id="2022-02-28：LSTM-Covariance-main-zip"><a href="#2022-02-28：LSTM-Covariance-main-zip" class="headerlink" title="2022-02-28：LSTM_Covariance-main.zip"></a>2022-02-28：LSTM_Covariance-main.zip</h3><blockquote>
<p>链接：<a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1Dtx-p4LRHhIGjTilVvgw-g">https://pan.baidu.com/s/1Dtx-p4LRHhIGjTilVvgw-g</a><br>提取码：8egl<br>–来自百度网盘超级会员V5的分享</p>
</blockquote>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        Author:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">Jincan</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        Link:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://Liu-Jincan.github.io/2022/02/25/yan-jiu-sheng-justtry-function/endnote-shu-ju-tong-hua/04-yue-du-code-shi-yong-xun-huan-shen-jing-wang-luo-jin-xing-shu-ju-tong-hua-de-guan-ce-wu-chai-xie-fang-chai-gui-fan-2021/">https://Liu-Jincan.github.io/2022/02/25/yan-jiu-sheng-justtry-function/endnote-shu-ju-tong-hua/04-yue-du-code-shi-yong-xun-huan-shen-jing-wang-luo-jin-xing-shu-ju-tong-hua-de-guan-ce-wu-chai-xie-fang-chai-gui-fan-2021/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        Reprint policy:
                    </i>
                </span>
                <span class="reprint-info">
                    All articles in this blog are used except for special statements
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    reprint policy. If reproduced, please indicate source
                    <a href="/about" target="_blank">Jincan</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>Copied successfully, please follow the reprint policy of this article</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">more</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            <span class="chip bg-color">No tag</span>
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">Thanks for your reward</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.png" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;Previous</div>
            <div class="card">
                <a href="/2022/02/28/yan-jiu-sheng-justtry-function/endnote-shu-ju-tong-hua/07-code-nansencenter-da-tutorials-2021/">
                    <div class="card-image">
                        
                        <img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220327135302.png" class="responsive-img" alt="07-阅读：nansencenter-DA-tutorials-2021">
                        
                        <span class="card-title">07-阅读：nansencenter-DA-tutorials-2021</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            ~~
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2022-02-28
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E6%95%B0%E6%8D%AE%E5%90%8C%E5%8C%96/" class="post-category">
                                    数据同化
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Next&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2022/02/25/yan-jiu-sheng-justtry-function/hai-yang-shu-ju/01-era5-shu-ju/">
                    <div class="card-image">
                        
                        <img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220327145128.png" class="responsive-img" alt="01-ERA5数据">
                        
                        <span class="card-title">01-ERA5数据</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            ~~
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2022-02-25
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E6%B5%B7%E6%B4%8B%E6%95%B0%E6%8D%AE/" class="post-category">
                                    海洋数据
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;TOC</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    });
</script>


    
    <!-- 05 footer是什么？页脚 -->
    <footer class="page-footer bg-color">
    <!-- 音乐  -->
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="6992203508"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
	style="margin-bottom: 15px !important;">
	
	
	
	
	
	<!--  copyright那本分的div -->
	<div class="col s12 m8 l8 copy-right">
            
            <!-- 这里是 Copyright @, &nbsp是空格, &copy是那个符号哟 -->
            <!-- https://zhidao.baidu.com/question/745714487580680772.html, JavaScript中的“&nbsp”是什么意思, 转义符号  -->
            Copyright&nbsp;&copy;
            
            <!-- 这里是2021, 默认的theme.time.year是2019,在这里我指定为2021,因为我是2021-12月份创建的博客,good job -->
            
            
                <span id="year">2021-2022</span>
            
            
            <!-- 这里是Jincan Liu, 还包括了对应的超链接哦 -->
            <a href="/about" target="_blank">Jincan Liu</a>
            
            <!-- 这里是关于 Hexo -->
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            
            <!-- 这里是关于 matery -->
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <!-- br表示换行, https://zhidao.baidu.com/question/187056327.html -->
            <br>
            
            <!-- 这里是为了显示站点总字数 -->
            
            	<!-- <i>标签是斜体作用, 这里是为了显示图形? -->
            	<!-- <span>是行内元素, span的意义是添加指定样式,详见https://blog.csdn.net/microcosmv/article/details/51953490 -->
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;Total Words:&nbsp;<span
                        class="white-color">480.7k</span>
            
            
            <!-- 不蒜子计数器的使用, https://blog.csdn.net/weixin_46247581/article/details/105848853, hexo s 中显示的不是正确的, 不用担心, 看 hexo d 上的即可 -->
            
            
                
            
                            
            <!-- 这显示总访问量 -->    <!-- 显示每篇文章的访问量的方法, https://blog.csdn.net/qq_23590921/article/details/103864482 -->
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;Total visits:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
            <!-- 这里显示总访问人数 -->
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;Total visitors:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
                         
            <br>

            <!-- 运行天数提醒. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2021";
                        var startMonth = "12";
                        var startDate = "20";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // 区分是否有年份.
                        var language = 'En';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = '本站已运行 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                daysTip = '本站已運行 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = '本站已运行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = '本站已運行 ' + diffYears + ' 年 ' + diffDays + ' 天';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
            <!-- 不知道干什么 -->
            
        </div>
	
	
	
	
		
	
	<!-- 联系图标的 div -->
        <div class="col s12 m4 l4 social-link social-statis">






    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=3079779149" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 3079779149" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>



    <a href="mailto:3079779149@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我: jincanliu@qq.com; jincan8liu@gmail.com" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>



    <a href="https://www.researchgate.net/profile/Jincan-Liu" class="tooltipped" target="_blank" data-tooltip="访问我的ResearchGate" data-position="top" data-delay="50">
        <i class="fab fa-researchgate"></i>
    </a>



    <a href="https://github.com/Liu-Jincan" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>






    <a href="https://www.zhihu.com/people/JincanLiu" class="tooltipped" target="_blank" data-tooltip="访问我的知乎" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">知</i>
    </a> 



    <a href="https://space.bilibili.com/341192538" class="tooltipped" target="_blank" data-tooltip="访问我的bilibili" data-position="top" data-delay="50">
        <i class="iconfont icon-bilibili-fill"></i>
    </a>



</div>        
        

    </div>
</footer>


<!-- 回到顶部的div -->
<div class="progress-bar"></div>


    <!-- 06 search是什么？搜索遮照栏 -->
    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    
    <!-- 07 back-top是什么？回到顶部按钮 -->
    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <!-- fa-arrow-up -->
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <!-- 08 ??? -->
    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>
    
    <!-- 09 图标绘制工具 -->
    

    <!-- 10 ???-->
    

    <!-- 11 雪花特效 -->
    

    <!-- 12 鼠标星星特效 -->
    


    <!-- 13 -->
     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- 14 -->
    <!-- Baidu Analytics -->

    
    <!-- 15 -->
    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <!-- 16 -->
    
    
    <!-- 17 -->
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    


    <!-- 18 -->
    
    
    <!-- 19 -->
    

    <!-- 20 腾讯兔小巢-->
    
    
    <!-- 21 canvas_nest特效 -->
    
	
    <!-- 22 ribbon特效 -->
    
    
    <!-- 23 -->
    

    <!-- 24 -->
    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
