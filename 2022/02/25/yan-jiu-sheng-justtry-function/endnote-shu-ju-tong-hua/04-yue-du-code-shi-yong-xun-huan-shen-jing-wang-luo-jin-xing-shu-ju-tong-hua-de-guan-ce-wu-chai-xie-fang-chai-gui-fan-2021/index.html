<!DOCTYPE HTML>
<!-- 01 è¯­è¨€é€‰æ‹© -->
<html lang="En">

<!-- 02 headæ˜¯å“ªé‡Œï¼Ÿok~~ï¼Œé¦–é¡µï¼Œåˆ†ç±»ï½ï½ -->
<!-- ä¸‹é¢çš„è¿™ä¸ªejsè¯­å¥ï¼Œæ·»åŠ ç½‘ç«™çš„headéƒ¨åˆ†ï¼Œå³ä¸»é¡µï¼Œåˆ†ç±»ç­‰åŠå…¶å›¾æ ‡ -->


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="04-é˜…è¯»ï¼šä½¿ç”¨å¾ªç¯ç¥ç»ç½‘ç»œè¿›è¡Œæ•°æ®åŒåŒ–çš„è§‚æµ‹è¯¯å·®åæ–¹å·®è§„èŒƒ-2021, Jincan">
    <meta name="description" content="~~">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>04-é˜…è¯»ï¼šä½¿ç”¨å¾ªç¯ç¥ç»ç½‘ç»œè¿›è¡Œæ•°æ®åŒåŒ–çš„è§‚æµ‹è¯¯å·®åæ–¹å·®è§„èŒƒ-2021 | Jincan</title>
    <link rel="icon" type="image/png" href="/favicon_hua.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    
    <!-- aliyunç½‘ç«™æ•™ç¨‹æ·»åŠ å›¾æ ‡æ‰€éœ€çš„å¯¼å…¥cssï¼Œæ”¾åˆ° matery ä¸­çš„ my.cssä¸­ -->
    <link rel="stylesheet" type="text/css" href="/css/my.css">
    
    
    
    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

     
<meta name="generator" content="Hexo 5.4.1">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>


<!-- 03 backgroundæ˜¯ä»€ä¹ˆï¼Ÿç½‘ç«™èƒŒæ™¯å›¾ -->



<body>
    <!--04 headeræ˜¯ä»€ä¹ˆï¼Ÿlogoï¼Œnavigationï¼Œgithublink -->
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo_hua.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Jincan</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>Index</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>Categories</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>Archives</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>About</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>Friends</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="Search" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo_hua.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Jincan</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			Index
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			Categories
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			Archives
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			About
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			Friends
		</a>
          
        </li>
        
        
    </ul>
</div>


        </div>

        
    </nav>

</header>

    
<script src="/libs/cryptojs/crypto-js.min.js"></script>
<script>
    (function() {
        let pwd = '';
        if (pwd && pwd.length > 0) {
            if (pwd !== CryptoJS.SHA256(prompt('è¯·è¾“å…¥è®¿é—®æœ¬æ–‡ç« çš„å¯†ç ')).toString(CryptoJS.enc.Hex)) {
                alert('å¯†ç é”™è¯¯ï¼Œå°†è¿”å›ä¸»é¡µï¼');
                location.href = '/';
            }
        }
    })();
</script>




<div class="bg-cover pd-header post-cover" style="background-image: url('https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220327135302.png')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">04-é˜…è¯»ï¼šä½¿ç”¨å¾ªç¯ç¥ç»ç½‘ç»œè¿›è¡Œæ•°æ®åŒåŒ–çš„è§‚æµ‹è¯¯å·®åæ–¹å·®è§„èŒƒ-2021</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        height: calc(100vh - 250px);
        overflow: scroll;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- æ–‡ç« å†…å®¹è¯¦æƒ… -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                          <div class="article-tag">
                            <span class="chip bg-color">No tag</span>
                          </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E6%95%B0%E6%8D%AE%E5%90%8C%E5%8C%96/" class="post-category">
                                æ•°æ®åŒåŒ–
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>Publish Date:&nbsp;&nbsp;
                    2022-02-25
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>Update Date:&nbsp;&nbsp;
                    2022-04-17
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>Word Count:&nbsp;&nbsp;
                    11.3k
                </div>
                

                

                
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- æ˜¯å¦åŠ è½½ä½¿ç”¨è‡ªå¸¦çš„ prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="07-é˜…è¯»ï¼šä½¿ç”¨å¾ªç¯ç¥ç»ç½‘ç»œè¿›è¡Œæ•°æ®åŒåŒ–çš„è§‚æµ‹è¯¯å·®åæ–¹å·®è§„èŒƒ-2021"><a href="#07-é˜…è¯»ï¼šä½¿ç”¨å¾ªç¯ç¥ç»ç½‘ç»œè¿›è¡Œæ•°æ®åŒåŒ–çš„è§‚æµ‹è¯¯å·®åæ–¹å·®è§„èŒƒ-2021" class="headerlink" title="07-é˜…è¯»ï¼šä½¿ç”¨å¾ªç¯ç¥ç»ç½‘ç»œè¿›è¡Œæ•°æ®åŒåŒ–çš„è§‚æµ‹è¯¯å·®åæ–¹å·®è§„èŒƒ-2021"></a><center>07-é˜…è¯»ï¼šä½¿ç”¨å¾ªç¯ç¥ç»ç½‘ç»œè¿›è¡Œæ•°æ®åŒåŒ–çš„è§‚æµ‹è¯¯å·®åæ–¹å·®è§„èŒƒ-2021</center></h1><h2 id="å‚è€ƒèµ„æ–™"><a href="#å‚è€ƒèµ„æ–™" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h2><ul>
<li><p>è‹±æ–‡åï¼š<strong>Observation error covariance specification in dynamical systems for data assimilation using recurrent neural networks</strong></p>
</li>
<li><p>æœŸåˆŠï¼šã€ŠNeural Computing and Applicationsã€‹ï¼ŒLetPubï¼Œ<a target="_blank" rel="noopener" href="https://www.letpub.com.cn/index.php?page=journalapp&amp;view=search">https://www.letpub.com.cn/index.php?page=journalapp&amp;view=search</a></p>
<blockquote>
<p>è¿™ä¸ªæœŸåˆŠå¥½åƒä¸é”™~~</p>
</blockquote>
</li>
<li><p>ä½œè€…ï¼šSibo Chengï¼Œ Mingming Qiu</p>
</li>
<li><p>æ¥è‡ªäºWjcè€å¸ˆçš„åˆ†äº«ï¼Œç”¨äº<strong>2022åˆ›æ–°åŸºé‡‘</strong>çš„æ€è€ƒçš„å‡ºå‘ç‚¹ï¼› </p>
</li>
<li><p><code>è°·æ­Œæµè§ˆå™¨æ— æ³•é˜…è¯»çš„å…¬å¼ï¼Œç«ç‹æµè§ˆå™¨å¯ä»¥~~~ğŸ˜ï¼Œä½†æ˜¯ç¿»è¯‘è´¨é‡æ²¡æœ‰è°·æ­Œç¿»è¯‘å¥½â”­â”®ï¹â”­â”®</code></p>
</li>
<li><p><code>æ€ç»´æµè®°å½•æ›´å¥½å§~</code></p>
</li>
</ul>
<h2 id="Abstract"><a href="#Abstract" class="headerlink" title="Abstract"></a>Abstract</h2><p>Data assimilation techniques are widely used to predict complex dynamical systems with uncertainties, based on timeseries observation data. <strong>Error covariance matrices modeling</strong> is an important element in data assimilation algorithms which can considerably impact the forecasting accuracy. The estimation of these covariances, which usually relies on <strong>empirical assumptions</strong> and <strong>physical constraints</strong>, is often imprecise and computationally expensive, especially for systems of large dimensions. In this work, we propose a <strong>data-driven approach based on long short term memory (LSTM) recurrent neural networks (RNN)</strong> to improve both the accuracy and the efficiency of observation covariance specification in data assimilation for dynamical systems. </p>
<blockquote>
<ul>
<li><code>è¯¯å·®åæ–¹å·®çŸ©é˜µå»ºæ¨¡æ˜¯æ•°æ®åŒåŒ–ç®—æ³•ä¸­çš„ä¸€ä¸ªé‡è¦å…ƒç´ ï¼Œå®ƒä¼šæå¤§åœ°å½±å“é¢„æµ‹çš„å‡†ç¡®æ€§ã€‚</code></li>
<li><code>è¿™äº›åæ–¹å·®çš„ä¼°è®¡é€šå¸¸ä¾èµ–äºç»éªŒå‡è®¾å’Œç‰©ç†çº¦æŸï¼Œé€šå¸¸ä¸ç²¾ç¡®ä¸”è®¡ç®—æˆæœ¬å¾ˆé«˜ï¼Œå°¤å…¶æ˜¯å¯¹äºå¤§å°ºå¯¸ç³»ç»Ÿã€‚</code></li>
</ul>
</blockquote>
<p>Learning the covariance matrix from observed/simulated time-series data, the proposed approach <strong>does not require any knowledge or assumption about prior error distribution</strong>, unlike classical posterior tuning methods. </p>
<blockquote>
<ul>
<li><code>ä¸ç»å…¸çš„åéªŒè°ƒæ•´æ–¹æ³•ä¸åŒï¼Œæ‰€æå‡ºçš„æ–¹æ³•ä¸éœ€è¦ä»»ä½•å…³äºå…ˆéªŒè¯¯å·®åˆ†å¸ƒçš„çŸ¥è¯†æˆ–å‡è®¾ã€‚</code></li>
</ul>
</blockquote>
<p>We have compared the novel approach with <strong>two state-of-the-art covariance tuning algorithms, namely DI01 and D05</strong>, first in a <strong>Lorenz dynamical system</strong> and then in a <strong>2D shallow water</strong> twin experiments framework with different covariance parameterization using ensemble assimilation. </p>
<blockquote>
<ul>
<li><code>ä¸¤ç§æœ€å…ˆè¿›çš„åæ–¹å·®è°ƒæ•´ç®—æ³•ï¼ˆå³ DI01 å’Œ D05ï¼‰</code></li>
<li><code>Lorenz åŠ¨åŠ›ç³»ç»Ÿ</code></li>
<li><code>äºŒç»´æµ…æ°´å­ªç”Ÿå®éªŒ</code></li>
</ul>
</blockquote>
<p>This novel method shows significant advantages in observation covariance specification, assimilation accuracy, and computational efficiency.</p>
<blockquote>
<ul>
<li><code>æ–°æ–¹æ³•åœ¨è§‚æµ‹åæ–¹å·®è§„èŒƒã€åŒåŒ–ç²¾åº¦å’Œè®¡ç®—æ•ˆç‡æ–¹é¢å…·æœ‰æ˜¾ç€ä¼˜åŠ¿ã€‚</code></li>
</ul>
</blockquote>
<h2 id="Acknowledgments"><a href="#Acknowledgments" class="headerlink" title="Acknowledgments"></a>Acknowledgments</h2><p>S.Cheng would like to thank Dr. D.Lucor, Dr. J-P.Argaud, Dr. B.Iooss, and Dr. A.PoncÂ¸ot for <strong>fruitful discussions about the error covariance computation</strong>. This research was supported by EDF R&amp;D. This research was partially funded by the Leverhulme Centre for Wildfires, Environment and Society through the Leverhulme Trust, grant number RC-2018-023.</p>
<h2 id="Declarations-with-code"><a href="#Declarations-with-code" class="headerlink" title="Declarations (with code)"></a>Declarations (with code)</h2><p><strong>Conflict of interest statement</strong></p>
<p>â€¦</p>
<p><strong>Code availability</strong> </p>
<p>Code for the proposed LSTM-based covariance specification, together with DI01, D05 methods, for both Lorenz and shallow water models is available at <a target="_blank" rel="noopener" href="https://github.com/scheng1992/">https://github.com/scheng1992/</a> LSTM_Covariance.</p>
<p><strong>Contribution statement</strong></p>
<p>â€¦</p>
<p><strong>Open Access</strong></p>
<p>â€¦</p>
<h2 id="9-Discussion"><a href="#9-Discussion" class="headerlink" title="9 Discussion"></a>9 Discussion</h2><p>The precision of DA reconstruction/prediction depends heavily on the specification of both the background and the observation error correlation. The latter is often challenging to estimate in real-world applications because of the dynamic nature of the observation data. Furthermore, the observation matrix $\mathbf{R}$ can not be empirically estimated from an ensemble of simulated trajectories, unlike the background error covariance. In this paper, we review in detail some well-known <strong>observation covariance tuning algorithms</strong> <strong>[23, 54]</strong>, based on <strong>time-variant posterior innovation quantities</strong>. These methods, being widely adopted in geoscience, rely on some <strong>specific prior assumptions</strong> such as knowledge of the <strong>correlation structure</strong> <strong>[23]</strong> or the <strong>background matrix</strong> <strong>[24]</strong>. This is difficult to fulfill in some domains where very little knowledge about the prior error is available.</p>
<blockquote>
<ul>
<li><code>ä¸ºä»€ä¹ˆï¼Ÿï¼šè§‚å¯ŸçŸ©é˜µ R ä¸èƒŒæ™¯è¯¯å·®åæ–¹å·®ä¸åŒï¼Œä¸èƒ½ä»æ¨¡æ‹Ÿè½¨è¿¹çš„é›†åˆä¸­å‡­ç»éªŒä¼°è®¡</code></li>
<li><code>ä»€ä¹ˆæ˜¯ï¼Ÿï¼šæ—¶å˜åéªŒåˆ›æ–°é‡</code></li>
</ul>
</blockquote>
<p>In this study, we have proposed a novel machine learning approach based on LSTM neural networks to predict the $\mathbf{R}$ matrix using time series observation data as model input. Similar to the work of <strong>[23, 24]</strong>, $\mathbf{R}$ is assumed to be <strong>time-invariant, at least over a sufficiently long time period</strong>. Both the <strong>Kalman- and variational-type assimilation methods</strong> can benefit from the method proposed in this paper for improving the assimilation accuracy. The proposed data-driven approach also contributes to tackling <strong>one of the major bottlenecks of DA: it is time-consuming and computationally expensive to update covariance matrix, by mapping raw sensor observations to observation error covariance matrix</strong>. In both the Lorenz96 and the shallow water models presented in this paper, the LSTM-based approach displays significant strength, compared to classical posterior tuning methods DI01 and D05, in terms of: </p>
<ul>
<li>(i) estimation accuracy of the observation covariance $\mathbf{R}$; </li>
<li>(ii) reconstruction and prediction accuracy of the DA schema, using the estimated $\mathbf{R}$ matrix; </li>
<li>(iii) computational efficiency of the online covariance estimation; </li>
<li>(iv) flexibility of different model parameterization. It is worth mentioning that an important limitation of the proposed LSTM-based method is the specification of $\Phi_{\mathbf{R}}$ which defines the range of parameters for training.</li>
</ul>
<blockquote>
<ul>
<li><code>-&gt; å¾ˆå¼ºå¤§ï¼Œå¯ä»¥åšå¾ˆå¤šè¿™æ–¹é¢çš„å·¥ä½œ</code></li>
</ul>
</blockquote>
<p>Since we assume that the observation matrix is timeinvariant, the proposed approach could <strong>only deal with fixed sensor placement for dynamical systems</strong>, which is also the case of DI01 and D05 tuning algorithms. The possibility of time-variant sensor placement warrants further investigation. As pointed out by <strong>[55]</strong>, the DL model can be stolen or reverse engineered, by model inversion or model extraction attack. Despite the fact that all data used in the current study is generated from <strong>toy models</strong>, it is important to ensure the data privacy when applying the model to real applications. </p>
<blockquote>
<ul>
<li><code>é™åˆ¶åªèƒ½åœ¨ç©ºé—´ç‚¹ä¸Šè¿›è¡Œï¼Ÿï¼šåªèƒ½å¤„ç†åŠ¨æ€ç³»ç»Ÿçš„å›ºå®šä¼ æ„Ÿå™¨æ”¾ç½®</code></li>
</ul>
</blockquote>
<p>Future research should also consider applying the new method to a broader range of real-world problems, including <strong>NWP</strong>, hydrology, and object tracking, where the offline data simulation could be more computationally expensive compared to the two test models presented in this paper. To this end, future studies could also investigate <strong>the combination of model reduction methods</strong>, such as <strong>domain localization [56]</strong>, <strong>proper orthogonal decomposition</strong>, <strong>information-based data compression [57]</strong>, <strong>auto-encoder neural networks [58]</strong>, and <strong>the current covariance estimation method</strong>. More precisely, the data assimilation can be performed in the compressed low dimensional space (e.g., obtained from <strong>POD</strong> or auto-encoder). The <strong>LSTM-based</strong> covariance specification algorithm developed in this work can be used to estimate the observation error covariance matrices in the low dimensional space for improving the accuracy of reduced-order data assimilation approaches.</p>
<blockquote>
<ul>
<li><code>æ›´å¹¿æ³›çš„ç°å®é—®é¢˜</code></li>
<li><code>åˆ›æ–°å·¥ä½œï¼šä¸ºäº†å‡å°‘è®¡ç®—æˆæœ¬ï¼Œå‹ç¼©çš„ä½ç»´ç©ºé—´</code></li>
</ul>
</blockquote>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1 Introduction"></a>1 Introduction</h2><p>In order to <strong>improve the reconstruction and prediction of dynamical systems with uncertainties</strong>, <strong>data assimilation (DA) techniques</strong>, originally developed in <strong>numerical weather prediction (NWP) [1]</strong> and geosciences [2], are widely applied to industrial problems, such as hydrology [3], wildfire forecasting [4], drought monitoring[5] and nuclear engineering [6]. </p>
<ul>
<li><p>DA algorithms aim to find the optimal approximation (also known as the analyzed state) of the state variables (usually representing a physical field of interest, such as velocity, temperature, etc.,), relying on prior estimations and real-time observations, both assumed to be noisy. Due to the large dimension (often ranging from $10^6$ to $10^{10}$ in NWP and geoscience problems), <strong>prior errors are supposed to be Gaussian distributed</strong> for the sake of simplicity [7]. As a consequence, the prior error distribution can be perfectly characterized by the <strong>first (mean) and the second (covariance)</strong> moment. </p>
<blockquote>
<p><code>DAç®—æ³•ï¼šæ”¹è¿›å…·æœ‰ä¸ç¡®å®šæ€§çš„åŠ¨åŠ›ç³»ç»Ÿçš„é‡å»ºå’Œé¢„æµ‹ï¼Œä¾é å…ˆå‰çš„ä¼°è®¡å’Œå®æ—¶è§‚å¯Ÿæ¥æ‰¾åˆ°çŠ¶æ€å˜é‡ï¼Œä¸ºäº†ç®€å•èµ·è§ï¼Œå…ˆéªŒè¯¯å·®åº”è¯¥æ˜¯é«˜æ–¯åˆ†å¸ƒçš„</code></p>
</blockquote>
</li>
<li><p>The output of the DA algorithms is determined through some <strong>optimization function</strong> where <strong>the weight of prior simulations and observations is determined by the associated error covariance matrices, respectively named as background and observation covariances</strong>. </p>
<p><code>è§£é‡Šäº†DAä¸­è¯¯å·®åæ–¹å·®çŸ©é˜µçš„å®è´¨ï¼šæ¨¡æ‹Ÿå’Œè§‚å¯Ÿçš„æƒé‡ç”±ç›¸å…³çš„è¯¯å·®åæ–¹å·®çŸ©é˜µç¡®å®šï¼Œåˆ†åˆ«ç§°ä¸ºèƒŒæ™¯å’Œè§‚å¯Ÿåæ–¹å·®ã€‚</code></p>
</li>
<li><p>These error covariance matrices thus <strong>provide crucial information</strong> in DA algorithms [8], for not only the <strong>estimation of the analyzed state but also specifying posterior error distributions</strong> [9]. </p>
<blockquote>
<p><code>DAä¸­è¯¯å·®åæ–¹å·®çŸ©é˜µçš„æ„ä¹‰ï¼šä¸ä»…ç”¨äºä¼°è®¡åˆ†æçŠ¶æ€ï¼Œè¿˜ç”¨äºæŒ‡å®šåéªŒè¯¯å·®åˆ†å¸ƒ</code></p>
</blockquote>
</li>
<li><p>The prior errors represented by these matrices, especially in the case of observation errors, consisting of an ensemble of different sources of noise/uncertainties, including model error, instrument noise, and representativity error [10, 11].</p>
<blockquote>
<p><code>ç”¨çŸ©é˜µè¡¨ç¤ºçš„å…ˆéªŒè¯¯å·®åŒ…å«å“ªäº›ï¼šæ¨¡å‹è¯¯å·®ã€ä»ªå™¨å™ªå£°å’Œä»£è¡¨æ€§è¯¯å·®</code></p>
</blockquote>
</li>
</ul>
<p>In statistics, the covariance matrix of a random vector is often obtained via empirical estimation where <strong>a sufficient number of simultaneous samplings</strong> is required to avoid estimation bias [12]. Moreover, when the sampling number is inferior to the problem dimension, the estimated covariance will be <strong>rank deficient</strong>. In DA problems, <strong>the high dimensionality and lack of simultaneous data (i.e., several backgrounds or observation trajectories in the same time window) represent significant obstacles of covariance computation in data assimilation</strong> [13]. </p>
<blockquote>
<ul>
<li><code>DAä¸­åæ–¹å·®è®¡ç®—çš„é‡å¤§éšœç¢ï¼šé«˜ç»´å’Œç¼ºä¹åŒæ—¶æ•°æ®</code></li>
</ul>
</blockquote>
<p>To overcome these difficulties, we often rely on <strong>calibration (e.g., least-square) methods based on some generic correlation kernels</strong>, often with <strong>homogeneous and isotropic characteristics</strong> [14]. </p>
<ul>
<li><p>Balanced operators can be employed for <strong>multivariate systems</strong> [15]. </p>
</li>
<li><p>In terms of correlation kernels, <strong>the family of MatÃ©rn functions</strong>, including the Exponential kernel (MatÃ©rn 1/2), the Balgovind kernel (MatÃ©rn  3/2, also known as second-order auto-regressive (SOAR) function), and the Gaussian kernel (MatÃ©rn  5/2), is often prioritized for covariance computing <strong>owing to its smoothness and capability to capture spatial correlations in physical processes</strong> [10, 16, 17]. </p>
</li>
<li><p><strong>Other stationary covariance models</strong> involve, for instance, <strong>convolution formulation</strong> [18] or <strong>diffusion-based operators</strong> [19], both contribute to an efficient storage of the covariance matrices. However, limited by homogeneous and isotropic assumptions, it remains cumbersome to represent complex spatial correlation (often multi-dimensional and multivariate) using <strong>these one-dimensional kernels</strong>.</p>
</li>
</ul>
<blockquote>
<ul>
<li><code>è§£å†³DAä¸­åæ–¹å·®è®¡ç®—é‡å¤§éšœç¢çš„ç»å…¸æ–¹æ³•</code></li>
</ul>
</blockquote>
<p>In this study, we develop and test a novel data-driven approach based on recurrent neural networks (RNNs) to improve both <strong>the accuracy and the efficiency of observation covariance specification</strong> in dynamical data assimilation problems. The novel approach is tested and compared with <strong>two state-of-the-art covariance tuning algorithms</strong> in two different digital experiments with <strong>parametric and nonparametric covariance estimation</strong>, respectively.</p>
<blockquote>
<ul>
<li><code>æœ¬æ–‡åˆ›æ–°ç‚¹~ï¼Œæ–°çš„æ–¹æ³•ï¼Œè¿›è¡ŒåŒåŒ–åæ–¹å·®çš„è®¡ç®—~</code></li>
</ul>
</blockquote>
<p>The paper is organized as follows. In Section 2, we introduce the related work for error covariance specification. The problem statement and the contribution of this paper are described in Section 3. Data assimilation techniques and the ensemble methods are introduced briefly in Section 4. We then describe traditional posterior covariance tuning algorithms DI01 and D05 in Section 5. The novel LSTM-based method is introduced in Section 6, followed by the comparison in the Lorenz (Section 7) and the shallow water twin experiments (Section 8). We close the paper with a discussion in Section 9.</p>
<h2 id="2-Related-work"><a href="#2-Related-work" class="headerlink" title="2 Related work"></a>2 Related work</h2><p>To gain a clearer insight into covariance evolution, </p>
<ul>
<li><p>some <strong>ensemble-based methods such as [1] (NMC) and [20] (EnKF)</strong>, have been developed to provide a <strong>non-parametric covariance estimation</strong>. These methods depend on <strong>the propagation of an ensemble of simulated trajectories</strong>, initialized either at different forecasting time steps (NMC) or by adding some artificially set perturbations to the current state (EnKF). <strong>These methods are more appropriate for modeling the background matrix compared rather than the observation matrix</strong>. The latter, independent from the numerical simulations, can not be represented by the propagation of artificially added noises. </p>
</li>
<li><p><strong>The Particle-Aided Unscented Kalman Filter [21]</strong> can estimate systems with high nonlinearity with a real-time updating of the background matrix. However, the observation matrix can not be estimated directly via the Particle-Aided Unscented Kalman Filter. </p>
<blockquote>
<p><code>ä¸Šé¢ä¸¤ç‚¹è¯´æ˜ï¼ŒNFCï¼ŒEnKF,PAUKF,è¿™äº›æ–¹æ³•æ˜¯é€‚ç”¨äºèƒŒæ™¯è¯¯å·®åæ–¹å·®çš„ï¼Œä¸é€‚ç”¨äºè§‚æµ‹è¯¯å·®åæ–¹å·®ã€‚</code></p>
</blockquote>
</li>
<li><p>In practice, the observation matrix is often set to be <strong>diagonal or spatially isotropic</strong> for the sake of simplicity (e.g. [22]). However, it is shown in the work of [10] that <strong>well-specified correlated observation covariances</strong> can significantly improve the performance of DA algorithms.</p>
<blockquote>
<p><code>è¿™ä¸€ç‚¹è¯´æ˜ï¼Œç®€å•çš„è§‚æµ‹è¯¯å·®åæ–¹å·®æ˜¯ä¸å¤Ÿå¥½çš„ã€‚</code></p>
</blockquote>
</li>
</ul>
<p>Several methods of <strong>data-derived posterior diagnosis</strong> have also been developed <strong>based on the analysis of innovation quantities</strong>.(The innovation quantities consist of the difference <strong>between the observations and the projected background/analyzed state in the observation space</strong>). </p>
<blockquote>
<ul>
<li><code>innovation quantitiesï¼Œåº”è¯¥æ˜¯ä¸ªä¸“æœ‰åç§°ï¼Œå¯èƒ½ä¸å«åˆ›æ–°é‡ï¼Œå¯èƒ½å¯ä»¥åœ¨åŒåŒ–è¯¾ç¨‹é‚£ä¸ªpdfç¬”è®°ä¸­æ‰¾åˆ°ç›¸å…³çš„ä»‹ç»</code></li>
</ul>
</blockquote>
<ul>
<li><p>As a strong contributor to this topic, the meteorology community developed several well-known <strong>posterior diagnoses and their improved versions</strong> [23â€“25] to <strong>adjust the background/observation ratio</strong>, <strong>the correlation scale length</strong>, or <strong>the full covariance structure in the observation space</strong> (both the observation matrix and the projected background matrix). </p>
</li>
<li><p>Some iterative processes [26, 27] based on the <strong>fixed-point theory</strong> have also been proposed for <strong>error covariance tuning</strong>. </p>
<p>Recent works of [28, 29] have proved the convergence of so-called <strong>Desroziers iterative methods[24] (also known as D05)</strong> in the ideal case. In brief, they have mathematically proved that, by using a semi-positive definite matrix as an initial guess, D05 iterative method converges on the <strong>exact time-invariant (at least over a sufficiently long time period) observation error covariance</strong>, when the background matrix and the transformation operator (which maps the state variables to real-time observations) are perfectly known <strong>a priori</strong>.  (Here, by the term â€˜â€˜exactâ€™â€™, we refer to the covariance truly corresponding to the remaining errors present in the observation space). </p>
<p>On the other hand, it is also mentioned by [29] that <strong>a regularization step</strong> is necessary for practice for applying D05 and the convergence of the regularized iterations remains an open question [3, 29]. </p>
</li>
<li><p>To deal with <strong>timevarying systems</strong>, <strong>lag-innovation statistics</strong> are used for error covariance estimation [30]. The essential idea is to build a secondary Kalman-filtering process for adjusting error covariances using time-shifted innovation vectors. </p>
</li>
<li><p>For <strong>more details of the innovation-based methods</strong>, we refer to the overview of [13] which also covers some other estimation methods, such as the family of <strong>likelihood-based approaches</strong> and <strong>expectation-maximum(EM) methods</strong>.</p>
</li>
</ul>
<h2 id="3-Problem-statement-and-contribution-ï¼ˆQï¼‰"><a href="#3-Problem-statement-and-contribution-ï¼ˆQï¼‰" class="headerlink" title="3 Problem statement and contribution ï¼ˆQï¼‰"></a>3 Problem statement and contribution ï¼ˆQï¼‰</h2><p>Our work lies in a similar condition of [24, 29] where both the state <strong>forward model</strong> and the <strong>transformation operator</strong> are presumed to be well known. </p>
<blockquote>
<p><code>â†‘ å‰å‘æ¨¡å‹ï¼Œåº”è¯¥æ˜¯åŠ¨åŠ›æ¨¡å¼ï¼Œæœ¬æ–‡æ˜¯Mçš„æ–œä½“åŠ ç²—</code></p>
<p><code>â†‘ è½¬æ¢ç®—å­ï¼Œåº”è¯¥æ˜¯è§‚æµ‹ç®—å­ï¼Œæœ¬æ–‡æ˜¯Hçš„æ–œä½“ï¼Œçº¿æ€§æ˜¯H</code></p>
</blockquote>
<ul>
<li><p>As the main difficulty concerns the <strong>non-synchronous time-variant observations</strong> in dynamical systems (which prevents empirical estimation), in this work we propose <strong>the use of recurrent neural networks (RNNs) [31]</strong> for <strong>the specification of the observation matrix across the underlying dynamics of the observed quantities</strong>. </p>
</li>
<li><p>RNN has been widely adapted for <strong>the prediction/reconstruction of dynamical systems</strong>, especially in <strong>natural language processing (NLP)</strong> [32] and image/video processing [33] due to its convincing capacity for dealing with time series. More recently, RNN has also made their way to other engineering fields such as biomedical applications and computational fluid mechanics [34]. </p>
<blockquote>
<p><code>â†‘ RNN çš„ä¼˜ç‚¹ï¼Œå¹¿æ³›è¢«åº”ç”¨</code></p>
</blockquote>
</li>
<li><p>In general, the combination of deep learning and data assimilation methods [35, 36] has been widely adapted and analyzed in a variety of industrial applications, including air pollution [37] and ocean-atmosphere modeling [38]. </p>
</li>
<li><p><strong>A convolutional neural network (CNN) for covariance estimation</strong> has also been suggested in the work of [39]. </p>
</li>
<li><p>In this study, we propose a novel methodology for <strong>LSTM-based covariance estimation</strong> which can be easily integrated into any DA schema for dynamical systems. </p>
<blockquote>
<p><code>Qï¼šâ†‘ æ–°æ–¹æ³•ï¼ŒçœŸçš„å¾ˆå®¹æ˜“ç”¨è¿›å»å—ï¼Ÿ~</code></p>
</blockquote>
<p>Here, we first construct a set of <strong>training covariance matrices</strong>, being either parametric or non-parametric, within a certain range defined <strong>a priori</strong>. For each matrix in the training set, we then <strong>simulate a dynamic trajectory</strong> of the observation vector relying on the knowledge of the forward model where the noises at each time step are generated following a centered Gaussian distribution characterized by the error covariance. These trajectories are later used as input variables to train the long-short-term-memory (LSTM) RNN regression model where <strong>the time-invariant observation matrices stand for the learning target</strong>. For <strong>the online evaluation</strong>, only the historical observation data is needed to predict the error covariances. </p>
<blockquote>
<p><code>â†‘ æ–°æ–¹æ³•ï¼Œå®ç°è¿‡ç¨‹</code></p>
</blockquote>
<p>Compared to traditional posterior tuning methods [24, 40] which require several implementations of DA algorithms, the proposed machine learning (ML) method can be <strong>much more computationally efficient for real-time covariance estimation</strong>. Moreover, <strong>no prior knowledge concerning either the background or the observation matrix</strong> is necessary for the proposed ML approach unlike most of the traditional methods. For example, DI01 [23] requires precise knowledge of correlation structures for both background and observation matrices while D05 [24] make use of the perfect knowledge of the background covariance.</p>
<blockquote>
<p><code>â†‘ æ–°æ–¹æ³•ï¼Œä¸ä¼ ç»Ÿæ–¹æ³•çš„å¯¹æ¯”ï¼Œæ–°æ–¹æ³•çš„ä¼˜åŠ¿</code></p>
</blockquote>
</li>
</ul>
<p>In order to make a comprehensive comparison with traditional methods, <strong>two different twin experiment frameworks</strong> are implemented in this paper, using respectively <strong>the Lorenz96 and the 2D shallow-water models</strong>. </p>
<ul>
<li><p>The Lorenz system, characterized by only three state variables, is associated with <strong>a non-parametric covariance modeling</strong> while we use <strong>an isotropic correlation kernel</strong> to parameterize the observation matrix in the shallow water dynamics. </p>
<blockquote>
<p><code>â†‘ éå‚æ•°åŒ–æ–¹æ³•å’Œå„å‘åŒæ€§ç›¸å…³æ ¸ï¼Œä¸¤ç§æ–¹æ³•çš„åŒºåˆ«ï¼Ÿ</code></p>
</blockquote>
</li>
<li><p>In both cases, we compare the performance of the proposed <strong>LSTM-based method</strong> against the state-of-the-art tuning approaches D05 and DI01 in terms of both the covariance specification and the posterior DA accuracy. </p>
</li>
<li><p>An <strong>ensemble DA schema</strong> is used for estimating t<strong>he time-variant background matrix</strong> for each of these methods.</p>
<blockquote>
<p><code>â†‘ é€‰å–çš„æ˜¯é›†åˆDAæ–¹æ³•ï¼Œä¼°è®¡æ—¶å˜èƒŒæ™¯çŸ©é˜µ</code></p>
</blockquote>
</li>
</ul>
<h2 id="4-Data-assimilation-ï¼ˆQï¼‰"><a href="#4-Data-assimilation-ï¼ˆQï¼‰" class="headerlink" title="4 Data assimilation ï¼ˆQï¼‰"></a>4 Data assimilation ï¼ˆQï¼‰</h2><h3 id="4-1-Principle-of-data-assimilation-ï¼ˆQï¼‰"><a href="#4-1-Principle-of-data-assimilation-ï¼ˆQï¼‰" class="headerlink" title="4.1 Principle of data assimilation ï¼ˆQï¼‰"></a>4.1 Principle of data assimilation ï¼ˆQï¼‰</h3><blockquote>
<p><code>åœ¨markdownä¸­å¦‚ä½•åŠ å…¥ä¸Šæ ‡ã€ä¸‹æ ‡ï¼Ÿï¼š</code></p>
<p><code> ç”¨å…¬å¼ï¼Œç½‘é¡µç¿»è¯‘ä¼šå‡ºé—®é¢˜ï¼Œä¸ç”¨å…¬å¼çš„æ–¹æ³• https://www.jianshu.com/p/13b3366f0260</code></p>
</blockquote>
<p>The objective of data assimilation algorithms is to approach the estimation of systemâ€™s states <strong>x</strong> to its true values <strong>x<sub>true</sub></strong>, also known as the true state, by taking advantage of <strong>two sources of information</strong>: </p>
<ul>
<li>the prior estimation or forecast <strong>x<sub>b</sub></strong>, which is also called the background state, </li>
<li>and the measurement or observation <strong>y</strong>. </li>
</ul>
<p>DA algorithms aim to find an optimally weighted compromise between <strong>x<sub>b</sub></strong> and <strong>y</strong> by minimizing the lost function <em><strong>J</strong></em> defined as:</p>
<blockquote>
<p><code>Qï¼šâ†“ ä¸ºä»€ä¹ˆJæ˜¯è¿™ä¸ªå½¢å¼ï¼Ÿ</code></p>
</blockquote>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225144725.png" style="zoom:72%;">

<p>where <em><strong>H</strong></em> denotes the transformation operator from the state space to observation space. <strong>B</strong> and <strong>R</strong> are, respectively, the background and the observation error covariance matrices, i.e.</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225150048.png" style="zoom:72%;">

<p>Errors <strong>Îµ<sub>b</sub>, Îµ<sub>y&nbsp;</sub></strong> are supposed to be <strong>centered Gaussian</strong> following:</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225150304.png" style="zoom:72%;">

<blockquote>
<p><code>â†‘ å‡è®¾1ï¼šé«˜æ–¯åˆ†å¸ƒ</code></p>
</blockquote>
<p>In <strong>Eq 1</strong>, the left side strives for incorporating the prior information <strong>x<sub>b</sub></strong> , and the right side penalizes the difference between the observation <strong>y</strong> and the state variables after having been mapped to the observation space <em><strong>H(x)</strong></em> . Both terms are weighted by the corresponding inverse of error covariance matrix (<strong>B<sup>-1</sup></strong>, <strong>R<sup>-1</sup></strong>) to <strong>reflect confidences for each of them</strong>.</p>
<p>The optimization problem of <strong>Eq 1</strong>, so called <strong>three-dimensional variational (3D-Var)</strong> formulation, is a general representation of variational assimilation which <strong>does not take into account model errors</strong>. The output of <strong>Eq 1</strong> is denoted as <strong>x<sub>a</sub></strong>, i.e.</p>
<blockquote>
<p><code>â†‘ Qï¼šæ¨¡å¼è¯¯å·®ï¼Œæ˜¯ä»€ä¹ˆï¼Ÿ</code></p>
</blockquote>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225150829.png" style="zoom:72%;">

<p>If <em><strong>H</strong></em> is the <strong>linear observation operator</strong> represented by <strong>H</strong> , <strong>Eq 6</strong> can be solved via <strong>BLUE (Best Linearized Unbiased Estimator)</strong> formulation:</p>
<blockquote>
<p><code>â†‘ å‡è®¾2ï¼šçº¿æ€§è§‚æµ‹ç®—å­</code></p>
</blockquote>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225151004.png" style="zoom:72%;">

<p>where <strong>A</strong> =Cov( <strong>x<sub>a</sub></strong>- <strong>x<sub>true</sub></strong>) is the analyzed error covariance, and <strong>K</strong> is the <strong>Kalman gain matrix</strong> described by </p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225151432.png" style="zoom:72%;">

<p>In the rest of this paper, we define <strong>H</strong> as a linear transformation operator. Nevertheless, it is usually more challenging to find the minimum of <strong>Eq 1</strong> when <strong>H</strong> is nonlinear, even more, challenging when states are high-dimensional. The solution for the minimization often involves <strong>gradient descent algorithms such as â€˜â€˜L-BFGS-Bâ€™â€™ [41] or adjoint-based [42] numerical techniques</strong>.</p>
<p>DA algorithms could be <strong>applied to dynamical systems thanks to sequential applications</strong> expressed by a transition operator  <strong><em>M</em><sub>t<sup>k</sup>â†’t<sup>k+1</sup></sub></strong> (from discrete time <strong>t<sup>k</sup> to t<sup>k+1</sup></strong>), where</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225152151.png" style="zoom:78%;">

<p><strong>x<sub>b,t<sup>k+1</sup></sub></strong> thus depends on the knowledge of <strong><em>M</em><sub>t<sup>k</sup>â†’t<sup>k+1</sup></sub></strong> and the DA correcting state <strong>x<sub>a,t<sup>k</sup></sub></strong> , i.e.</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225152602.png" style="zoom:78%;">

<p>Obviously, the more accurate <strong>x<sub>a,t<sup>k</sup></sub></strong>  is, the more reliable <strong>x<sub>b,t<sup>k+1</sup></sub></strong> would be.</p>
<p>To leverage the information embedded in the background state and observations, <strong>covariance matrices modeling is a pivotal point in DA</strong> as they influence not only how prior errors spread but may also change the DA results [26].</p>
<h3 id="4-2-Ensemble-methods-ï¼ˆQï¼‰"><a href="#4-2-Ensemble-methods-ï¼ˆQï¼‰" class="headerlink" title="4.2 Ensemble methods ï¼ˆQï¼‰"></a>4.2 Ensemble methods ï¼ˆQï¼‰</h3><p><strong>Ensemble data assimilation (EnDA)</strong> [43, 44] methods have shown a strong performance in dealing with <strong>non-linear chaotic DA systems</strong> by creating <strong>an ensemble with size</strong> <em>M</em> <strong>of the system state</strong> depicted as:</p>
<blockquote>
<p><code>â†‘ Mæ–œä½“åŠ ç²—æ˜¯åŠ¨åŠ›ç³»ç»Ÿï¼ŒMæ–œä½“æœªåŠ ç²—æ˜¯ç³»ç»ŸçŠ¶æ€é›†åˆçš„å¤§å°</code></p>
<p><code>â†“ ç³»ç»ŸçŠ¶æ€é›†åˆï¼Œç†è§£æ·±ç‚¹</code></p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225162140.png"></p>
<ul>
<li><p><strong>The latter</strong> is used to represent both the prior and the posterior probability distribution of the state variables. </p>
<blockquote>
<p><code>Qï¼šâ†‘ åè€…ï¼ŒæŒ‡çš„æ˜¯å“ªä¸ªï¼Ÿ</code></p>
</blockquote>
</li>
<li><p>The system states of the ensemble evolve under  <strong><em>M</em><sub>t<sup>k</sup>â†’t<sup>k+1</sup></sub></strong> and DA is applied to each of these ensemble states at <strong>every assimilation windows</strong>. </p>
<blockquote>
<p><code>â†‘ æ„æ€æŒ‡çš„æ˜¯ï¼Œå¯¹ç³»ç»ŸçŠ¶æ€é›†åˆä¸­çš„æ¯ä¸€ä¸ªç³»ç»ŸçŠ¶æ€éƒ½è¿›è¡ŒåŒåŒ–</code></p>
</blockquote>
</li>
<li><p>Furthermore, instead of evolving the system to obtain the <strong>B</strong> matrix, which is a time and computationally expensive process when a large number of states is available, <strong>B</strong> is estimated as a sample covariance:</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225161222.png" alt=" " style="zoom:78%;">

<p>where</p>
<p><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225161336.png"></p>
<p>and the estimation becomes <strong>more reliable with the increases of</strong> <em>M</em> . </p>
</li>
<li><p>For applications in this study, EnDA, with a sufficiently large number of examples, is used to estimate <strong>x<sub>b,t<sup>k</sup></sub></strong>  and <strong>B<sub>b,t<sup>k</sup></sub></strong>  so that we can focus on the comparison of <strong>R</strong> matrix modelings.</p>
</li>
</ul>
<h3 id="4-3-Observation-error-covariances-specification"><a href="#4-3-Observation-error-covariances-specification" class="headerlink" title="4.3 Observation error covariances specification"></a>4.3 Observation error covariances specification</h3><p>For the estimation of <strong>R</strong>, under the assumption that the system model is stationary, </p>
<blockquote>
<p><code>â†‘ å‡è®¾3ï¼šç³»ç»Ÿæ¨¡å‹å¹³è¡¡</code></p>
</blockquote>
<ul>
<li><p>a wide variety of methods have been explored, for example, the DI01 [23] method which adjusts accordingly the ratio between <em>Tr</em>(<strong>B</strong>) and <em>Tr</em>(<strong>R</strong>) and the D05 [24] approach which estimates the full observation space iteratively. </p>
<p>However, these methods, based on posterior innovation quantities (i.e., <strong>y</strong> - <strong><em>H</em>(x<sub>a</sub>)</strong>) which requires several applications of DA algorithms, can be <strong>computationally expensive</strong>. </p>
<p>Moreover, these tuning methods, especially the D05 which estimates the full matrix, are <strong>not suitable for different matrix parameterizations</strong>. </p>
</li>
<li><p>In this paper, working with time-series observation data, we use LSTM to predict the corresponding <strong>R</strong> matrix under similar assumptions of DI01 and D05. The two classical methods, introduced in Section 5, are implemented to compare the results with the proposed machine learning approach.</p>
</li>
</ul>
<h2 id="5-Posterior-covariance-tuning-algorithms"><a href="#5-Posterior-covariance-tuning-algorithms" class="headerlink" title="5 Posterior covariance tuning algorithms"></a>5 Posterior covariance tuning algorithms</h2><h3 id="5-1-Desroziers-and-Ivanov-DI01-tuning-algorithm-ï¼ˆQï¼‰"><a href="#5-1-Desroziers-and-Ivanov-DI01-tuning-algorithm-ï¼ˆQï¼‰" class="headerlink" title="5.1 Desroziers and Ivanov (DI01) tuning algorithm ï¼ˆQï¼‰"></a>5.1 Desroziers and Ivanov (DI01) tuning algorithm ï¼ˆQï¼‰</h3><p>Because <strong>B</strong> and <strong>R</strong> determine the weight of background and observation information in the loss function ( <strong>Eq 1</strong>), the knowledge of Tr(<strong>B</strong>) and Tr(<strong>R</strong>) is crucial to DA accuracy. </p>
<blockquote>
<p><code>Qï¼šâ†‘ ä¸ºä»€ä¹ˆBå’ŒRçŸ©é˜µçš„Tr()å¾ˆé‡è¦ï¼Ÿ</code></p>
</blockquote>
<p><strong>DI01 [23] tuning algorithm</strong>, relying on the diagnosis of <strong>innovation quantities</strong>, has been widely adopted in meteorology [28, 45] and geoscience [46]. Consecutive works have been carried out to improve its performance and feasibility in problems of large dimensions [47]. Without modifying error correlation structures, DI01 adjusts the prior error amplitudes by applying an iterative fixed-point procedure.</p>
<blockquote>
<p><code>Qï¼šâ†‘ DI01çš„éªŒè¯æŒ‡æ ‡æ˜¯åˆ›æ–°é‡ï¼ˆå¢ç›Šé‡ï¼‰ï¼Œ0ï¼Œï¼Ÿ</code></p>
</blockquote>
<p>As demonstrated in [23, 48], when <strong>B</strong> and <strong>R</strong> are perfectly specified,</p>
<blockquote>
<p><code>Q: â†‘ éœ€è¦ B å’Œ R è¢«é¢„å…ˆæŒ‡å®šï¼Œé‚£ DI01 åšä»€ä¹ˆï¼Ÿ</code></p>
</blockquote>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225202325.png" style="zoom:93%;">

<p>where <strong>H</strong> is a linearized observation operator. Based on <strong>Eqs 13 and 14</strong> it is possible to iteratively correct the magnitudes of <strong>B</strong> and <strong>R</strong>, following</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225202444.png" style="zoom:93%;">

<p>using the two indicators</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225202603.png" style="zoom:93%;">

<p>where <em>q</em> is the current iteration.</p>
<p>Acting as scaling coefficients, the sequences {<em>s</em><sub><em>b,q</em></sub>} and {<em>s</em><sub><em>o,q</em></sub>} modify the error variance magnitude in the iterative process. It is worth reminding that both the analyzed state <strong>x<sub>a</sub></strong> and the gain matrix <strong>K<sub><em>q</em></sub></strong> are obtained using <strong>B<sub><em>q</em></sub></strong> ,  <strong>R<sub><em>q</em></sub></strong>  which depend on <em>s</em><sub><em>b,q</em></sub> and <em>s</em><sub><em>o,q</em></sub>. When the correlation patterns of both <strong>B</strong> and <strong>R</strong> are well known, <strong>DI01 is equivalent to a maximum-likelihood parameter tuning</strong>, as pointed out in [28, 47].</p>
<p>Unlike other posterior covariance diagnosis/computations, such as [24, 26], the estimation of the full matrices is not needed in DI01. Instead, <strong>only the estimation of two scalar values (<em>J</em><sub>b</sub>, <em>J</em><sub>o</sub>) is required</strong>, which significantly <strong>reduce the computational cost</strong>. As a consequence, <strong>this method could be more appropriate for online covariance tuning</strong>.</p>
<blockquote>
<p><code>Q: â†‘ DI01ä¸ºä»€ä¹ˆä¸éœ€è¦å¯¹æ•´ä¸ªçŸ©é˜µè¿›è¡Œä¼°è®¡ï¼Ÿå› ä¸ºå¢ç›Šæ˜¯éªŒè¯æŒ‡æ ‡å—ï¼Ÿ</code></p>
</blockquote>
<h3 id="5-2-Desroziers-iterative-method-D05-in-the-observation-space"><a href="#5-2-Desroziers-iterative-method-D05-in-the-observation-space" class="headerlink" title="5.2 Desroziers iterative method (D05) in the observation space"></a>5.2 Desroziers iterative method (D05) in the observation space</h3><p><strong>The Desroziers diagnosis (D05)</strong>[24], subject to prior and posterior state-observation residuals has been widely applied in engineering problems, including numerical weather prediction[28] and hydrology [3]. The work of [24] proved that when <strong>B</strong> and <strong>R</strong> are well known <strong>a priori</strong>, the expectation of the analysis state should satisfy:</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225203904.png" style="zoom:95%;">

<p>The difference between the left side and the right side of <strong>Eq 18</strong>,</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225203956.png" style="zoom:95%;">

<blockquote>
<p><code>â†‘ D05è¿­ä»£æ–¹æ³•çš„æ”¶æ•›æŒ‡æ ‡ï¼Œå½“æ”¶æ•›æ—¶ï¼Œè¶‹è¿‘0</code></p>
</blockquote>
<p>can be used as a validation indicator of the <strong>R</strong> matrix estimation where ||.||<sub><em>F</em></sub>  denotes the Frobenius norm. Applying this method, time variant observation/background data can contribute to the estimation of the <strong>R</strong> matrix because the expectation in <strong>Eq 18</strong> could be evaluated using residuals at different time steps. When the <strong>B</strong> matrix is well known, an iterative process has been introduced to estimate the <strong>R</strong> matrix:</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225204210.png" style="zoom:95%;">

<blockquote>
<p><code>â†‘ D05è¿­ä»£æ–¹æ³•è¦æ±‚ B çŸ©é˜µå·²çŸ¥~</code></p>
</blockquote>
<p>based on the fixed-point theory [29]. The current analysis state <strong>x<sub><em>a,q</em></sub></strong> is obtained using the specification of  <strong>R<sub><em>q</em></sub></strong> while  <strong>x<sub><em>b</em></sub></strong> , <strong>B</strong>,  <strong>y</strong> remains invariant. As proved in [28, 29], under the assumption of sufficient observation data and well known <strong>B</strong> matrix, the iterative process of <strong>Eq 20</strong> converges to the exact observation error covariance. However, as shown in [29], the intermediate matrices <strong>R<sub><em>q</em></sub></strong>  could be non-symmetric and possibly contain negative or complex eigenvalues, which is cumbersome for DA algorithms to deal with.</p>
<p>In practice, a posterior regularization at each iteration step is often required to ensure the positive definiteness of <strong>R<sub><em>q</em></sub></strong> [29] where the first step of the regularization could be symmetrizing the estimated <strong>R<sub><em>q</em></sub></strong>  matrix, i.e.,</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225204611.png" style="zoom:96%;">

<p>The spectrum of  <strong>R<sub><em>q</em></sub></strong>  now contains only real numbers but they are not necessarily positive. The hybrid method[2] is a standard approach in ensemble-based DA methods to ensure the positive definiteness, which consists of combining a prior defined covariance matrix <strong>C</strong> with the one obtained from empirical estimation. We thus obtain the formulation of the regularized observation matrix  <strong>R<sub>r,n</sub></strong> :</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225204748.png" style="zoom:95%;">

<blockquote>
<p><code>â†‘ æ­£åˆ™åŒ–ï¼Œä¸ºäº†æ»¡è¶³æ­£å®šæ€§ï¼ˆå®æ•°ï¼‰+éè´Ÿæ€§ï¼Œ</code></p>
</blockquote>
<p>following <strong>Eq 21</strong> with Î¼âˆˆ(0,1). The matrix <strong>C</strong> is often set as a diagonal matrix since it helps to enhance the matrix conditioning. In this work, we choose to set</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225204913.png" style="zoom:95%;">

<blockquote>
<p><code>â†“ æ­£åˆ™åŒ–çš„è§‚æµ‹çŸ©é˜µæ”¶æ•›æ€§ä»æœªè§£å†³~</code></p>
</blockquote>
<p>so that <em>Tr</em>(<strong>R<sub><em>q</em></sub></strong>) will not be modified due to the post regularization. As mentioned in the discussion of [3, 29], <strong>the convergence of regularized observation matrices remains an open question</strong>. Therefore, a small iteration number is often assigned for D05 tuning in industrial problems (e.g., <em>q</em> = 2 in [3, 49]). Since the right side of <strong>Eq 20</strong> can be estimated using residual quantities at different time steps, D05 is often used to <strong>deal with time series observation data</strong> (e.g., [3, 49]) when assuming the <strong>R</strong> matrix is time-invariant.</p>
<h2 id="6-LSTM-for-error-covariance-estimation"><a href="#6-LSTM-for-error-covariance-estimation" class="headerlink" title="6 LSTM for error covariance estimation"></a>6 LSTM for error covariance estimation</h2><h3 id="6-1-Introduction-of-RNN-and-LSTM"><a href="#6-1-Introduction-of-RNN-and-LSTM" class="headerlink" title="6.1 Introduction of RNN and LSTM"></a>6.1 Introduction of RNN and LSTM</h3><p>LSTM, first introduced in [50], is a kind of RNN [31], capable of solving <strong>long-term dependency problems</strong> [51] that traditional RNN could not handle. As with other recurrent neural networks, LSTM has a chain-like structure. This structure is created by repeating the same module shown on the left side in <strong>Fig. 1</strong>. In addition, the repeating module comprises four neural networks instead of only one. The specific structure of the <strong>repeating module</strong> is on the right side in <strong>Fig. 1</strong>.</p>
<blockquote>
<p><code>â†‘ æå®æ¯…è€å¸ˆçš„è§†é¢‘å¯¹RNNï¼Œè®²çš„å¾ˆè¯¦ç»†~ </code></p>
</blockquote>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225211508.png" style="zoom:100%;">

<p>An essential part of LSTM is the <strong>cell state</strong> C<sub><em>t<sup>k-1</sup></em></sub>  which is the long-term memory storing information about past behaviors. LSTM uses <strong>three gates</strong> with each composed out of <strong>a sigmoid layer neural network</strong> (single layer neural network with sigmoid activation function at the output layer) and a <strong>pointwise multiplication operation</strong>, to protect and control information of the cell state as shown in <strong>Fig. 1</strong>.</p>
<p><strong>The first gate is the forget gate</strong> following:</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225211732.png" style="zoom:95%;">

<p>where the <strong>recurrent variable</strong> h<sub><em>t<sup>k-1</sup></em></sub> summarizing all the information about past behaviors,  x<sub><em>t<sup>k</sup></em></sub>  resuming information about current behaviors, and  W<sub><em>f</em></sub>  and <em>b</em><sub><em>f</em></sub>  are weights and bias, respectively, parameterizing the sigma layer neural network.  The forget gate decides what kind of information is going to be ignored in C<sub><em>t<sup>k-1&nbsp;</sup></em></sub>.</p>
<p><strong>The second gate is the input gate</strong>, and it determines which new information is added into C<sub><em>t<sup>k-1</sup></em></sub> . This new information, $\tilde{\mathbf{C}}_{t^{k}}$, as conforming to</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225212609.png" style="zoom:95%;">

<p>is attained by passing h<sub><em>t<sup>k-1</sup></em></sub> and x<sub><em>t<sup>k</sup></em></sub> to a tanh layer neural network (single layer neural network with tanh activation function at the output layer) with parameters W<sub><em>c</em></sub>  and <em>b</em><sub><em>c</em></sub> .</p>
<p>$\tilde{\mathbf{C}}_{t^{k}}$ is then multiplied by weight coefficients i<sub><em>t<sup>k</sup></em></sub>  which is acquired by the input gate, i.e.,</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225212927.png" style="zoom:95%;">

<p>i<sub><em>t<sup>k</sup></em></sub> is applied to decide which new information would be employed to update C<sub><em>t<sup>k-1</sup></em></sub>.</p>
<p>Hence, the state cell C<sub><em>t<sup>k</sup></em></sub> at the current time step <em>t<sup>k</sup></em> can be attained using</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225213116.png" alt=" " style="zoom:95%;">

<p>Finally, the acquisition of h<sub><em>t<sup>k</sup></em></sub> requires the participation of the output gate and a tanh activation function: first, the tanh activation function <em>tanh</em> is used to create a cell state candidate information <em>tanh</em>(C<sub><em>t<sup>k</sup></em></sub>). <em>tanh</em>(C<sub><em>t<sup>k</sup></em></sub>) is then multiplied by some weight coefficients following</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225213356.png" alt=" " style="zoom:95%;">

<p>to decide which information of  <em>tanh</em>(C<sub><em>t<sup>k</sup></em></sub>)  would contribute to the obtainment of  h<sub><em>t<sup>k</sup></em></sub>  . Among them, o<sub><em>t<sup>k</sup></em></sub>, is generated by the output gate with neural network parameters  W<sub><em>o</em></sub>  and <em>b</em><sub><em>o</em></sub> , i.e.,</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220225213556.png" style="zoom:95%;">

<h3 id="6-2-LSTM-for-R-matrix-estimation-using-time-series-observation-data-Q"><a href="#6-2-LSTM-for-R-matrix-estimation-using-time-series-observation-data-Q" class="headerlink" title="6.2 LSTM for R matrix estimation using time series observation data (Q)"></a>6.2 LSTM for R matrix estimation using time series observation data (Q)</h3><p>The tuning methods presented in Section 5 have been applied in various engineering applications with significant improvement of covariance specification and DA accuracy. However, these methods which require several applications of DA algorithms can be computationally expensive for high-dimensional problems. Another important drawback stands for the requirement of precise knowledge on either the <strong>correlation patterns</strong> of <strong>B</strong> and <strong>R</strong> (for DI01) or the full <strong>B</strong> matrix (for D05). </p>
<blockquote>
<p><code>Q: â†‘ è¿˜æ˜¯ä¸èƒ½ç†è§£ DI01 åšä»€ä¹ˆï¼Ÿcorrelation pattern æ˜¯ full matrixå—ï¼Ÿ</code></p>
</blockquote>
<p>In this study, we aim to build a data-driven surrogate model for efficient online <strong>R</strong> matrix specification using LSTM. Unlike DI01 or D05, no specific knowledge about the error covariances or the state/observation dynamical systems other than the transformation operator <em><strong>H</strong></em> and the forward model  <strong><em>M</em><sub>t<sup>k</sup>â†’t<sup>k+1</sup></sub></strong> (which is also indispensable for standard DA algorithms including variational methods and Kalman-filters) is required.</p>
<blockquote>
<p><code>â†‘ æŒ‡å‡ºäº†æœ¬ç®—æ³•çš„éœ€è¦ï¼Œè§‚æµ‹ç®—å­ã€å‰å‘æ¨¡å‹ï¼Œä¸éœ€è¦ï¼ŒBå’ŒRçš„ç›¸å…³ç‰¹å®šä¿¡æ¯</code></p>
<p><code>ğŸ˜~win+. emojiè¡¨æƒ…åŒ…</code></p>
</blockquote>
<h4 id="Algorithm-1ï¼šSimulated-observations-generating-process"><a href="#Algorithm-1ï¼šSimulated-observations-generating-process" class="headerlink" title="Algorithm 1ï¼šSimulated observations generating process"></a>Algorithm 1ï¼šSimulated observations generating process</h4><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226134527.png" style="zoom:67%;">

<p><strong>our main idea is to build a training set for the specific problem</strong>, including predefined time-invariant observation matrices {$\mathbf{R}^{[\text{iter}]}$}  within certain range and generated dynamical observation vector {$\mathbf{y}_{t^{k}}^{[\text {iter }]}$}.  </p>
<blockquote>
<p><code>â†‘ ç®—æ³•1ï¼šç›®çš„</code></p>
</blockquote>
<p>Setting the dynamical observations {$\mathbf{y}_{t^{k}}^{[\text {iter }]}$} as the system input and the <strong>R</strong> matrices as output, <strong>LSTM networks are used to learn the error distribution across the underlying observation dynamics</strong>.</p>
<blockquote>
<p><code>â†‘ ç®—æ³•1ï¼šå’ŒLSTMçš„è”ç³»ï¼ŒLSTMçš„è¾“å…¥ï¼Œè¾“å‡ºï¼ŒLSTMä½œç”¨</code></p>
</blockquote>
<p>More precisely, a real function $g^{\mathbf{R}}(.): \Phi_{\mathbf{R}} \longrightarrow \mathbb{R}^{m \times m}$ is predefined where $\Phi_{\mathbf{R}}$ is an empirically estimated real space which <strong>defines the range of a set of parameters, such as marginal error variance, correlation scale length [18]</strong> for computing the <strong>R</strong> matrices. The generated observation matrices {$\mathbf{R}^{[\text{iter}]}$}  are set to be <strong>symmetric positive definite (SPD)</strong> thanks to the function $g^{\mathbf{R}}(.)$. Both $g^{\mathbf{R}}(.)$ and $\Phi_{\mathbf{R}}$ vary for different applications.</p>
<blockquote>
<p><code>â†‘ ç®—æ³•1ï¼šä»‹ç»äº†</code>$\Phi_{\mathbf{R}}$ï¼Œ<code>ç”Ÿæˆçš„Ræ˜¯å¯¹ç§°æ­£å®šçš„</code></p>
</blockquote>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226133013.png" alt=" " style="zoom:67%;">

<blockquote>
<p><code>â†‘ ç®—æ³•1ï¼šæ ¸å¿ƒæ±‚è§£å…¬å¼</code></p>
</blockquote>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226114331.png" alt=" " style="zoom:67%;">

<blockquote>
<p><code>â†‘ ç®—æ³•1ï¼šå®Œæ•´çš„è§‚æµ‹æ¨¡æ‹Ÿç”Ÿæˆè¿‡ç¨‹ï¼›</code></p>
</blockquote>
<h4 id="Algorithm-2-LSTM-training-and-validation-process"><a href="#Algorithm-2-LSTM-training-and-validation-process" class="headerlink" title="Algorithm 2: LSTM training and validation process"></a>Algorithm 2: LSTM training and validation process</h4><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226133421.png" style="zoom:67%;">

<p><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226133548.png"></p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226133810.png" style="zoom:67%;">

<p><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226134947.png"></p>
<p>Different from classical covariance tuning algo-rithms, the LSTM network only makes use of historical observation data, requiring neither the background states nor the error covariance matrix. The advantage of using LSTM is more salient <strong>when the observation dimension is large</strong>, for example, millions or even billions, while such dimension is not uncommon in real-world applications [2, 7].</p>
<p>To estimate <strong>R</strong>, LSTM is first trained to learn: <strong>related variables</strong></p>
<ul>
<li>â€“ <strong>either</strong> which can be used to constitute the symmetry observation error covariance matrix (i.e., input variables of the g<sup>R</sup>(.) function) <strong>in a parametric modeling</strong>;</li>
<li> â€“<strong>or</strong> elements of the <strong>R</strong> matrix (e.g., variables in the upper triangle and those in the diagonal of the covariance matrix) <strong>in a non-parametric modeling</strong>. </li>
</ul>
<p>The whole process for <strong>R</strong> estimation using LSTM is described in <strong>Algorithm 2</strong>.</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226140352.png" style="zoom:100%;">

<p>In Algorithm 2, it is suggested that LSTM training process is consisted of <strong>training and validation processes</strong>: </p>
<ul>
<li><p><strong>the training process</strong> is comprised of the forward prediction and the backward neural network weight parameters updating processes; </p>
</li>
<li><p>and <strong>validation process</strong> is used to predict desirable outputs or objectives and then calculate validation loss between predicted output and prior true output values. </p>
</li>
<li><p><strong>N_epoch</strong> indicates the number of times that the entire example data set is passed forward and backward through the LSTM during the training process. </p>
</li>
<li><p><strong>Early stopping</strong>, which terminates the training process when the validation loss reaches the minimum and is always the minimum value after N_patience_epoch epochs, is applied to reduce the LSTM training time.</p>
</li>
</ul>
<p>It is important to note that the offline data generation and LSTM training processes need to be carried out individually for different DA applications (<strong>Fig 4</strong>).</p>
<p><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226140509.png"></p>
<h2 id="7-Lorenz-twin-experiment"><a href="#7-Lorenz-twin-experiment" class="headerlink" title="7 Lorenz twin experiment"></a>7 Lorenz twin experiment</h2><h3 id="7-1-Twin-experiment-principle"><a href="#7-1-Twin-experiment-principle" class="headerlink" title="7.1 Twin experiment principle"></a>7.1 Twin experiment principle</h3><p>In order to overcome the drawback that, in a realistic experiment, <strong>x</strong><sub>true</sub> is usually unknown and <strong>y</strong> is often mixed with noises, twin experiment, in which a prototypical test case is selected to simulate real situations, is applied so as to provide <strong>x</strong><sub>true</sub> for comparison. </p>
<blockquote>
<p><code>â†‘ è§£é‡Šäº†ä»€ä¹ˆæ˜¯å­ªç”Ÿå®éªŒ</code></p>
</blockquote>
<p>In this experiment, a mapping is applied to some sampling true trajectory <strong>x</strong><sub>true,<em>t<sup>k</sup></em></sub> at some points in space and time and arbitrary random noises are added to obtain simulated raw measurements  <strong>y</strong><sub><em>t<sup>k</sup></em></sub>  . DA is then implemented starting from the initial background state <strong>x</strong><sub>b,<em>t<sup>0</sup></em></sub> representing the prior information that could be obtained about corresponding state <strong>x</strong><sub>true,<em>t<sup>0</sup></em></sub>  , along with initial raw measurement  <strong>y</strong><sub><em>t<sup>0</sup></em></sub>  . The output state is then compared against <strong>x</strong><sub>true</sub> , verifying the distance of these two states and minimizing it to evaluate and improve the performance of DA. </p>
<p>In this section, we use a twin experiment to evaluate the performance of applying DA to a simple Lorenz system in which raw measurement error covariance is estimated/adjusted using, respectively, DI01, D05 and LSTM.</p>
<h3 id="7-2-Experiment-set-up-ï¼ˆQï¼‰"><a href="#7-2-Experiment-set-up-ï¼ˆQï¼‰" class="headerlink" title="7.2 Experiment set up ï¼ˆQï¼‰"></a>7.2 Experiment set up ï¼ˆQï¼‰</h3><p>The Lorenz system, first studied by Edward Lorenz, is a system of ordinary differential equations. For certain parameter values and initial conditions, the Lorenz system is notable for having chaotic solutions, in particular the Lorenz attractor, toward which a system tends to evolve. The Lorenz 96 system[52] has been widely used as a prototypical test case to compare the performance of DA algorithms[34, 35, 53]. </p>
<blockquote>
<p><code>â†‘ æ´›ä¼¦å…¹ç³»ç»Ÿå¹¿æ³›åº”ç”¨äºDAä¸­</code></p>
</blockquote>
<p>Here we build a twin experiment framework with a simple three dimensional Lorenz system in which the state vector is denoted as <strong>x</strong>=[x<sub>(0)</sub>, x<sub>(1)</sub>, x<sub>(2)</sub>]. The studied <strong>Lorenz system</strong> can be characterized as:</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226143503.png" style="zoom:95%;">

<!--- The initial values of the true state **x**<sub>true,*t<sup>0</sup>*</sub> are set to be [0, 1, 1.05] while the initial background state **x**<sub>b,*t<sup>0</sup>*</sub> is generated by combining **x**<sub>true,*t<sup>0</sup>*</sub> with a centered Gaussian noise **Îµ**<sub>*b,t<sup>0</sup>*</sub> : <img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226144151.png" style="zoom:95%;" /> Then both of true states  **x**<sub>true</sub> ={**x**<sub>true,*t<sup>0</sup>*</sub>,...,**x**<sub>true,*t<sup>T</sup>*</sub> } and background states  **x**<sub>b</sub> ={ **x**<sub>b,*t<sup>0</sup>*</sub> ,..., **x**<sub>b,*t<sup>T</sup>*</sub> } of the Lorenz system evolve by conforming, respectively, to the Lorenz equation in Eq 32 until t=1s with total *T* =1000 time steps.  -->

<p>initial true state, initial background state â†’(Lorenz) true state, background</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226144836.png" alt="  " style="zoom:95%;">

<p>observations â† observation operator, noise</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226145209.png" style="zoom:95%;">

<p><strong>EnDA</strong> is then applied in this twin experiment to update the background ensemble using available observations.</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226150001.png" style="zoom:95%;">

<blockquote>
<p><code>Qï¼šâ†‘ åŒåŒ–çª—å£æ˜¯ 10 ä¸ªæ—¶é—´æ­¥å—ï¼Ÿ</code></p>
</blockquote>
<h3 id="7-3-DA-with-LSTM-based-covariance-estimation"><a href="#7-3-DA-with-LSTM-based-covariance-estimation" class="headerlink" title="7.3 DA with LSTM-based covariance estimation"></a>7.3 DA with LSTM-based covariance estimation</h3><p><strong>R</strong> matrix generation</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226151107.png" style="zoom:95%;">

<blockquote>
<p> â†‘ å‚æ•°åŒ–<strong>R</strong>ç”Ÿæˆå¯¹ç§°æ­£å®šçŸ©é˜µçš„ç½‘ç«™ï¼š<a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_spd_matrix.html">https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_spd_matrix.html</a></p>
</blockquote>
<p>the input, output and structure of <strong>LSTM function</strong></p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226152701.png" style="zoom:90%;">

<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226153047.png" style="zoom:75%;">

<p>LSTM1000 and LSTM200ï¼š</p>
<blockquote>
<p>â†‘  In this Lorenz twin experiment, two LSTM networks, respectively named as <strong>LSTM1000 and LSTM200</strong> are designed with different input sizes of times series data. LSTM1000 is trained on a total of 1000 time steps for predicting the R matrix while LSTM200 makes use of only the first 200 time steps to simulate a realistic application where the time-invariant R matrix is estimated using historical data for improving future DA performance. The evaluation of both LSTM1000 and LSTM200, in terms of DA accuracy, is made using the full test dataset with 1000 times steps. By leveraging the LSTM model along with available observations, we can still perform DA algorithms even though R is not explicitly given. The results are then compared with the ones obtained using the exact R matrix.</p>
</blockquote>
<h3 id="7-4-Results"><a href="#7-4-Results" class="headerlink" title="7.4 Results"></a>7.4 Results</h3><p>Prediction results of the <strong>non-parametric error covariance</strong> and the true valuesï¼š</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226155018.png" style="zoom:67%;">

<p><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226155112.png"></p>
<p>The averaged DA performance </p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226163134.png" style="zoom:80%;">

<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226163708.png" style="zoom:80%;">

<p><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226163826.png"></p>
<p><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226163916.png"></p>
<blockquote>
<p>â†‘ <code>averaged</code> æ˜¯å› ä¸ºEnDAæœ‰100ä¸ªèƒŒæ™¯è½¨è¿¹ï¼›</p>
</blockquote>
<h2 id="8-Application-to-shallow-water-equations"><a href="#8-Application-to-shallow-water-equations" class="headerlink" title="8 Application to shallow water equations"></a>8 Application to shallow water equations</h2><h3 id="8-1-Experiment-setup"><a href="#8-1-Experiment-setup" class="headerlink" title="8.1 Experiment setup"></a>8.1 Experiment setup</h3><p>For further evaluating the performance of error covariance estimation using LSTM when incorporated with predefined correlation kernels, we also set up a twin experiment framework with <strong>a simplified 2D shallow-water dynamical model</strong>, which is frequently used for <strong>testing data assimilation algorithms</strong> ( e.g., [26, 42]). </p>
<p>A cylinder of water is positioned in the middle of the study field with size 20<em>mm</em> Ã— 20<em>mm</em> and released at the initial time step <em>t<sup>k</sup>=t<sup>0</sup></em> s (i.e., with no initial speed), leading to a non-linear wave-propagation. The dynamics of the water level <em>h</em> (in <em>mm</em>), as well as the horizontal and vertical velocity field (respectively denoted as <em>u</em> and <em>v</em> in 0.1<em>m/s</em>), is given by the nonconservative shallow water equations,</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220227201158.png" style="zoom:80%;">

<blockquote>
<p><code>â†‘ æ½œæ°´æ¨¡å‹</code></p>
</blockquote>
<p>The evolution of the reference state (x<sub>true</sub>), together with the error-free model <strong>equivalent observations</strong> (i.e., H(x<sub>true</sub>)), is illustrated in <strong>Fig 8</strong>. </p>
<p><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220227201917.png"></p>
<p>Spatially <strong>correlated prior observation errors</strong> are generated artificially and combined with the transformation operator to simulate real-time observations. More precisely, the observations are generated from the model equivalent  H(x<sub>true</sub>) <strong>separately for the fields u and v</strong>. H is defined as a <strong>sparse matrix to imply the fact that measurements in real-world applications are sparser than true states</strong> due to the interference existing in the former situations as well as the limited performances of sensors.</p>
<blockquote>
<p><code>â†‘ è¿™é‡Œå¯¹Hç®—å­ä¸è§‚æµ‹çš„å…³ç³»è¯´çš„éå¸¸åˆ°ä½ï¼Œå¯¹Hç®—å­çš„ç¨€ç–æ€§ä¹Ÿè®²çš„å¾ˆå¥½</code></p>
</blockquote>
<p>As shown in <strong>Fig 7</strong>, the spatial observations at time <em>t<sup>k</sup></em> is defined as the average of u<sub><em>t<sup>k</sup></em></sub> and v<sub><em>t<sup>k</sup></em></sub>  in a 2 Ã— 2 cells area with an observation error Îµ<sub>y<sub><em>t<sup>k</sup></em></sub></sub> ,</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220227204749.png" alt=" " style="zoom:80%;">

<p>and identical for y<sub><em>v,i,j,t<sup>k</sup></em></sub> . </p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220227204957.png" style="zoom:80%;">

<p>Therefore, the dimension of the observation vector y = [ y<sub><em>u,t<sup>k</sup></em></sub>, y<sub><em>v,t<sup>k</sup></em></sub>] is 200.</p>
<blockquote>
<p><code>â†‘ ä¸Šé¢ä»‹ç»çš„æ˜¯æŸä¸€æ—¶åˆ»çš„è§‚æµ‹æ˜¯ä»€ä¹ˆï¼ŒH è§‚æµ‹ç®—å­ä¾æ­¤æ„å»º</code></p>
</blockquote>
<p>In this experiment, we suppose that the observation error  Îµ<sub>y<sub><em>u,i,j,t<sup>k</sup></em></sub></sub>  and Îµ<sub>y<sub><em>v,i,j,t<sup>k</sup></em></sub></sub>  , respectively of the velocity fields u and v, follow the same <strong>Gaussian distribution</strong> N(0,R). Thus, the observation error covariance in this shallow water system can be fully characterized by a 100 Ã— 100 <strong>R</strong> matrix after the observations (originally in a 2D grid) being converted to a 1D vector.</p>
<blockquote>
<p><code>â†‘ ä¸Šé¢ä»‹ç»çš„æ˜¯æŸä¸€æ—¶åˆ»è§‚æµ‹è¯¯å·®åæ–¹å·®çš„ç»´æ•°</code></p>
</blockquote>
<p>Here we adopt a different parameterization of the R matrix thanks to an <strong>isotropic correlation function</strong> Ïˆ<sub>R</sub>(.),</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220227210650.png" style="zoom:80%;">

<ul>
<li><p>where <strong>D</strong>=[<em>D</em><sub>0</sub>,â€¦, <em>D</em><sub>99</sub>], representing the error variances in the 2D (10 Ã— 10) velocity field. Each element of D is generated individually following an uniform distribution,</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220227210854.png" style="zoom:80%;">

<p>which produces only positive elements to guarantee the positive definiteness of R.</p>
</li>
<li><p>Ïˆ<sub>R</sub>(.) is the <strong>second-order auto-aggressive (also known as Balgovind) function</strong>,</p>
<img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220227211048.png" style="zoom:80%;">

<p>where <em>L</em><sub>R</sub> is the correlation scale length, fixed as <em>L</em><sub>R</sub> = 10 in this application. <em>r</em> denotes the correlation scale length in the 2D space and is also generated uniformly with  <em>r</em> ~U(1,5). </p>
<p>Being part of Matern kernels, <strong>the SOAR function is often used in DA</strong> for prior error covariance modeling [6, 26] thanks to its smoothness and good conditioning. </p>
</li>
</ul>
<blockquote>
<p><code>â†‘ ä¸Šé¢ä»‹ç»äº†è§‚æµ‹è¯¯å·®åæ–¹å·®çš„æ„å»º</code></p>
</blockquote>
<p>The simulation of x<sub><em>b,t<sup>k</sup></em></sub>=[u<sub><em>b,t<sup>k</sup></em></sub>, v<sub><em>b,t<sup>k</sup></em></sub>] via the same discretization of <strong>Eq 39</strong> (except the initial conditions) is used as background states at time <em>t<sup>k</sup></em> in the DA modeling. Similar to the Lorenz experiment(i.e., <strong>Eq 35</strong>), {x<sub><em>b,t<sup>k</sup></em></sub>} is acquired by combining {x<sub><em>a,t<sup>k</sup></em></sub>} with randomly generated Gaussian errors, while {x<sub><em>a,t<sup>k</sup></em></sub>} is obtained every 100 time steps (i.e., 0.01s) from ensemble DA with time series observation data {y<sub><em>t<sup>k</sup></em></sub>} and the estimated observation error covariance R.</p>
<blockquote>
<p><code>â†‘ ä¸Šé¢ä»‹ç»äº†æŸä¸€æ—¶åˆ»çš„èƒŒæ™¯åœºæ˜¯ä»€ä¹ˆ</code></p>
</blockquote>
<h3 id="8-2-DA-with-LSTM-estimated-R"><a href="#8-2-DA-with-LSTM-estimated-R" class="headerlink" title="8.2 DA with LSTM estimated R"></a>8.2 DA with LSTM estimated R</h3><p>As with the Lorenz experiment, simulated observations {y<sub><em>t<sup>k</sup></em></sub>}, generated in the same process with that in the Lorenz system, are used as input training data for the LSTM model, while the <strong>D</strong> vector and the correlation scale <strong>r</strong> served as training output. </p>
<blockquote>
<p><code>â†‘ ä¸Šé¢ä»‹ç»äº†æµ…æ°´è¯•éªŒLSTMæ¨¡å‹è®­ç»ƒé›†çš„è¾“å…¥å’Œè¾“å‡º</code></p>
</blockquote>
<p>The specific structure of this LSTM network is shown in <strong>Table 3</strong>. This model has the same structure as the one of the Lorenz systems shown in <strong>Table 1</strong>, except the input and output dimensions. Besides, two types of LSTM are also proposed as what have been realized in the Lorenz system: <strong>LSTM1000</strong> employs the whole 1000 time steps observation data as LSTM training and prediction inputs while <strong>LSTM200</strong> makes use of only the first 200 time steps of observation data as the LSTM inputs. </p>
<p><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220227212912.png"></p>
<blockquote>
<p><code>â†‘ ä¸Šé¢ä»‹ç»äº†æµ…æ°´è¯•éªŒLSTMæ¨¡å‹ç»“æ„ï¼Œä¸¤ä¸ªè¯•éªŒ</code></p>
</blockquote>
<p>After the LSTM is well trained on the training set of 173000 generated observation trajectories in this experiment, R can be gained even only observation time-series data {y<sub><em>t<sup>k</sup></em></sub>} is acknowledged.</p>
<blockquote>
<p><code>â†‘ ...</code></p>
</blockquote>
<p>Similar to the Lorenz system, EnDA is performed here with an ensemble of 100 state trajectories initialized from the same initial state x<sub><em>t<sup>0</sup></em></sub> for each observation series. <strong>EnDA takes place every 200 time steps</strong> with the R matrix estimated through different methods.</p>
<blockquote>
<p><code>â†‘ EnDA é›†åˆï¼ŒEnDA åŒåŒ–çª—å£</code></p>
</blockquote>
<h3 id="8-3-Results"><a href="#8-3-Results" class="headerlink" title="8.3 Results"></a>8.3 Results</h3><h2 id="Pycharm-å®ç°-code"><a href="#Pycharm-å®ç°-code" class="headerlink" title="Pycharm å®ç° code"></a>Pycharm å®ç° code</h2><h3 id="Gitæ‰˜ç®¡ï¼ˆå¾…ï¼‰"><a href="#Gitæ‰˜ç®¡ï¼ˆå¾…ï¼‰" class="headerlink" title="Gitæ‰˜ç®¡ï¼ˆå¾…ï¼‰"></a>Gitæ‰˜ç®¡ï¼ˆå¾…ï¼‰</h3><p>ç›®å‰ä¿å­˜åœ¨Dç›˜ï¼›</p>
<h3 id="ç•Œé¢MATLABåŒ–-ç¯å¢ƒé…ç½®"><a href="#ç•Œé¢MATLABåŒ–-ç¯å¢ƒé…ç½®" class="headerlink" title="ç•Œé¢MATLABåŒ–+ç¯å¢ƒé…ç½®"></a>ç•Œé¢MATLABåŒ–+ç¯å¢ƒé…ç½®</h3><ol>
<li><p>ä¸ºäº†<strong>ä½¿å¾—pycharmæ›´åƒMATLAB</strong>ï¼Œï¼š</p>
<ul>
<li><p>ä¸»é¢˜è®¾ç½®ä¸º <strong>ç™½è‰²</strong>ï¼›</p>
</li>
<li><p>å‹¾é€‰<code>Run with Python Console</code>ï¼Œåœ¨è¿è¡Œå®Œæ–‡ä»¶åï¼Œ<strong>èƒ½åœ¨Python Consoleçœ‹åˆ°å˜é‡</strong>;</p>
<p><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226203810.png"></p>
</li>
<li><p>å³é”®æ‰§è¡Œæ‰€é€‰ä»£ç ï¼Œ<strong>èƒ½åœ¨Python Consoleçœ‹åˆ°å˜é‡</strong>;</p>
</li>
<li><p>pycharmä¸ä¼šå°†å½“å‰æ–‡ä»¶ç›®å½•è‡ªåŠ¨åŠ å…¥è‡ªå·±çš„sourse_pathã€‚å³é”®make_directory asâ€“&gt;sources pathå°†å½“å‰å·¥ä½œçš„æ–‡ä»¶å¤¹åŠ å…¥source_pathå°±å¯ä»¥äº†ã€‚è¿™æ ·<strong>å¯ä»¥åœ¨åŒç›®å½•ä¸‹importå…¶å®ƒpyæ–‡ä»¶</strong>ã€‚</p>
<blockquote>
<p>æ–‡ä»¶å¤¹åŠ å…¥source_pathåä¼šæ˜¾ç¤ºæˆ<strong>è“è‰²</strong>ã€‚</p>
</blockquote>
</li>
</ul>
<blockquote>
<p><strong>å…¶å®pycharmå¾ˆå¼ºå¤§çš„</strong>~~ä»¥å‰æ˜¯è‡ªå·±äº†è§£çš„ä¸å¤Ÿå¤š~</p>
<p><strong>æœ‰äº›MATLABé‚£å‘³é“äº†</strong>~~</p>
<p><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226211922.png"></p>
<p>æ€ä¹ˆ<strong>æ„Ÿè§‰pycharmæ¯”matlabè¿˜å¥½ç”¨å‘€</strong>~~ğŸ˜Š</p>
</blockquote>
</li>
<li><p>åœ¨pycharmä¸Šä»¥é¡¹ç›®çš„å½¢å¼æ‰“å¼€<code>LSTM_Covariance-main</code>æ–‡ä»¶å¤¹ï¼Œé€šè¿‡Anacondaï¼Œä¸ºé¡¹ç›®åˆ›å»ºä¸€ä¸ªæ–°ç¯å¢ƒ</p>
<p><img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220226170212.png"></p>
</li>
<li><p>ä¸ºç¯å¢ƒå®‰è£…ç›¸å…³pythonåŒ…ï¼ˆåº“ï¼‰</p>
<pre class="line-numbers language-none"><code class="language-none">numpy
scipy
matplotlib
keras
tensorflow
sklearn
pandas<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>è¿›å…¥ Anaconda Promptï¼Œè¾“å…¥ï¼š</p>
<pre class="line-numbers language-Anaconda" data-language="Anaconda"><div class="caption"><span>Prompt</span></div><code class="language-Anaconda">conda info -e
conda activate LSTM_Covariance-main
pip install tensorflow<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre></li>
</ol>
<h4 id="å‚è€ƒèµ„æ–™-1"><a href="#å‚è€ƒèµ„æ–™-1" class="headerlink" title="å‚è€ƒèµ„æ–™"></a>å‚è€ƒèµ„æ–™</h4><p>pycharm<strong>æ–°å»ºé¡¹ç›®ç¯å¢ƒ</strong>è®¾ç½®è¯¦è§£ï¼š<a target="_blank" rel="noopener" href="https://blog.csdn.net/weixin_38858443/article/details/108966449">https://blog.csdn.net/weixin_38858443/article/details/108966449</a></p>
<ul>
<li>é¡¹ç›®ã€è§£é‡Šå™¨ã€ç¯å¢ƒå‡ ä¸ªæ¦‚å¿µçš„ç†è§£</li>
<li>åœ¨pycharmä¸ºé¡¹ç›®æ–°å»ºä¸€ä¸ªæ–°ç¯å¢ƒ</li>
</ul>
<p>Pycharmä¸­<strong>è¿è¡ŒPythonä»£ç </strong>çš„å‡ ç§æ–¹å¼ï¼š<a target="_blank" rel="noopener" href="https://blog.csdn.net/JHON07/article/details/78966837">https://blog.csdn.net/JHON07/article/details/78966837</a></p>
<ul>
<li>å³é”®ï¼Œrunï¼Œok~~</li>
</ul>
<p>PyCharmé…ç½®anacondaç¯å¢ƒ <strong>å®‰è£…ç¬¬ä¸‰æ–¹åº“</strong>ï¼š<a target="_blank" rel="noopener" href="https://blog.51cto.com/u_15284226/2992785">https://blog.51cto.com/u_15284226/2992785</a></p>
<p>Pycharmåœ¨è¿è¡Œè¿‡ç¨‹ä¸­,**æŸ¥çœ‹æ¯ä¸ªå˜é‡çš„æ“ä½œ(show variables)**ï¼š<a target="_blank" rel="noopener" href="http://www.deiniu.com/article/188284.htm">http://www.deiniu.com/article/188284.htm</a></p>
<ul>
<li>è®©ä½ çš„Pycharmç”¨å¾—å’Œmatlabä¸€æ¨¡ä¸€æ ·ï¼ï¼š<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/337278800?ivk_sa=1024320u">https://zhuanlan.zhihu.com/p/337278800?ivk_sa=1024320u</a></li>
</ul>
<p>ä¸ºä»€ä¹ˆç”¨pycharmåœ¨åŒç›®å½•ä¸‹importï¼Œpycharmä¼šæŠ¥é”™ï¼Œä½†æ˜¯å®é™…å¯ä»¥è¿è¡Œï¼Ÿï¼š</p>
<h3 id="Lorenz"><a href="#Lorenz" class="headerlink" title="Lorenz"></a>Lorenz</h3><h4 id="simulated-data-generation-py-ï¼ˆQTï¼‰"><a href="#simulated-data-generation-py-ï¼ˆQTï¼‰" class="headerlink" title="simulated_data_generation.py ï¼ˆQTï¼‰"></a>simulated_data_generation.py ï¼ˆQTï¼‰</h4><p><code>simulated_data_generation.py</code> released in 2022-02-26</p>
<ul>
<li><p>æ•´ä¸ªè¿è¡Œæ—¶é—´</p>
<p>è¿è¡Œå¼€å§‹æ—¶é—´ï¼š17:55</p>
<p>è¿è¡Œç»“æŸæ—¶é—´ï¼š20:50</p>
</li>
<li><p><code>.ravel çŸ©é˜µå‘é‡åŒ–</code></p>
</li>
<li><p><code>.concatenate axis=0 æ•°ç»„æ‹¼æ¥</code></p>
</li>
<li><p><code>y = np.dot(H,x)               #why this is this expression to calculate y? </code></p>
<p>è¿™ä¸ª x ï¼Œåœ¨è®ºæ–‡7.2ä¸­æŒ‡å‡ºæ˜¯x<sub>true</sub>ï¼Œ</p>
<p>è€Œä»£ç ä¸­çš„ x æ ¹æ®7.2ä¸­å…¬å¼(33)åº”è¯¥æ˜¯x<sub>b</sub>ï¼Œ</p>
<p><strong>QTï¼šçŸ›ç›¾äº†å—ï¼Ÿ</strong></p>
<p><strong>çŒœæµ‹</strong>ï¼šæˆ‘è§‰å¾—åº”è¯¥æ˜¯ä»£ç å‡ºäº†é—®é¢˜</p>
<ul>
<li><p>ä»£ç ä¸­å‡ºç°äº†ä¸¤æ¬¡ x<sub>true</sub> çš„å®šä¹‰ï¼Œæœ‰ä¸€ä¸ªåº”è¯¥æ˜¯x<sub>b</sub>ï¼›</p>
</li>
<li><p>ä»<strong>åŒåŒ–å…¬å¼</strong>å¯ä»¥çœ‹å‡ºï¼Œyåº”è¯¥ç­‰äºH(x<sub>true</sub>) ï¼Œ<strong>å¦‚æœè§‚æµ‹æ•°æ®yç­‰äºH(x<sub>b</sub>)ï¼Œé‚£è¿˜éœ€è¦åŒåŒ–ä»€ä¹ˆå‘€</strong>ï¼Œç›´æ¥x<sub>a</sub>=x<sub>b</sub> ã€‚</p>
<p>å¯ä»¥çœ‹çœ‹åé¢<strong>ä½œè€…æ˜¯æ€ä¹ˆåŒåŒ–çš„</strong>~</p>
<p>å¾€ä¸‹çœ‹~</p>
</li>
</ul>
</li>
<li><p><strong>æ•´ä¸ªpyçš„ä½œç”¨ï¼Œ6ä¸­çš„ç®—æ³•1ï¼Œ7.2éƒ¨åˆ†</strong>ï¼Œç”Ÿæˆè®­ç»ƒé›†ï¼›</p>
</li>
<li><p><code>simulated_data_generation.py</code> released in 2022-02-26 æœ€å¼€å§‹çš„ä»£ç </p>
</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># -*- coding: utf-8 -*-</span>
<span class="token comment"># generate the trainning set for keras regression </span>

<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> scipy<span class="token punctuation">.</span>optimize <span class="token keyword">import</span> fmin
<span class="token keyword">from</span> scipy<span class="token punctuation">.</span>optimize <span class="token keyword">import</span> fmin_l_bfgs_b

<span class="token comment">#from scipy.optimize import fmin_ncg</span>
<span class="token keyword">from</span> scipy<span class="token punctuation">.</span>linalg <span class="token keyword">import</span> sqrtm
<span class="token keyword">import</span> math


<span class="token keyword">from</span> constructB <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> lorentz_attractor <span class="token keyword">import</span> <span class="token operator">*</span>

<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>gridspec <span class="token keyword">as</span> gridspec
<span class="token keyword">import</span> time
<span class="token keyword">import</span> random
<span class="token keyword">import</span> lorentz_attractor
<span class="token keyword">import</span> sklearn
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets

<span class="token keyword">import</span> os

<span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isdir<span class="token punctuation">(</span><span class="token string">'lorenz_cov_train_v2'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span><span class="token string">'lorenz_cov_train_v2'</span><span class="token punctuation">)</span>

<span class="token comment">#######################################################################</span>

<span class="token keyword">def</span> <span class="token function">correlation_from_covariance</span><span class="token punctuation">(</span>covariance<span class="token punctuation">)</span><span class="token punctuation">:</span>
    v <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>np<span class="token punctuation">.</span>diag<span class="token punctuation">(</span>covariance<span class="token punctuation">)</span><span class="token punctuation">)</span>
    outer_v <span class="token operator">=</span> np<span class="token punctuation">.</span>outer<span class="token punctuation">(</span>v<span class="token punctuation">,</span> v<span class="token punctuation">)</span>
    correlation <span class="token operator">=</span> covariance <span class="token operator">/</span> outer_v   <span class="token comment">#https://www.mygreatlearning.com/blog/covariance-vs-correlation/</span>
    correlation<span class="token punctuation">[</span>covariance <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">return</span> correlation

<span class="token comment">######################################################################</span>
<span class="token comment">#define matrix R by extra-diagonal elements</span>
<span class="token keyword">def</span> <span class="token function">R_covariance_dim3</span><span class="token punctuation">(</span>r1<span class="token punctuation">,</span>r2<span class="token punctuation">,</span>r3<span class="token punctuation">)</span><span class="token punctuation">:</span>
    M <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    M<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> r1
    M<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> r2
    M<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> r3
    M <span class="token operator">=</span> M <span class="token operator">+</span> M<span class="token punctuation">.</span>T
    M <span class="token operator">+=</span> np<span class="token punctuation">.</span>eye<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> M
    
<span class="token comment">################################################################################</span>
<span class="token comment">#######################################################################</span>
<span class="token keyword">def</span> <span class="token function">cov_to_cor</span><span class="token punctuation">(</span>M<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># from a covariance matrix to its associated correlation matrix</span>
    inv_diag_M<span class="token operator">=</span>np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>inv<span class="token punctuation">(</span>sqrtm<span class="token punctuation">(</span>np<span class="token punctuation">.</span>diag<span class="token punctuation">(</span>np<span class="token punctuation">.</span>diag<span class="token punctuation">(</span>M<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    cor_M <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>inv_diag_M<span class="token punctuation">,</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>M<span class="token punctuation">,</span>inv_diag_M<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> cor_M


<span class="token keyword">def</span> <span class="token function">lorenz_1step</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> z<span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> r<span class="token operator">=</span><span class="token number">28</span><span class="token punctuation">,</span> b<span class="token operator">=</span><span class="token number">2.667</span><span class="token punctuation">,</span>dt <span class="token operator">=</span> <span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    x_dot<span class="token punctuation">,</span> y_dot<span class="token punctuation">,</span> z_dot <span class="token operator">=</span> lorenz<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> z<span class="token punctuation">)</span>
    x_next <span class="token operator">=</span> x <span class="token operator">+</span> <span class="token punctuation">(</span>x_dot <span class="token operator">*</span> dt<span class="token punctuation">)</span>
    y_next <span class="token operator">=</span> y <span class="token operator">+</span> <span class="token punctuation">(</span>y_dot <span class="token operator">*</span> dt<span class="token punctuation">)</span>
    z_next <span class="token operator">=</span> z <span class="token operator">+</span> <span class="token punctuation">(</span>z_dot <span class="token operator">*</span> dt<span class="token punctuation">)</span>    
    <span class="token keyword">return</span> x_next<span class="token punctuation">,</span> y_next<span class="token punctuation">,</span> z_next

<span class="token keyword">def</span> <span class="token function">VAR_3D</span><span class="token punctuation">(</span>xb<span class="token punctuation">,</span>Y<span class="token punctuation">,</span>H<span class="token punctuation">,</span>B<span class="token punctuation">,</span>R<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#booleen=1 garde la trace</span>
    xb1<span class="token operator">=</span>np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>xb<span class="token punctuation">)</span>
    xb1<span class="token punctuation">.</span>shape<span class="token operator">=</span><span class="token punctuation">(</span>xb1<span class="token punctuation">.</span>size<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
    Y<span class="token punctuation">.</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>Y<span class="token punctuation">.</span>size<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
    dim_x <span class="token operator">=</span> xb1<span class="token punctuation">.</span>size
    K<span class="token operator">=</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>B<span class="token punctuation">,</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>H<span class="token punctuation">)</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>inv<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>H<span class="token punctuation">,</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>B<span class="token punctuation">,</span>np<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>H<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">+</span>R<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#matrice de gain, Kalman gain</span>
    A<span class="token operator">=</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>eye<span class="token punctuation">(</span>dim_x<span class="token punctuation">)</span><span class="token operator">-</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>K<span class="token punctuation">,</span>H<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>B<span class="token punctuation">)</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>eye<span class="token punctuation">(</span>dim_x<span class="token punctuation">)</span><span class="token operator">-</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>K<span class="token punctuation">,</span>H<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">+</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>K<span class="token punctuation">,</span>R<span class="token punctuation">)</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>K<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment">#not the kalman filter expression???</span>
    vect<span class="token operator">=</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>H<span class="token punctuation">,</span>xb1<span class="token punctuation">)</span>
    xa<span class="token operator">=</span>np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>xb1<span class="token operator">+</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>K<span class="token punctuation">,</span><span class="token punctuation">(</span>Y<span class="token operator">-</span>vect<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> xa<span class="token punctuation">,</span>A   <span class="token comment">#xa is the new estimated data, A is the new covariance,</span>
<span class="token comment">###################################################################################</span>

<span class="token comment">###################################################################################</span>
    <span class="token comment">#parameters</span>
num_steps <span class="token operator">=</span> <span class="token number">1000</span>
H <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
R <span class="token operator">=</span> <span class="token number">0.001</span><span class="token operator">*</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0.4</span><span class="token punctuation">,</span><span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0.4</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0.4</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">0.4</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

B <span class="token operator">=</span><span class="token number">0.01</span><span class="token operator">*</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0.2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0.2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token number">0.2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment">#Q = 0.0001*np.eye(3)</span>

<span class="token comment">###################################################################################</span>
<span class="token comment">#save the trainning set for different R </span>
trainning_set <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>num_steps<span class="token operator">*</span><span class="token number">3</span><span class="token operator">+</span><span class="token number">3</span><span class="token operator">+</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>   

<span class="token comment">###################################################################################</span>

<span class="token comment">#############################################################################</span>
    <span class="token comment"># true states vector 3 * number_steps</span>
xs<span class="token punctuation">,</span>ys<span class="token punctuation">,</span>zs <span class="token operator">=</span> lorenz_attractor<span class="token punctuation">(</span>s<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> r<span class="token operator">=</span><span class="token number">28</span><span class="token punctuation">,</span> b<span class="token operator">=</span><span class="token number">2.667</span><span class="token punctuation">,</span> dt <span class="token operator">=</span> <span class="token number">0.001</span><span class="token punctuation">,</span> num_steps<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span>

x_true <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>num_steps<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

x_true<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>xs<span class="token punctuation">)</span>
x_true<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>ys<span class="token punctuation">)</span>
x_true<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>zs<span class="token punctuation">)</span>


<span class="token comment">###############################################################################</span>
<span class="token keyword">for</span> ii <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">if</span> ii<span class="token operator">%</span><span class="token number">100</span> <span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>ii<span class="token punctuation">)</span>
            
<span class="token comment"># construct observations</span>
                
<span class="token comment">#=========================================================================</span>
    <span class="token comment">#generate x with noise</span>
    <span class="token keyword">for</span> repetation <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        xs<span class="token punctuation">,</span>ys<span class="token punctuation">,</span>zs <span class="token operator">=</span> lorenz_attractor<span class="token punctuation">(</span>s<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> r<span class="token operator">=</span><span class="token number">28</span><span class="token punctuation">,</span> b<span class="token operator">=</span><span class="token number">2.667</span><span class="token punctuation">,</span> dt <span class="token operator">=</span> <span class="token number">0.001</span><span class="token punctuation">,</span> num_steps <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">,</span>x0 <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token operator">+</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                    y0<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">+</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">)</span><span class="token punctuation">,</span>z0<span class="token operator">=</span><span class="token number">1.05</span><span class="token operator">+</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        
        x_true <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>num_steps<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        
        x_true<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>xs<span class="token punctuation">)</span>
        x_true<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>ys<span class="token punctuation">)</span>
        x_true<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>zs<span class="token punctuation">)</span>                
        
<span class="token comment">#=========================================================================</span>

        y_true <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>num_steps<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        y_obs <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>num_steps<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        
        v <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
        R <span class="token operator">=</span> correlation_from_covariance<span class="token punctuation">(</span>sklearn<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>make_spd_matrix<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment">#SPD covariance</span>
        
        r1 <span class="token operator">=</span> R<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span>
        r2 <span class="token operator">=</span> R<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span>
        r3 <span class="token operator">=</span> R<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span>
        
        R <span class="token operator">=</span> v<span class="token operator">*</span>R   
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_steps<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"sample time: "</span><span class="token punctuation">,</span>ii<span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"iteration time: "</span><span class="token punctuation">,</span>i<span class="token punctuation">)</span>
            x <span class="token operator">=</span> x_true<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token punctuation">]</span>
            x<span class="token punctuation">.</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
            y <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>H<span class="token punctuation">,</span>x<span class="token punctuation">)</span>               <span class="token comment">#why this is this expression to calculate y?        </span>
            y<span class="token punctuation">.</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>y<span class="token punctuation">.</span>size<span class="token punctuation">,</span><span class="token punctuation">)</span>
            y_true<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> y
            
            y_noise <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>multivariate_normal<span class="token punctuation">(</span>np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>R<span class="token punctuation">)</span>
            y_noise<span class="token punctuation">.</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>y_noise<span class="token punctuation">.</span>size<span class="token punctuation">,</span><span class="token punctuation">)</span>
            y_noise <span class="token operator">+=</span> y 
            y_obs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> y_noise
            
            parameters <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>r1<span class="token punctuation">,</span>r2<span class="token punctuation">,</span>r3<span class="token punctuation">,</span>v<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment">#output for deep learning regression</span>
                        <span class="token comment">#train_row = np.concatenate((y_obs.ravel(),x_true.ravel())) #input for deep learning    #what are the functionalities of these r -&gt;covaraicen! why v is not necessary???</span>
            train_row <span class="token operator">=</span> y_obs<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span>
            train_row <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>train_row<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>parameters<span class="token punctuation">)</span><span class="token punctuation">)</span>
            
        train_row<span class="token punctuation">.</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>train_row<span class="token punctuation">.</span>size<span class="token punctuation">)</span>
        trainning_set <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>trainning_set<span class="token punctuation">,</span>train_row<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>

        <span class="token comment"># if repetation+ii*10==5000:</span>

        <span class="token comment">#     np.savetxt(f"lorenz_cov_train_v2/trainset_withx_steps1000_test_{10000+repetation+ii*10}.csv", trainning_set, delimiter=",")</span>

trainning_set <span class="token operator">=</span> trainning_set<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
<span class="token comment">#####################################################################################""</span>
np<span class="token punctuation">.</span>savetxt<span class="token punctuation">(</span><span class="token string">"lorenz_cov_train_v2/trainset_withx_steps1000_test8.csv"</span><span class="token punctuation">,</span> trainning_set<span class="token punctuation">,</span> delimiter<span class="token operator">=</span><span class="token string">","</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<blockquote>
<blockquote>
<blockquote>
</blockquote>
</blockquote>
</blockquote>
<p><code>simulated_data_generation.py</code> åœ¨released in 2022-02-26 åŸºç¡€ä¸Šï¼Œè¿›è¡Œæ³¨é‡Š</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># -*- coding: utf-8 -*-</span>
<span class="token comment"># generate the trainning set for keras regression </span>

<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> scipy<span class="token punctuation">.</span>optimize <span class="token keyword">import</span> fmin
<span class="token keyword">from</span> scipy<span class="token punctuation">.</span>optimize <span class="token keyword">import</span> fmin_l_bfgs_b

<span class="token comment">#from scipy.optimize import fmin_ncg</span>
<span class="token keyword">from</span> scipy<span class="token punctuation">.</span>linalg <span class="token keyword">import</span> sqrtm
<span class="token keyword">import</span> math


<span class="token keyword">from</span> constructB <span class="token keyword">import</span> <span class="token operator">*</span>
<span class="token keyword">from</span> lorentz_attractor <span class="token keyword">import</span> <span class="token operator">*</span>

<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt

<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>gridspec <span class="token keyword">as</span> gridspec
<span class="token keyword">import</span> time
<span class="token keyword">import</span> random
<span class="token keyword">import</span> lorentz_attractor
<span class="token keyword">import</span> sklearn
<span class="token keyword">from</span> sklearn <span class="token keyword">import</span> datasets

<span class="token keyword">import</span> os

<span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isdir<span class="token punctuation">(</span><span class="token string">'lorenz_cov_train_v2'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span><span class="token string">'lorenz_cov_train_v2'</span><span class="token punctuation">)</span>

<span class="token comment">#######################################################################</span>

<span class="token keyword">def</span> <span class="token function">correlation_from_covariance</span><span class="token punctuation">(</span>covariance<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''
    Given:
        covariance: å¯¹ç§°æ­£å®šçŸ©é˜µ
    Returns:
        correlation: (-1,1) çš„å¯¹ç§°æ­£å®šçŸ©é˜µï¼Œç›¸å…³ç³»æ•°

    '''</span>
    v <span class="token operator">=</span> np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>np<span class="token punctuation">.</span>diag<span class="token punctuation">(</span>covariance<span class="token punctuation">)</span><span class="token punctuation">)</span>
    outer_v <span class="token operator">=</span> np<span class="token punctuation">.</span>outer<span class="token punctuation">(</span>v<span class="token punctuation">,</span> v<span class="token punctuation">)</span>
    correlation <span class="token operator">=</span> covariance <span class="token operator">/</span> outer_v   <span class="token comment">#https://www.mygreatlearning.com/blog/covariance-vs-correlation/</span>
    correlation<span class="token punctuation">[</span>covariance <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">0</span>
    <span class="token keyword">return</span> correlation

<span class="token comment">######################################################################</span>
<span class="token comment">#define matrix R by extra-diagonal elements</span>
<span class="token keyword">def</span> <span class="token function">R_covariance_dim3</span><span class="token punctuation">(</span>r1<span class="token punctuation">,</span>r2<span class="token punctuation">,</span>r3<span class="token punctuation">)</span><span class="token punctuation">:</span>
    M <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    M<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token operator">=</span> r1
    M<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> r2
    M<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span> <span class="token operator">=</span> r3
    M <span class="token operator">=</span> M <span class="token operator">+</span> M<span class="token punctuation">.</span>T
    M <span class="token operator">+=</span> np<span class="token punctuation">.</span>eye<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> M
    
<span class="token comment">################################################################################</span>
<span class="token comment">#######################################################################</span>
<span class="token keyword">def</span> <span class="token function">cov_to_cor</span><span class="token punctuation">(</span>M<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># from a covariance matrix to its associated correlation matrix</span>
    inv_diag_M<span class="token operator">=</span>np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>inv<span class="token punctuation">(</span>sqrtm<span class="token punctuation">(</span>np<span class="token punctuation">.</span>diag<span class="token punctuation">(</span>np<span class="token punctuation">.</span>diag<span class="token punctuation">(</span>M<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    cor_M <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>inv_diag_M<span class="token punctuation">,</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>M<span class="token punctuation">,</span>inv_diag_M<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> cor_M


<span class="token keyword">def</span> <span class="token function">lorenz_1step</span><span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> z<span class="token punctuation">,</span> s<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> r<span class="token operator">=</span><span class="token number">28</span><span class="token punctuation">,</span> b<span class="token operator">=</span><span class="token number">2.667</span><span class="token punctuation">,</span>dt <span class="token operator">=</span> <span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    x_dot<span class="token punctuation">,</span> y_dot<span class="token punctuation">,</span> z_dot <span class="token operator">=</span> lorenz<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> z<span class="token punctuation">)</span>
    x_next <span class="token operator">=</span> x <span class="token operator">+</span> <span class="token punctuation">(</span>x_dot <span class="token operator">*</span> dt<span class="token punctuation">)</span>
    y_next <span class="token operator">=</span> y <span class="token operator">+</span> <span class="token punctuation">(</span>y_dot <span class="token operator">*</span> dt<span class="token punctuation">)</span>
    z_next <span class="token operator">=</span> z <span class="token operator">+</span> <span class="token punctuation">(</span>z_dot <span class="token operator">*</span> dt<span class="token punctuation">)</span>    
    <span class="token keyword">return</span> x_next<span class="token punctuation">,</span> y_next<span class="token punctuation">,</span> z_next

<span class="token keyword">def</span> <span class="token function">VAR_3D</span><span class="token punctuation">(</span>xb<span class="token punctuation">,</span>Y<span class="token punctuation">,</span>H<span class="token punctuation">,</span>B<span class="token punctuation">,</span>R<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment">#booleen=1 garde la trace</span>
    xb1<span class="token operator">=</span>np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>xb<span class="token punctuation">)</span>
    xb1<span class="token punctuation">.</span>shape<span class="token operator">=</span><span class="token punctuation">(</span>xb1<span class="token punctuation">.</span>size<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
    Y<span class="token punctuation">.</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>Y<span class="token punctuation">.</span>size<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
    dim_x <span class="token operator">=</span> xb1<span class="token punctuation">.</span>size
    K<span class="token operator">=</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>B<span class="token punctuation">,</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>H<span class="token punctuation">)</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>linalg<span class="token punctuation">.</span>inv<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>H<span class="token punctuation">,</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>B<span class="token punctuation">,</span>np<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>H<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">+</span>R<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#matrice de gain, Kalman gain</span>
    A<span class="token operator">=</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>eye<span class="token punctuation">(</span>dim_x<span class="token punctuation">)</span><span class="token operator">-</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>K<span class="token punctuation">,</span>H<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>B<span class="token punctuation">)</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>eye<span class="token punctuation">(</span>dim_x<span class="token punctuation">)</span><span class="token operator">-</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>K<span class="token punctuation">,</span>H<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token operator">+</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>K<span class="token punctuation">,</span>R<span class="token punctuation">)</span><span class="token punctuation">,</span>np<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span>K<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment">#not the kalman filter expression???</span>
    vect<span class="token operator">=</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>H<span class="token punctuation">,</span>xb1<span class="token punctuation">)</span>
    xa<span class="token operator">=</span>np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>xb1<span class="token operator">+</span>np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>K<span class="token punctuation">,</span><span class="token punctuation">(</span>Y<span class="token operator">-</span>vect<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> xa<span class="token punctuation">,</span>A   <span class="token comment">#xa is the new estimated data, A is the new covariance,</span>
<span class="token comment">###################################################################################</span>

<span class="token comment">###################################################################################</span>
<span class="token comment">#parameters</span>
num_steps <span class="token operator">=</span> <span class="token number">1000</span>
H <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
R <span class="token operator">=</span> <span class="token number">0.001</span><span class="token operator">*</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0.4</span><span class="token punctuation">,</span><span class="token number">0.1</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0.4</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0.4</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0.1</span><span class="token punctuation">,</span><span class="token number">0.4</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

B <span class="token operator">=</span><span class="token number">0.01</span><span class="token operator">*</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0.2</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0.2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0.2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">.</span><span class="token punctuation">,</span><span class="token number">0.2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment">#Q = 0.0001*np.eye(3)</span>

<span class="token comment">###################################################################################</span>
<span class="token comment">#save the trainning set for different R </span>
trainning_set <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>num_steps<span class="token operator">*</span><span class="token number">3</span><span class="token operator">+</span><span class="token number">3</span><span class="token operator">+</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token comment">#åŠ 3çš„åŸå› ï¼šLorenz ç³»ç»Ÿæ¯ä¸ªå‚æ•°çš„æ—¶é—´èŠ‚ç‚¹ä¸ªæ•°ï¼Œæ¯”æ­¥é•¿æ•°å¤š 1ï¼Œæœ‰3ä¸ªå‚æ•°ï¼ŒåŠ 3</span>
    <span class="token comment">#åŠ 4çš„åŸå› ï¼šR çŸ©é˜µç”Ÿæˆçš„4ä¸ªå‚æ•°</span>

<span class="token comment">###################################################################################</span>

<span class="token comment">#############################################################################</span>
<span class="token comment"># true states vector 3 * number_steps</span>
xs<span class="token punctuation">,</span>ys<span class="token punctuation">,</span>zs <span class="token operator">=</span> lorenz_attractor<span class="token punctuation">(</span>s<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> r<span class="token operator">=</span><span class="token number">28</span><span class="token punctuation">,</span> b<span class="token operator">=</span><span class="token number">2.667</span><span class="token punctuation">,</span> dt <span class="token operator">=</span> <span class="token number">0.001</span><span class="token punctuation">,</span> num_steps<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">)</span>

x_true <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>num_steps<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># çœŸå®åœº</span>

x_true<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>xs<span class="token punctuation">)</span>
x_true<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>ys<span class="token punctuation">)</span>
x_true<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>zs<span class="token punctuation">)</span>


<span class="token comment">###############################################################################</span>
<span class="token keyword">for</span> ii <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">2000</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># ii = 0   ç®—æ³•1  ä¸­çš„iter?</span>
    <span class="token keyword">if</span> ii<span class="token operator">%</span><span class="token number">100</span> <span class="token operator">==</span><span class="token number">0</span><span class="token punctuation">:</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>ii<span class="token punctuation">)</span>
            
<span class="token comment"># construct observations</span>
                
<span class="token comment">#=========================================================================</span>
    <span class="token keyword">for</span> repetation <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment"># repetation = 0</span>
        <span class="token comment"># èƒŒæ™¯åœº çš„ç”Ÿæˆ</span>
        xs<span class="token punctuation">,</span>ys<span class="token punctuation">,</span>zs <span class="token operator">=</span> lorenz_attractor<span class="token punctuation">(</span>s<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span> r<span class="token operator">=</span><span class="token number">28</span><span class="token punctuation">,</span> b<span class="token operator">=</span><span class="token number">2.667</span><span class="token punctuation">,</span> dt <span class="token operator">=</span> <span class="token number">0.001</span><span class="token punctuation">,</span> num_steps <span class="token operator">=</span> <span class="token number">1000</span><span class="token punctuation">,</span>x0 <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">.</span><span class="token operator">+</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
                                    y0<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">.</span><span class="token operator">+</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">)</span><span class="token punctuation">,</span>z0<span class="token operator">=</span><span class="token number">1.05</span><span class="token operator">+</span>np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>normal<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">0.05</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        
        x_true <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>num_steps<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># èƒŒæ™¯åœºï¼Œè¿™é‡Œåªå¯¹åˆå§‹å€¼è¿›è¡Œå™ªå£°å¹²æ‰°ï¼Œæ˜¯å› ä¸ºlorenzæ˜¯ä¸ªæ··æ²Œç³»ç»Ÿï¼›</span>
        
        x_true<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>xs<span class="token punctuation">)</span>
        x_true<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>ys<span class="token punctuation">)</span>
        x_true<span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> np<span class="token punctuation">.</span>copy<span class="token punctuation">(</span>zs<span class="token punctuation">)</span>                
        
<span class="token comment">#=========================================================================</span>

        y_true <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>num_steps<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#</span>
        y_obs <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span>num_steps<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#</span>

        <span class="token comment"># R çš„æ„å»º</span>
        v <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>uniform<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">100</span><span class="token punctuation">.</span><span class="token punctuation">)</span>
        R <span class="token operator">=</span> correlation_from_covariance<span class="token punctuation">(</span>sklearn<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>make_spd_matrix<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment">#SPD covariance</span>
        
        r1 <span class="token operator">=</span> R<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span>
        r2 <span class="token operator">=</span> R<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span>
        r3 <span class="token operator">=</span> R<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span>
        
        R <span class="token operator">=</span> v<span class="token operator">*</span>R

        <span class="token comment"># è®­ç»ƒæ•°æ®é›† çš„æ„å»ºï¼šLorenz 3 ä¸ªå‚æ•°çš„æ—¶é—´èŠ‚ç‚¹ï¼ˆ3*1001ï¼‰ï¼ŒR çš„ 4 ä¸ªå‚æ•° ï¼ˆ+4ï¼‰</span>
        <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_steps<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># i=0</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"sample time: "</span><span class="token punctuation">,</span>ii<span class="token punctuation">)</span> <span class="token comment">#é‡‡æ ·æ¬¡æ•°</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"iteration time: "</span><span class="token punctuation">,</span>i<span class="token punctuation">)</span> <span class="token comment">#è¿­ä»£æ¬¡æ•°</span>
            <span class="token comment"># è§‚æµ‹ y çš„ç”Ÿæˆ</span>
            x <span class="token operator">=</span> x_true<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token punctuation">]</span>
            x<span class="token punctuation">.</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>x<span class="token punctuation">.</span>size<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span>
            y <span class="token operator">=</span> np<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>H<span class="token punctuation">,</span>x<span class="token punctuation">)</span>               <span class="token comment">#why this is this expression to calculate y?        </span>
            y<span class="token punctuation">.</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>y<span class="token punctuation">.</span>size<span class="token punctuation">,</span><span class="token punctuation">)</span>
            y_true<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> y
            
            y_noise <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>multivariate_normal<span class="token punctuation">(</span>np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">,</span>R<span class="token punctuation">)</span>
            y_noise<span class="token punctuation">.</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>y_noise<span class="token punctuation">.</span>size<span class="token punctuation">,</span><span class="token punctuation">)</span>
            y_noise <span class="token operator">+=</span> y 
            y_obs<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> y_noise

            <span class="token comment"># æ‹¼æ¥ä¸Š R çš„ 4 ä¸ªå‚æ•°</span>
            parameters <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span><span class="token punctuation">[</span>r1<span class="token punctuation">,</span>r2<span class="token punctuation">,</span>r3<span class="token punctuation">,</span>v<span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment">#output for deep learning regression</span>
                        <span class="token comment">#train_row = np.concatenate((y_obs.ravel(),x_true.ravel())) #input for deep learning    #what are the functionalities of these r -&gt;covaraicen! why v is not necessary???</span>
            train_row <span class="token operator">=</span> y_obs<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># .ravel çŸ©é˜µå‘é‡åŒ–ï¼Œx = np.array([[1,2],[3,4]]),åˆ™print(np.ravel(x)) = [1 2 3 4]</span>
            train_row <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>train_row<span class="token punctuation">.</span>ravel<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>parameters<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># .concatenate æ•°ç»„æ‹¼æ¥</span>
            
        train_row<span class="token punctuation">.</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span>train_row<span class="token punctuation">.</span>size<span class="token punctuation">)</span> <span class="token comment"># .shape</span>
        trainning_set <span class="token operator">=</span> np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>trainning_set<span class="token punctuation">,</span>train_row<span class="token punctuation">)</span><span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># .concatenate axis=0 æ•°ç»„æ‹¼æ¥</span>

        <span class="token comment"># if repetation+ii*10==5000:</span>

        <span class="token comment">#     np.savetxt(f"lorenz_cov_train_v2/trainset_withx_steps1000_test_{10000+repetation+ii*10}.csv", trainning_set, delimiter=",")</span>

trainning_set <span class="token operator">=</span> trainning_set<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token comment"># ä¸è¦ç¬¬ä¸€è¡Œï¼Œå…¨æ˜¯ 0 çš„é‚£ä¸€è¡Œï¼›</span>
<span class="token comment">#####################################################################################""</span>
np<span class="token punctuation">.</span>savetxt<span class="token punctuation">(</span><span class="token string">"lorenz_cov_train_v2/trainset_withx_steps1000_test8.csv"</span><span class="token punctuation">,</span> trainning_set<span class="token punctuation">,</span> delimiter<span class="token operator">=</span><span class="token string">","</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="QTï¼šä¸ºä»€ä¹ˆçº¿æ€§è§‚æµ‹ç®—å­Hæ˜¯å›ºå®šçš„é‚£ä¸ªçŸ©é˜µï¼Ÿä¸ºä»€ä¹ˆH-x-åŠ ä¸Šä¸ªå¤šå…ƒè¯¯å·®çš„åæ–¹å·®åˆ†å¸ƒï¼Œå°±å˜æˆè§‚æµ‹äº†ï¼Ÿï¼ˆå› ä¸ºDAä¸­ï¼Œè§‚æµ‹ä¹Ÿæ˜¯æœ‰è¯¯å·®çš„ï¼Ÿï¼‰"><a href="#QTï¼šä¸ºä»€ä¹ˆçº¿æ€§è§‚æµ‹ç®—å­Hæ˜¯å›ºå®šçš„é‚£ä¸ªçŸ©é˜µï¼Ÿä¸ºä»€ä¹ˆH-x-åŠ ä¸Šä¸ªå¤šå…ƒè¯¯å·®çš„åæ–¹å·®åˆ†å¸ƒï¼Œå°±å˜æˆè§‚æµ‹äº†ï¼Ÿï¼ˆå› ä¸ºDAä¸­ï¼Œè§‚æµ‹ä¹Ÿæ˜¯æœ‰è¯¯å·®çš„ï¼Ÿï¼‰" class="headerlink" title="QTï¼šä¸ºä»€ä¹ˆçº¿æ€§è§‚æµ‹ç®—å­Hæ˜¯å›ºå®šçš„é‚£ä¸ªçŸ©é˜µï¼Ÿä¸ºä»€ä¹ˆH(x)åŠ ä¸Šä¸ªå¤šå…ƒè¯¯å·®çš„åæ–¹å·®åˆ†å¸ƒï¼Œå°±å˜æˆè§‚æµ‹äº†ï¼Ÿï¼ˆå› ä¸ºDAä¸­ï¼Œè§‚æµ‹ä¹Ÿæ˜¯æœ‰è¯¯å·®çš„ï¼Ÿï¼‰"></a>QTï¼šä¸ºä»€ä¹ˆçº¿æ€§è§‚æµ‹ç®—å­Hæ˜¯å›ºå®šçš„é‚£ä¸ªçŸ©é˜µï¼Ÿä¸ºä»€ä¹ˆH(x)åŠ ä¸Šä¸ªå¤šå…ƒè¯¯å·®çš„åæ–¹å·®åˆ†å¸ƒï¼Œå°±å˜æˆè§‚æµ‹äº†ï¼Ÿï¼ˆå› ä¸ºDAä¸­ï¼Œè§‚æµ‹ä¹Ÿæ˜¯æœ‰è¯¯å·®çš„ï¼Ÿï¼‰</h4><h4 id="lorenz-lstm200-py"><a href="#lorenz-lstm200-py" class="headerlink" title="lorenz_lstm200.py"></a>lorenz_lstm200.py</h4><p><code>lorenz_lstm200.py</code> released in 2022-02-26</p>
<ul>
<li><p>æŠ¥é”™ï¼š</p>
<pre class="line-numbers language-none"><code class="language-none">ImportError: cannot import name 'Adam' from 'keras.optimizers' (D:\Program Files (x86)\Anaconda3\envs\LSTM_Covariance-main\lib\site-packages\keras\optimizers.py)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>è§£å†³æ–¹æ³•ï¼š<a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/62707558/importerror-cannot-import-name-adam-from-keras-optimizers/69581798">https://stackoverflow.com/questions/62707558/importerror-cannot-import-name-adam-from-keras-optimizers/69581798</a></p>
<pre class="line-numbers language-none"><code class="language-none">from tensorflow.keras.optimizers import Adam<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre></li>
<li><p>æ•´ä¸ªè¿è¡Œæ—¶é—´</p>
<p>è¿è¡Œå¼€å§‹æ—¶é—´ï¼š11:40 </p>
<p>è¿è¡Œç»“æŸæ—¶é—´ï¼š14:20</p>
</li>
<li><p>ç›¸å…³ä»£ç çŸ¥è¯†ç‚¹</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># ç›¸å¯¹è·¯å¾„è§£å†³åŠæ³•</span>
<span class="token comment">#train_data = data_set_order('D:/LSTM_Covariance-main/lorenz/lorenz_cov_train_v2/trainset_withx_steps1000_test8.csv')</span>
<span class="token comment">#os.getcwd()</span>
os<span class="token punctuation">.</span>chdir<span class="token punctuation">(</span><span class="token string">'D:/LSTM_Covariance-main/lorenz/'</span><span class="token punctuation">)</span>

<span class="token comment"># -2è¡¨ç¤ºçš„æ„æ€</span>
train_data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token builtin">file</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span>  <span class="token comment">#å–è¿™ä¸ªæ•°ç»„ä»ç¬¬ä¸€è¡Œåˆ°å€’æ•°ç¬¬ä¸‰è¡Œï¼Œæœ€åä¸¤è¡Œè¢«ä¸¢å¼ƒäº†ã€‚</span>

<span class="token comment"># .insert axis=1 åˆ—æ’å…¥</span>
train_data<span class="token operator">=</span>np<span class="token punctuation">.</span>insert<span class="token punctuation">(</span>r0<span class="token punctuation">,</span><span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>r0<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>r1<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> 

<span class="token comment">#.concateenate axis=1 åˆ—åˆå¹¶`</span>
train_data<span class="token operator">=</span>np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>train_data<span class="token punctuation">,</span>r3<span class="token punctuation">)</span><span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> 

<span class="token comment"># .random.shuffle æ‰“ä¹±è¡Œçš„é¡ºåº</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>train_data <span class="token punctuation">)</span>

<span class="token comment"># ä¸matlabä¸ä¸€æ ·çš„ä¸€ç‚¹ï¼šç´¢å¼•</span>
input_data <span class="token operator">=</span> train_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">603</span><span class="token punctuation">]</span> 
output_data <span class="token operator">=</span> train_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">603</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token comment">#å‡ºç°ä¸¤æ¬¡ 603 ï¼Œç´¢å¼•çš„æ•°æ®é‡å¤äº†å—ï¼Ÿæ²¡æœ‰</span>

<span class="token comment"># å¯ä»¥å¯¹ä¸­æ–‡å˜é‡è¿›è¡Œèµ‹å€¼ï¼Œæ„ä¹‰åœ¨äºï¼Œå¯ä»¥åœ¨pycharmçœ‹åˆ°å˜é‡çš„å¤§çº²</span>
P03_LSTMæ¨¡å‹ç»“æ„å’Œè¿è¡Œ <span class="token operator">=</span> <span class="token number">0</span>

<span class="token comment"># pycharmä¸­plt.show()ä¸æ˜¾ç¤ºå›¾åƒè§£å†³åŠæ³•</span>
<span class="token keyword">import</span> matplotlib
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt
matplotlib<span class="token punctuation">.</span>use<span class="token punctuation">(</span><span class="token string">'TKAgg'</span><span class="token punctuation">)</span><span class="token comment">#åŠ ä¸Šè¿™è¡Œä»£ç å³å¯ï¼Œaggæ˜¯ä¸€ä¸ªæ²¡æœ‰å›¾å½¢æ˜¾ç¤ºç•Œé¢çš„ç»ˆç«¯ï¼Œå¸¸ç”¨çš„æœ‰å›¾å½¢ç•Œé¢æ˜¾ç¤ºçš„ç»ˆç«¯æœ‰TkAggç­‰</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre></li>
<li><p><code>lorenz_lstm200.py</code> released in 2022-02-26 æœ€å¼€å§‹çš„ä»£ç </p>
</li>
</ul>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># -*- coding: utf-8 -*-</span>
<span class="token triple-quoted-string string">"""
Created on Wed Jan  6 13:39:58 2021

@author: siboc
"""</span>

<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">import</span> scipy
<span class="token keyword">import</span> math
<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt


<span class="token keyword">from</span> keras<span class="token punctuation">.</span>models <span class="token keyword">import</span> Sequential
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> Dense
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> r2_score
<span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
<span class="token keyword">import</span> keras<span class="token punctuation">.</span>backend <span class="token keyword">as</span> K
<span class="token comment"># check scikit-learn version</span>

<span class="token comment"># check scikit-learn version</span>
<span class="token keyword">import</span> sklearn
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>linear_model <span class="token keyword">import</span> LinearRegression
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>datasets <span class="token keyword">import</span> make_regression
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>neighbors <span class="token keyword">import</span> KNeighborsRegressor
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>tree <span class="token keyword">import</span> DecisionTreeRegressor
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

<span class="token keyword">def</span> <span class="token function">data_set_order</span><span class="token punctuation">(</span><span class="token builtin">file</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
	train_data <span class="token operator">=</span> np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token builtin">file</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
	r0<span class="token operator">=</span>train_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token number">1001</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token number">201</span><span class="token punctuation">]</span>
	r1<span class="token operator">=</span>train_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">1001</span><span class="token punctuation">:</span><span class="token number">2002</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token number">201</span><span class="token punctuation">]</span>
	r2<span class="token operator">=</span>train_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">2002</span><span class="token punctuation">:</span><span class="token number">3003</span><span class="token punctuation">]</span><span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token number">201</span><span class="token punctuation">]</span>
	r3<span class="token operator">=</span>train_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">3003</span><span class="token punctuation">:</span><span class="token punctuation">]</span>
	r3<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">=</span>r3<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">/</span><span class="token number">100</span>
	train_data<span class="token operator">=</span>np<span class="token punctuation">.</span>insert<span class="token punctuation">(</span>r0<span class="token punctuation">,</span><span class="token punctuation">[</span>i<span class="token operator">+</span><span class="token number">1</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>r0<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>r1<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
	train_data<span class="token operator">=</span>np<span class="token punctuation">.</span>insert<span class="token punctuation">(</span>train_data<span class="token punctuation">,</span><span class="token punctuation">[</span><span class="token punctuation">(</span>i<span class="token operator">+</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">*</span><span class="token number">2</span> <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">int</span><span class="token punctuation">(</span>train_data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token operator">/</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span>r2<span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
	train_data<span class="token operator">=</span>np<span class="token punctuation">.</span>concatenate<span class="token punctuation">(</span><span class="token punctuation">(</span>train_data<span class="token punctuation">,</span>r3<span class="token punctuation">)</span><span class="token punctuation">,</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
	<span class="token keyword">return</span> train_data

<span class="token comment">#input</span>
train_data <span class="token operator">=</span> data_set_order<span class="token punctuation">(</span><span class="token string">'lorenz_cov_train_v2/trainset_withx_steps1000_test8.csv'</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"train_data shape: "</span><span class="token punctuation">,</span>train_data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>


<span class="token comment"># train_data1 = data_set_order('lorenz_cov_train/trainset_withx_repeat10bis3.csv')</span>
<span class="token comment"># print("train_data1 shape: ",train_data1.shape)</span>

<span class="token comment"># train_data2 = data_set_order('lorenz_cov_train/trainset_withx_repeat10bis4.csv')</span>
<span class="token comment"># print("train_data2 shape: ",train_data2.shape)</span>

<span class="token comment"># train_data3 = data_set_order('lorenz_cov_train/trainset_withx_repeat10bis5.csv')</span>
<span class="token comment"># print("train_data3 shape: ",train_data3.shape)</span>

<span class="token comment"># train_data4 = data_set_order('lorenz_cov_train/trainset_withx_repeat10bis6.csv')</span>
<span class="token comment"># print("train_data4 shape: ",train_data4.shape)</span>

<span class="token comment"># train_data5 = data_set_order('lorenz_cov_train/trainset_withx_repeat10bis7.csv')</span>
<span class="token comment"># print("train_data5 shape: ",train_data5.shape)</span>

<span class="token comment"># train_data6 = data_set_order('lorenz_cov_train/trainset_withx_repeat10bis8.csv')</span>
<span class="token comment"># print("train_data6 shape: ",train_data6.shape)</span>

<span class="token comment">#size: num_steps*3,r1,r2,r3,v</span>


<span class="token comment">#########################################################################################</span>

<span class="token comment">#train_data = np.array(pd.read_csv('data_1000steps/trainset_withx_1000steps.csv'))</span>
<span class="token comment">#</span>
<span class="token comment">#</span>
<span class="token comment">#train_data1 = np.array(pd.read_csv('data_1000steps/trainset_withx_1000stepsbis1.csv'))</span>
<span class="token comment">#</span>
<span class="token comment">#train_data2 = np.array(pd.read_csv('data_1000steps/trainset_withx_1000stepsbis2.csv'))</span>
<span class="token comment">#</span>
<span class="token comment">#train_data3 = np.array(pd.read_csv('data_1000steps/trainset_withx_1000stepsbis3.csv'))</span>





<span class="token comment"># train_data = np.concatenate((train_data6,train_data5),axis = 0)</span>

<span class="token comment"># train_data = np.concatenate((train_data,train_data4),axis = 0)</span>

<span class="token comment"># train_data = np.concatenate((train_data,train_data3),axis = 0)</span>

<span class="token comment"># train_data = np.concatenate((train_data,train_data2),axis = 0)</span>

<span class="token comment"># train_data = np.concatenate((train_data,train_data1),axis = 0)</span>

<span class="token comment"># train_data = np.concatenate((train_data,train_data0),axis = 0)</span>

<span class="token comment"># train_data=train_data[:120000,:]</span>


<span class="token comment">#weightstrain_data[:,604:]</span>
np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>shuffle<span class="token punctuation">(</span>train_data <span class="token punctuation">)</span>

input_data <span class="token operator">=</span> train_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">:</span><span class="token number">603</span><span class="token punctuation">]</span>
output_data <span class="token operator">=</span> train_data<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">603</span><span class="token punctuation">:</span><span class="token punctuation">]</span>



<span class="token comment">########################################################################</span>
train_part <span class="token operator">=</span> <span class="token number">0.97</span>

threshold <span class="token operator">=</span> <span class="token builtin">int</span><span class="token punctuation">(</span>train_part<span class="token operator">*</span>train_data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>


<span class="token comment">##########################################################################</span>

train_input <span class="token operator">=</span> input_data<span class="token punctuation">[</span><span class="token punctuation">:</span>threshold<span class="token punctuation">]</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"input_data shape: "</span><span class="token punctuation">,</span>input_data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>

train_output <span class="token operator">=</span> output_data<span class="token punctuation">[</span><span class="token punctuation">:</span>threshold<span class="token punctuation">]</span>

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">"output_data shape: "</span><span class="token punctuation">,</span>output_data<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>


test_input <span class="token operator">=</span> input_data <span class="token punctuation">[</span>threshold<span class="token punctuation">:</span><span class="token punctuation">]</span>

true_test_output <span class="token operator">=</span> output_data<span class="token punctuation">[</span>threshold<span class="token punctuation">:</span><span class="token punctuation">]</span>



X1 <span class="token operator">=</span> train_input
Y1 <span class="token operator">=</span> train_output

X2 <span class="token operator">=</span> test_input
<span class="token comment">#Y2 = ValidationSet_Y</span>

<span class="token comment">############################################################################</span>



<span class="token comment">#def my_loss_fn(y_true, y_pred):</span>
<span class="token comment">#    </span>
<span class="token comment">#    return K.mean(K.abs(y_true - y_pred) * weight)</span>

<span class="token comment"># ========================================================================================</span>
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> LSTM<span class="token punctuation">,</span>Dropout
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>layers <span class="token keyword">import</span> TimeDistributed
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>callbacks <span class="token keyword">import</span> EarlyStopping
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>callbacks <span class="token keyword">import</span> ModelCheckpoint
<span class="token keyword">from</span> keras<span class="token punctuation">.</span>optimizers <span class="token keyword">import</span> Adam




<span class="token comment"># save data</span>
<span class="token keyword">import</span> os
<span class="token keyword">import</span> json
<span class="token keyword">import</span> pickle

<span class="token keyword">if</span> <span class="token keyword">not</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>isdir<span class="token punctuation">(</span><span class="token string">'save_data_v2'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
	os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span><span class="token string">'save_data_v2'</span><span class="token punctuation">)</span>

hidden_size<span class="token operator">=</span><span class="token number">200</span>

input_sample<span class="token operator">=</span>input_data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>  <span class="token comment">#for one sample</span>


output_sample<span class="token operator">=</span>output_data<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>

input_data<span class="token operator">=</span>input_data<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>input_sample<span class="token punctuation">,</span><span class="token number">201</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span>  <span class="token comment">#201 is the time steps in data_generation</span>
output_data<span class="token operator">=</span>output_data<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>output_sample<span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span>

use_dropout<span class="token operator">=</span><span class="token boolean">True</span>
model <span class="token operator">=</span> Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>LSTM<span class="token punctuation">(</span>hidden_size<span class="token punctuation">,</span>input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">201</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>Dense<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment"># opt = Adam(lr=0.0001)</span>
model<span class="token punctuation">.</span><span class="token builtin">compile</span><span class="token punctuation">(</span>loss<span class="token operator">=</span><span class="token string">'mean_squared_error'</span><span class="token punctuation">,</span> optimizer<span class="token operator">=</span><span class="token string">'Adam'</span><span class="token punctuation">,</span> metrics<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'mae'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">.</span>summary<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

es<span class="token operator">=</span>EarlyStopping<span class="token punctuation">(</span>monitor<span class="token operator">=</span><span class="token string">'val_loss'</span><span class="token punctuation">,</span>mode<span class="token operator">=</span><span class="token string">'min'</span><span class="token punctuation">,</span>verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>patience<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">)</span>
<span class="token comment"># modelcheckpoint</span>
mc<span class="token operator">=</span>ModelCheckpoint<span class="token punctuation">(</span><span class="token string">'save_data_v2/sequentiallstm200_ing.h5'</span><span class="token punctuation">,</span>monitor<span class="token operator">=</span><span class="token string">'val_loss'</span><span class="token punctuation">,</span>mode<span class="token operator">=</span><span class="token string">'min'</span><span class="token punctuation">,</span>save_best_only<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>

history<span class="token operator">=</span>model<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>input_data<span class="token punctuation">,</span> output_data<span class="token punctuation">,</span> validation_split<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">,</span> epochs<span class="token operator">=</span><span class="token number">100</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> verbose<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>callbacks<span class="token operator">=</span><span class="token punctuation">[</span>es<span class="token punctuation">,</span>mc<span class="token punctuation">]</span><span class="token punctuation">)</span>




<span class="token comment"># model.save('save_data/sequentiallstm2')</span>
model<span class="token punctuation">.</span>save<span class="token punctuation">(</span><span class="token string">'save_data_v2/sequentiallstm200_ing_f.h5'</span><span class="token punctuation">)</span>

<span class="token comment"># https://stackoverflow.com/a/44674337/10349608</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'save_data_v2/sequentiallstm200_ing_history.pickle'</span><span class="token punctuation">,</span> <span class="token string">'wb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> file_his<span class="token punctuation">:</span>
	pickle<span class="token punctuation">.</span>dump<span class="token punctuation">(</span>history<span class="token punctuation">.</span>history<span class="token punctuation">,</span> file_his<span class="token punctuation">)</span>


<span class="token comment"># Calculate predictions</span>
PredTestSet <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X1<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>X1<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">201</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
PredValSet <span class="token operator">=</span> model<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>X2<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>X2<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token number">201</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">)</span>




plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>history<span class="token punctuation">.</span>history<span class="token punctuation">[</span><span class="token string">'val_loss'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Model loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Loss'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Epoch'</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'Train'</span><span class="token punctuation">,</span> <span class="token string">'Test'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> loc<span class="token operator">=</span><span class="token string">'upper left'</span><span class="token punctuation">)</span>
<span class="token comment">#plt.savefig('figure_dp/loss_trace.eps', format='eps',bbox_inches='tight')</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>



plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>PredValSet<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>true_test_output<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token string">'o'</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'blue'</span><span class="token punctuation">,</span>markersize<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
<span class="token comment">#plt.plot(list(range(0,1,0.1)),list(range(0,1,0.1)),'k')</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>PredValSet<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>true_test_output<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span><span class="token string">'o'</span><span class="token punctuation">,</span>color<span class="token operator">=</span><span class="token string">'blue'</span><span class="token punctuation">,</span>markersize<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>
<span class="token comment">#plt.plot(list(range(0,1,0.1)),list(range(0,1,0.1)),'k')</span>
plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>



<span class="token comment"># predint = model.predict(train_input[:3000])</span>

<span class="token comment"># trueint = train_output[:3000]</span>


<span class="token comment"># plt.plot(predint[:,3],trueint[:,3],'o', color='blue',markersize=5)</span>
<span class="token comment"># #plt.plot(list(range(0,1,0.1)),list(range(0,1,0.1)),'k')</span>
<span class="token comment"># plt.show()</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="QTï¼šTensorflow-kerasä¸kerasçš„åŒºåˆ«"><a href="#QTï¼šTensorflow-kerasä¸kerasçš„åŒºåˆ«" class="headerlink" title="QTï¼šTensorflow-kerasä¸kerasçš„åŒºåˆ«"></a>QTï¼šTensorflow-kerasä¸kerasçš„åŒºåˆ«</h4><p>Tensorflow-kerasä¸kerasçš„åŒºåˆ«ï¼š<a target="_blank" rel="noopener" href="https://www.jianshu.com/p/135b2ee61a1c">https://www.jianshu.com/p/135b2ee61a1c</a></p>
<blockquote>
<p>å¦‚æœä½ éœ€è¦ä»»ä½•ä¸€ä¸ªä¸Šè¿°tf.kerasçš„ç‰¹æœ‰ç‰¹æ€§çš„è¯ï¼Œé‚£å½“ç„¶åº”è¯¥é€‰æ‹©tf.kerasã€‚</p>
<p>å¦‚æœåç«¯å¯äº’æ¢æ€§å¯¹ä½ å¾ˆé‡è¦çš„è¯ï¼Œé‚£é€‰æ‹©kerasã€‚</p>
<p>å¦‚æœä»¥ä¸Šä¸¤æ¡å¯¹ä½ éƒ½ä¸é‡è¦çš„è¯ï¼Œé‚£é€‰ç”¨å“ªä¸ªéƒ½å¯ä»¥ã€‚</p>
</blockquote>
<h3 id="Shallow-waterï¼šå¸Œæœ›èƒ½å¯¹lorenzä¸­é‡åˆ°çš„é—®é¢˜ï¼Œå¾—åˆ°å¯å‘"><a href="#Shallow-waterï¼šå¸Œæœ›èƒ½å¯¹lorenzä¸­é‡åˆ°çš„é—®é¢˜ï¼Œå¾—åˆ°å¯å‘" class="headerlink" title="Shallow waterï¼šå¸Œæœ›èƒ½å¯¹lorenzä¸­é‡åˆ°çš„é—®é¢˜ï¼Œå¾—åˆ°å¯å‘~"></a>Shallow waterï¼šå¸Œæœ›èƒ½å¯¹lorenzä¸­é‡åˆ°çš„é—®é¢˜ï¼Œå¾—åˆ°å¯å‘~</h3><blockquote>
<p>ç®—æ³•1ï¼Œæ²¡ç»™å‡ºåŒåŒ–çš„å…·ä½“ç¨‹åº~~ğŸ¤®</p>
</blockquote>
<h3 id="2022-02-28ï¼šLSTM-Covariance-main-zip"><a href="#2022-02-28ï¼šLSTM-Covariance-main-zip" class="headerlink" title="2022-02-28ï¼šLSTM_Covariance-main.zip"></a>2022-02-28ï¼šLSTM_Covariance-main.zip</h3><blockquote>
<p>é“¾æ¥ï¼š<a target="_blank" rel="noopener" href="https://pan.baidu.com/s/1Dtx-p4LRHhIGjTilVvgw-g">https://pan.baidu.com/s/1Dtx-p4LRHhIGjTilVvgw-g</a><br>æå–ç ï¼š8egl<br>â€“æ¥è‡ªç™¾åº¦ç½‘ç›˜è¶…çº§ä¼šå‘˜V5çš„åˆ†äº«</p>
</blockquote>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        Author:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">Jincan</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        Link:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://Liu-Jincan.github.io/2022/02/25/yan-jiu-sheng-justtry-function/endnote-shu-ju-tong-hua/04-yue-du-code-shi-yong-xun-huan-shen-jing-wang-luo-jin-xing-shu-ju-tong-hua-de-guan-ce-wu-chai-xie-fang-chai-gui-fan-2021/">https://Liu-Jincan.github.io/2022/02/25/yan-jiu-sheng-justtry-function/endnote-shu-ju-tong-hua/04-yue-du-code-shi-yong-xun-huan-shen-jing-wang-luo-jin-xing-shu-ju-tong-hua-de-guan-ce-wu-chai-xie-fang-chai-gui-fan-2021/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        Reprint policy:
                    </i>
                </span>
                <span class="reprint-info">
                    All articles in this blog are used except for special statements
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    reprint policy. If reproduced, please indicate source
                    <a href="/about" target="_blank">Jincan</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>Copied successfully, please follow the reprint policy of this article</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">more</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            <span class="chip bg-color">No tag</span>
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>å¾®ä¿¡æ‰«ä¸€æ‰«å³å¯åˆ†äº«ï¼</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">èµ</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">Thanks for your reward</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">æ”¯ä»˜å®</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">å¾® ä¿¡</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.png" class="reward-img" alt="æ”¯ä»˜å®æ‰“èµäºŒç»´ç ">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="å¾®ä¿¡æ‰“èµäºŒç»´ç ">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;Previous</div>
            <div class="card">
                <a href="/2022/02/28/yan-jiu-sheng-justtry-function/endnote-shu-ju-tong-hua/07-code-nansencenter-da-tutorials-2021/">
                    <div class="card-image">
                        
                        <img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220327135302.png" class="responsive-img" alt="07-é˜…è¯»ï¼šnansencenter-DA-tutorials-2021">
                        
                        <span class="card-title">07-é˜…è¯»ï¼šnansencenter-DA-tutorials-2021</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            ~~
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2022-02-28
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E6%95%B0%E6%8D%AE%E5%90%8C%E5%8C%96/" class="post-category">
                                    æ•°æ®åŒåŒ–
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                Next&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2022/02/25/yan-jiu-sheng-justtry-function/hai-yang-shu-ju/01-era5-shu-ju/">
                    <div class="card-image">
                        
                        <img src="https://raw.githubusercontent.com/Liu-Jincan/PicGo/main/img/20220327145128.png" class="responsive-img" alt="01-ERA5æ•°æ®">
                        
                        <span class="card-title">01-ERA5æ•°æ®</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            ~~
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2022-02-25
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E6%B5%B7%E6%B4%8B%E6%95%B0%E6%8D%AE/" class="post-category">
                                    æµ·æ´‹æ•°æ®
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- ä»£ç å—åŠŸèƒ½ä¾èµ– -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- ä»£ç è¯­è¨€ -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- ä»£ç å—å¤åˆ¶ -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- ä»£ç å—æ”¶ç¼© -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;TOC</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC æ‚¬æµ®æŒ‰é’®. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* ä¿®å¤æ–‡ç« å¡ç‰‡ div çš„å®½åº¦. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // åˆ‡æ¢TOCç›®å½•å±•å¼€æ”¶ç¼©çš„ç›¸å…³æ“ä½œ.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    });
</script>


    
    <!-- 05 footeræ˜¯ä»€ä¹ˆï¼Ÿé¡µè„š -->
    <footer class="page-footer bg-color">
    <!-- éŸ³ä¹  -->
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="6992203508"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
	style="margin-bottom: 15px !important;">
	
	
	
	
	
	<!--  copyrighté‚£æœ¬åˆ†çš„div -->
	<div class="col s12 m8 l8 copy-right">
            
            <!-- è¿™é‡Œæ˜¯ Copyright @, &nbspæ˜¯ç©ºæ ¼, &copyæ˜¯é‚£ä¸ªç¬¦å·å“Ÿ -->
            <!-- https://zhidao.baidu.com/question/745714487580680772.html, JavaScriptä¸­çš„â€œ&nbspâ€æ˜¯ä»€ä¹ˆæ„æ€, è½¬ä¹‰ç¬¦å·  -->
            Copyright&nbsp;&copy;
            
            <!-- è¿™é‡Œæ˜¯2021, é»˜è®¤çš„theme.time.yearæ˜¯2019,åœ¨è¿™é‡Œæˆ‘æŒ‡å®šä¸º2021,å› ä¸ºæˆ‘æ˜¯2021-12æœˆä»½åˆ›å»ºçš„åšå®¢,good job -->
            
            
                <span id="year">2021-2022</span>
            
            
            <!-- è¿™é‡Œæ˜¯Jincan Liu, è¿˜åŒ…æ‹¬äº†å¯¹åº”çš„è¶…é“¾æ¥å“¦ -->
            <a href="/about" target="_blank">Jincan Liu</a>
            
            <!-- è¿™é‡Œæ˜¯å…³äº Hexo -->
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            
            <!-- è¿™é‡Œæ˜¯å…³äº matery -->
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <!-- brè¡¨ç¤ºæ¢è¡Œ, https://zhidao.baidu.com/question/187056327.html -->
            <br>
            
            <!-- è¿™é‡Œæ˜¯ä¸ºäº†æ˜¾ç¤ºç«™ç‚¹æ€»å­—æ•° -->
            
            	<!-- <i>æ ‡ç­¾æ˜¯æ–œä½“ä½œç”¨, è¿™é‡Œæ˜¯ä¸ºäº†æ˜¾ç¤ºå›¾å½¢? -->
            	<!-- <span>æ˜¯è¡Œå†…å…ƒç´ , spançš„æ„ä¹‰æ˜¯æ·»åŠ æŒ‡å®šæ ·å¼,è¯¦è§https://blog.csdn.net/microcosmv/article/details/51953490 -->
                &nbsp;<i class="fas fa-chart-area"></i>&nbsp;Total Words:&nbsp;<span
                        class="white-color">480.7k</span>
            
            
            <!-- ä¸è’œå­è®¡æ•°å™¨çš„ä½¿ç”¨, https://blog.csdn.net/weixin_46247581/article/details/105848853, hexo s ä¸­æ˜¾ç¤ºçš„ä¸æ˜¯æ­£ç¡®çš„, ä¸ç”¨æ‹…å¿ƒ, çœ‹ hexo d ä¸Šçš„å³å¯ -->
            
            
                
            
                            
            <!-- è¿™æ˜¾ç¤ºæ€»è®¿é—®é‡ -->    <!-- æ˜¾ç¤ºæ¯ç¯‡æ–‡ç« çš„è®¿é—®é‡çš„æ–¹æ³•, https://blog.csdn.net/qq_23590921/article/details/103864482 -->
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;Total visits:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
            <!-- è¿™é‡Œæ˜¾ç¤ºæ€»è®¿é—®äººæ•° -->
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;Total visitors:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
                         
            <br>

            <!-- è¿è¡Œå¤©æ•°æé†’. -->
            
                <span id="sitetime"> Loading ...</span>
                <script>
                    var calcSiteTime = function () {
                        var seconds = 1000;
                        var minutes = seconds * 60;
                        var hours = minutes * 60;
                        var days = hours * 24;
                        var years = days * 365;
                        var today = new Date();
                        var startYear = "2021";
                        var startMonth = "12";
                        var startDate = "20";
                        var startHour = "0";
                        var startMinute = "0";
                        var startSecond = "0";
                        var todayYear = today.getFullYear();
                        var todayMonth = today.getMonth() + 1;
                        var todayDate = today.getDate();
                        var todayHour = today.getHours();
                        var todayMinute = today.getMinutes();
                        var todaySecond = today.getSeconds();
                        var t1 = Date.UTC(startYear, startMonth, startDate, startHour, startMinute, startSecond);
                        var t2 = Date.UTC(todayYear, todayMonth, todayDate, todayHour, todayMinute, todaySecond);
                        var diff = t2 - t1;
                        var diffYears = Math.floor(diff / years);
                        var diffDays = Math.floor((diff / days) - diffYears * 365);

                        // åŒºåˆ†æ˜¯å¦æœ‰å¹´ä»½.
                        var language = 'En';
                        if (startYear === String(todayYear)) {
                            document.getElementById("year").innerHTML = todayYear;
                            var daysTip = 'This site has been running for ' + diffDays + ' days';
                            if (language === 'zh-CN') {
                                daysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                daysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = daysTip;
                        } else {
                            document.getElementById("year").innerHTML = startYear + " - " + todayYear;
                            var yearsAndDaysTip = 'This site has been running for ' + diffYears + ' years and '
                                + diffDays + ' days';
                            if (language === 'zh-CN') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²è¿è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            } else if (language === 'zh-HK') {
                                yearsAndDaysTip = 'æœ¬ç«™å·²é‹è¡Œ ' + diffYears + ' å¹´ ' + diffDays + ' å¤©';
                            }
                            document.getElementById("sitetime").innerHTML = yearsAndDaysTip;
                        }
                    }

                    calcSiteTime();
                </script>
            
            <br>
            
            <!-- ä¸çŸ¥é“å¹²ä»€ä¹ˆ -->
            
        </div>
	
	
	
	
		
	
	<!-- è”ç³»å›¾æ ‡çš„ div -->
        <div class="col s12 m4 l4 social-link social-statis">






    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=3079779149" class="tooltipped" target="_blank" data-tooltip="QQè”ç³»æˆ‘: 3079779149" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>



    <a href="mailto:3079779149@qq.com" class="tooltipped" target="_blank" data-tooltip="é‚®ä»¶è”ç³»æˆ‘: jincanliu@qq.com; jincan8liu@gmail.com" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>



    <a href="https://www.researchgate.net/profile/Jincan-Liu" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„ResearchGate" data-position="top" data-delay="50">
        <i class="fab fa-researchgate"></i>
    </a>



    <a href="https://github.com/Liu-Jincan" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>






    <a href="https://www.zhihu.com/people/JincanLiu" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„çŸ¥ä¹" data-position="top" data-delay="50">
        <i class="fab fa-zhihu1">çŸ¥</i>
    </a> 



    <a href="https://space.bilibili.com/341192538" class="tooltipped" target="_blank" data-tooltip="è®¿é—®æˆ‘çš„bilibili" data-position="top" data-delay="50">
        <i class="iconfont icon-bilibili-fill"></i>
    </a>



</div>        
        

    </div>
</footer>


<!-- å›åˆ°é¡¶éƒ¨çš„div -->
<div class="progress-bar"></div>


    <!-- 06 searchæ˜¯ä»€ä¹ˆï¼Ÿæœç´¢é®ç…§æ  -->
    <!-- æœç´¢é®ç½©æ¡† -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;Search</span>
            <input type="search" id="searchInput" name="s" placeholder="Please enter a search keyword"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    
    <!-- 07 back-topæ˜¯ä»€ä¹ˆï¼Ÿå›åˆ°é¡¶éƒ¨æŒ‰é’® -->
    <!-- å›åˆ°é¡¶éƒ¨æŒ‰é’® -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <!-- fa-arrow-up -->
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <!-- 08 ??? -->
    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>
    
    <!-- 09 å›¾æ ‡ç»˜åˆ¶å·¥å…· -->
    

    <!-- 10 ???-->
    

    <!-- 11 é›ªèŠ±ç‰¹æ•ˆ -->
    

    <!-- 12 é¼ æ ‡æ˜Ÿæ˜Ÿç‰¹æ•ˆ -->
    


    <!-- 13 -->
     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- 14 -->
    <!-- Baidu Analytics -->

    
    <!-- 15 -->
    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <!-- 16 -->
    
    
    <!-- 17 -->
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    


    <!-- 18 -->
    
    
    <!-- 19 -->
    

    <!-- 20 è…¾è®¯å…”å°å·¢-->
    
    
    <!-- 21 canvas_nestç‰¹æ•ˆ -->
    
	
    <!-- 22 ribbonç‰¹æ•ˆ -->
    
    
    <!-- 23 -->
    

    <!-- 24 -->
    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
